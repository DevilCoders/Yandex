encoding "utf8";

import "test_compile.gztproto";

UTestTokenize "testTokenizeCC0" { {"abc123-5" } }
UTestTokenize "testTokenizeCC1" { {"abc123-5" tokenize = CHAR_CLASS } }
UTestTokenize "testTokenizeCC2" { { "северо-западный мекленбург" tokenize = CHAR_CLASS gram = { "ед,муж,дат" word=2 } } }
UTestTokenize "testTokenizeCC3" { { "(северо-западно-восточный) мекленбург" tokenize = CHAR_CLASS } }
UTestTokenize "testTokenizeCC4" { { "дроид r2d2 на татуин" tokenize = CHAR_CLASS gram = { "дат" word=4 } } }
UTestTokenize "testTokenizeNA1" { {"abc123-5" tokenize = NON_ALNUM } }
UTestTokenize "testTokenizeNA2" { { "северо-западный мекленбург" tokenize = NON_ALNUM } }
UTestTokenize "testTokenizeNA3" { { "(северо-западно-восточный) мекленбург" tokenize = NON_ALNUM } }

TArticle "turTestPanLabirinth1" { key = { "Pan'ın Labirenti" } }
TArticle "turTestPanLabirinth2" { key = { "Panın Labirenti" } }
TArticle "turTestPanLabirinth3" { key = { "Pan ın Labirenti" } }

