{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scipy.stats as sps\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dateutil.parser import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import json\n",
    "import typing as tp\n",
    "from sklearn.preprocessing import normalize\n",
    "import my_library as lib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_TO_OBSERVE = 14\n",
    "EMPTY_TYPE = 'undefined'\n",
    "column_types = set()\n",
    "TABLE_NAME = 'consumption_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = [\"nbs\", 'compute', 'ai', 'mdb', \n",
    "            'gpu', 'storage', 'mk8s', 'functions',\n",
    "            'speech', 'translate', 'vision', 'datalens', \n",
    "            'windows', 'marketplace', 'snapshot', 'image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_condition_request():\n",
    "    request = f\"\"\"\n",
    "    WHERE\n",
    "        toDate(event_time) < addDays(toDate(scoring_date), -1)\n",
    "    AND \n",
    "        toDate(first_first_trial_consumption_datetime) == \n",
    "        addDays(toDate(scoring_date), -{DAYS_TO_OBSERVE})\n",
    "    AND first_first_trial_consumption_datetime != '0000-00-00 00:00:00'\n",
    "    \"\"\"\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def services_req(services):\n",
    "    part_req = \"\"\n",
    "    for service in services:\n",
    "        column_types.add(f\"{service}:binary\")\n",
    "        part_req += f\"max(if (sku_name like '%{service}%', 1, 0)) as {service},\\n\"\n",
    "    return part_req[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumption_req():\n",
    "    part_req = \"\"\n",
    "    array_part_req = \"\"\n",
    "    for i in range(1, DAYS_TO_OBSERVE):\n",
    "        ind = i + 1\n",
    "        part_req += f\"\"\"SUM(if(toDate(event_time) == addDays(toDate(scoring_date), -{ind}), \n",
    "                            trial_consumption, 0)) as consumption_per_day_minus_{ind},\\n\"\"\"\n",
    "        column_types.add(f\"consumption_per_day_minus_{ind}:numeric\")\n",
    "        array_part_req = f\"\"\"consumption_per_day_minus_{ind}, \"\"\" + array_part_req\n",
    "    array_part_req = array_part_req[:-2]\n",
    "    part_req += f\"[{array_part_req}] as consumption_array\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_empty_days_in_the_end(array):\n",
    "    answer = 0;\n",
    "    for x in reversed(array):\n",
    "        if x < 0.1:\n",
    "            answer += 1\n",
    "        else:\n",
    "            break\n",
    "    return answer\n",
    "\n",
    "\n",
    "def predict_tan(target: tp.List[float]) -> float:\n",
    "    target = normalize(np.array(target)[:,np.newaxis], axis=0).ravel()\n",
    "    x = np.arange(0, target.shape[0])\n",
    "    model = LinearRegression()\n",
    "    model.fit(x.reshape(-1, 1), np.array(target))\n",
    "    return model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_consumption_scoring_table():\n",
    "    core_req = f\"\"\"\n",
    "SELECT\n",
    "    {services_req(services)},\n",
    "    {consumption_req()},\n",
    "    length(groupUniqArray(if(active_grant_ids == '', null, \n",
    "    active_grant_ids))) as number_of_grants, \n",
    "    billing_account_id,\n",
    "    addDays(toDate(first_first_trial_consumption_datetime), \n",
    "    {DAYS_TO_OBSERVE}) as scoring_date\n",
    "FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "{get_main_condition_request()}\n",
    "AND sku_lazy == 0\n",
    "GROUP BY billing_account_id, scoring_date\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "    # print(core_req)\n",
    "    df = lib.execute_query(core_req)\n",
    "    df['number_of_empty_days'] =\\\n",
    "    df['consumption_array'].apply(lambda array: len([x for x in array if x < 0.1]))\n",
    "    \n",
    "    df['number_of_empty_days_in_the_end'] =\\\n",
    "    df['consumption_array'].apply(lambda array: number_of_empty_days_in_the_end(array))\n",
    "    \n",
    "    df['mean_consumption'] =\\\n",
    "    df['consumption_array'].apply(lambda array: np.mean(array))\n",
    "    \n",
    "    df['median_consumption'] =\\\n",
    "    df['consumption_array'].apply(lambda array: np.median(array))\n",
    "    \n",
    "    df['std_consumption'] =\\\n",
    "    df['consumption_array'].apply(lambda array: np.std(array))\n",
    "    \n",
    "    df[\"consumer_plateau\"] =\\\n",
    "    ((df['consumption_array'].apply(lambda array: np.std(array[-5:])) /\\\n",
    "     (df['consumption_array'].apply(lambda array: np.mean(array[-5:]))\n",
    "      + 1e-5)) < 0.1).astype(int)\n",
    "    \n",
    "    df[\"min_consumption\"] =\\\n",
    "    df['consumption_array'].apply(lambda array: np.min(array))\n",
    "    \n",
    "    df[\"max_consumption\"] =\\\n",
    "    df['consumption_array'].apply(lambda array: np.max(array))\n",
    "    \n",
    "    df[\"consumption_tangens\"] = df['consumption_array'].apply(\n",
    "        lambda array: predict_tan(array))\n",
    "        \n",
    "    df.drop(columns = [\"consumption_array\"], inplace=True)\n",
    "    column_types.add(\"number_of_grants:numeric\")\n",
    "    column_types.add(\"max_consumption:numeric\")\n",
    "    column_types.add(\"min_consumption:numeric\")\n",
    "    column_types.add(\"consumer_plateau:binary\")\n",
    "    column_types.add(\"mean_consumption:numeric\")\n",
    "    column_types.add(\"std_consumption:numeric\")\n",
    "    column_types.add(\"consumption_tangens:numeric\")\n",
    "    column_types.add(\"median_consumption:numeric\")\n",
    "    column_types.add(\"number_of_empty_days:numeric\")\n",
    "    column_types.add(\"number_of_empty_days_in_the_end:numeric\")\n",
    "    \n",
    "    final_columns = [x.split(':')[0] for x in column_types]\n",
    "    assert set(df.columns) == set(final_columns + ['scoring_date', \n",
    "                                                   'billing_account_id']), \\\n",
    "    str(set(df.columns) - set(final_columns + ['scoring_date', 'billing_account_id'])) +\\\n",
    "    \"not matched\"\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_types(column_types):\n",
    "    rows = []\n",
    "    for column_type in column_types:\n",
    "        column, current_type = column_type.split(':')\n",
    "        rows.append([column, current_type, TABLE_NAME])\n",
    "    type_df = pd.DataFrame(np.matrix(rows), columns=['column_name', 'type',\n",
    "                                                     'table_name'])\n",
    "    lib.save_table('type_table', \"//home/cloud_analytics/scoring_v2/data_tables\", \n",
    "                   type_df, append=True)\n",
    "\n",
    "\n",
    "def add_table_to_model_to_observe():\n",
    "    tables_df = pd.DataFrame([TABLE_NAME], columns=['table_names'])\n",
    "    lib.save_table('table_names_for_scoring_model', \n",
    "               \"//home/cloud_analytics/scoring_v2/data_tables\", \n",
    "               tables_df, append=True)\n",
    "    \n",
    "\n",
    "def check_types_correspondence(df, column_types):\n",
    "    req = \"\"\"\n",
    "    SELECT\n",
    "        type,\n",
    "        checker_function\n",
    "    FROM \"//home/cloud_analytics/scoring_v2/data_tables/column_type_description\"\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    type_df = lib.execute_query(req)\n",
    "\n",
    "    checker_functions = {}\n",
    "    for func_str in type_df['checker_function']:\n",
    "        exec(func_str.replace(\"\\\\n\", '\\n'), checker_functions)\n",
    "    \n",
    "    assert len(df.columns) == len(column_types) + 2, \\\n",
    "    'difference in number of columns in dataframe and in column_types, '\n",
    "    f'{len(column_types) + 2 - len(df.columns)}'\n",
    "    \n",
    "    for column_type in column_types:\n",
    "        column, curr_type = column_type.split(\":\")\n",
    "        curr_function_name = curr_type.split(\"__\")[0]\n",
    "        if checker_functions.get(curr_function_name + \"_checker\") is None:\n",
    "            assert False, f\"no type {curr_function_name}\"\n",
    "        assert checker_functions[curr_function_name + \"_checker\"](df, column),\\\n",
    "        f'{curr_function_name} check failed for column {column}'\n",
    "        \n",
    "\n",
    "def save_all_results(df):\n",
    "    check_types_correspondence(df, column_types)\n",
    "    lib.save_table(TABLE_NAME, \"//home/cloud_analytics/scoring_v2/data_tables\", df)\n",
    "    save_types(column_types)\n",
    "    add_table_to_model_to_observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_df = make_consumption_scoring_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_table(TABLE_NAME, \"//home/cloud_analytics/scoring_v2/data_tables\", consumption_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_results(consumption_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
