{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lunin-dv/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import scipy.stats as sps\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from dateutil.parser import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import json\n",
    "import typing as tp\n",
    "import my_library as lib\n",
    "import ast\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_TO_OBSERVE = 14\n",
    "EMPTY_TYPE = 'undefined'\n",
    "TABLE_NAME = 'main_info_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_condition_request():\n",
    "    request = f\"\"\"\n",
    "    WHERE\n",
    "        toDate(event_time) < toDate(scoring_date)\n",
    "    AND \n",
    "        toDate(first_first_trial_consumption_datetime) == \n",
    "        addDays(toDate(scoring_date), -{DAYS_TO_OBSERVE})\n",
    "    AND first_first_trial_consumption_datetime != '0000-00-00 00:00:00'\n",
    "    \"\"\"\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns_NO_limits = [\n",
    "    \"puid\",\n",
    "    \"user_settings_email\",\n",
    "    \"email\",\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"country\",\n",
    "    \"city\",\n",
    "    'general_interests',\n",
    "    'channel',\n",
    "    'search_phrase'\n",
    "]\n",
    "\n",
    "string_columns_ONLY_in_day_use = [\n",
    "    \"cloud_id\",\n",
    "    \"ba_state\",\n",
    "    \"ba_type\",\n",
    "    \"ba_usage_status\",\n",
    "    \"ba_person_type\",\n",
    "    \"is_fraud\",\n",
    "    \"is_robot\",\n",
    "    \"ba_payment_cycle_type\",\n",
    "    \"grant_sources\",\n",
    "    'segment',\n",
    "    'master_account_id',\n",
    "    'account_name',\n",
    "    'first_first_paid_consumption_datetime',\n",
    "    \"os\",\n",
    "    \"device_model\",\n",
    "    \"device_type\",\n",
    "    \"ad_block\",\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    \"hits\",\n",
    "    \"total_visits\",\n",
    "    \"mobile_phone_vendor\",\n",
    "    'income',\n",
    "    'is_corporate_card'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_core_req(string_columns_NO_limits, string_columns_ONLY_in_day_use, numeric_columns):\n",
    "    \"\"\"\n",
    "    Создание таблицы с текущими на момент даты скоринга значениями столбцов из  columns\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    string_columns : List[str]\n",
    "        Столбцы, в которых данные храняться в виде string \n",
    "        (или нужно работать с данными в виде string)\n",
    "        Берется последняя не пустая запись по времени до scoring_date \n",
    "        и выдается как ответ\n",
    "    numeric_columns : List[str]\n",
    "        Столбцы, в которых данные храняться в виде числа\n",
    "        По ним возвращается максимум\n",
    "    Возвращает\n",
    "    -------\n",
    "    request: str\n",
    "        Clickhouse запрос с столбцами из \n",
    "        string_columns + numeric_columns + billing_account_id + scoring_date (из dates),\n",
    "        При этом смотрятся только те юзеры, для которых прошло ровно DAYS_TO_OBSERVE дней \n",
    "        с начала first_first_trial_consumption_datetime до одной из дат в dates\n",
    "    \"\"\"\n",
    "    string_no_limits_part_req = \"\"\n",
    "    for column in string_columns_NO_limits:\n",
    "        string_no_limits_part_req += f\"\"\"    \n",
    "        argMax({column}, \n",
    "        if(CAST({column} as String) != '' \n",
    "            AND \n",
    "            CAST({column} as String) != '[]', event_time, '')) as {column},\\n\"\"\"\n",
    "        \n",
    "    string_day_use_part_req = \"\"\n",
    "    for column in string_columns_ONLY_in_day_use:\n",
    "        string_day_use_part_req += f\"\"\"    \n",
    "        argMax(if (event == 'day_use', CAST({column} as String), ''), \n",
    "        if(if (event == 'day_use', CAST({column} as String), '') != '' \n",
    "           AND \n",
    "           if (event == 'day_use', CAST({column} as String), '') != '[]', event_time, '')) as {column},\\n\"\"\"\n",
    "    \n",
    "    numeric_part_req = \"\"\n",
    "    for column in numeric_columns:\n",
    "        numeric_part_req += f\"\"\"    max(if (event == 'day_use', {column}, 0)) as {column},\\n\"\"\"\n",
    "\n",
    "    core_req = f\"\"\"\n",
    "SELECT\n",
    "    {string_no_limits_part_req}\n",
    "    {string_day_use_part_req}\n",
    "    {numeric_part_req}\n",
    "    billing_account_id,\n",
    "    addDays(toDate(first_first_trial_consumption_datetime), {DAYS_TO_OBSERVE}) as scoring_date\n",
    "FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "{get_main_condition_request()}\n",
    "GROUP BY billing_account_id, scoring_date\n",
    "    \"\"\"\n",
    "    return core_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_company_by_name_req():\n",
    "    column_types.add('is_company_by_name:binary')\n",
    "    company_attributes_in_name = ['.ru',\n",
    "                                  '.com',\n",
    "                                  'коворкинг',\n",
    "                                  'компания',\n",
    "                                  'company',\n",
    "                                  'ooo',\n",
    "                                  'oao',\n",
    "                                  'оао',\n",
    "                                  'ооо',\n",
    "                                  'ао',\n",
    "                                  'ao',\n",
    "                                  'веб',\n",
    "                                  'группа']\n",
    "    company_attributes_in_name = [f\"lowerUTF8(account_name) like '%{name}%'\" \n",
    "                                  for name in company_attributes_in_name]\n",
    "    adding_text = \"OR \".join(company_attributes_in_name)\n",
    "    part_req  = f\"\"\"\n",
    "    if({adding_text}, 1, 0) as is_company_by_name\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def is_company_req():\n",
    "    column_types.add('is_company:binary')\n",
    "    part_req  = f\"\"\"\n",
    "    if(is_company_by_name == 1 or is_corporate_card == 1 \n",
    "    or ba_person_type like '%company%', 1, 0) as is_company\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def is_already_paid():\n",
    "    column_types.add('is_already_paid:binary')\n",
    "    part_req  = f\"\"\"\n",
    "    if(first_first_paid_consumption_datetime != '0000-00-00 00:00:00'\n",
    "       and\n",
    "       toDate(first_first_paid_consumption_datetime) < toDate(scoring_date), 1, 0) as is_already_paid\n",
    "    \"\"\"\n",
    "    return part_req\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_master_account_id_req():\n",
    "    column_types.add('has_master_account_id:binary')\n",
    "    part_req  = f\"\"\"\n",
    "    if(master_account_id != '', 1, 0) as has_master_account_id\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def grant_sources_req():\n",
    "    column_types.add('grant_sources_st:binary')\n",
    "    column_types.add('grant_sources_default:binary')\n",
    "    column_types.add('grant_sources_offer:binary')\n",
    "    column_types.add('grant_sources_policy:binary')\n",
    "    part_req  = f\"\"\"\n",
    "    if(grant_sources like '%ST%', 1, 0) as grant_sources_st,\n",
    "    if(grant_sources like '%default%', 1, 0) as grant_sources_default,\n",
    "    if(grant_sources like '%offer%', 1, 0) as grant_sources_offer,\n",
    "    if(grant_sources like '%policy%', 1, 0) as grant_sources_policy\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def from_desktop_req():\n",
    "    column_types.add('from_desktop:binary')\n",
    "    part_req  = f\"\"\"\n",
    "    if(device_type like '%desktop%', 1, 0) as from_desktop\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def os_req():\n",
    "    column_types.add('os:category')\n",
    "    part_req  = f\"\"\"\n",
    "    if (os != '', splitByChar(' ', assumeNotNull(os))[1], '') as os\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def usage_status_req():\n",
    "    column_types.add('usage_status:category')\n",
    "    part_req  = f\"\"\"\n",
    "    if(ba_usage_status == '', 'trial', ba_usage_status) as usage_status\n",
    "    \"\"\"\n",
    "    return part_req\n",
    "\n",
    "def person_type_req():\n",
    "    column_types.add('person_type:category')\n",
    "    part_req  = f\"\"\"\n",
    "    multiIf(ba_person_type == 'switzerland_nonresident_company', \n",
    "            'company',\n",
    "            ba_person_type == '', \n",
    "            'individual',\n",
    "            ba_person_type) as person_type\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_req():\n",
    "    column_types.add('age:category')\n",
    "    column_types.add('sex:category')\n",
    "    column_types.add('ba_type:category')\n",
    "    column_types.add('is_fraud:binary')\n",
    "    column_types.add('device_type:category')\n",
    "    column_types.add('ad_block:category')\n",
    "    column_types.add('is_robot:category')\n",
    "    column_types.add('segment:category')\n",
    "    column_types.add('income:category')\n",
    "    column_types.add('hits:numeric')\n",
    "    column_types.add('mobile_phone_vendor:numeric')\n",
    "    column_types.add('total_visits:numeric')\n",
    "    column_types.add('general_interests:json__30')\n",
    "    #column_types.add('account_name:category')\n",
    "    part_req  = f\"\"\"\n",
    "    age,\n",
    "    sex,\n",
    "    ba_type,\n",
    "    is_fraud,\n",
    "    device_type,\n",
    "    ad_block,\n",
    "    is_robot,\n",
    "    channel,\n",
    "    segment,\n",
    "    general_interests,\n",
    "    hits,\n",
    "    total_visits,\n",
    "    mobile_phone_vendor,\n",
    "    income,\n",
    "    account_name\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_req():\n",
    "    column_types.add('state:category')\n",
    "    part_req  = f\"\"\"\n",
    "    multiIf(ba_state == 'suspended' or ba_state == 'inactive' or ba_state == 'deleted', \n",
    "            'suspended_now',\n",
    "            ba_state == 'payment_required' or ba_state == 'payment_not_confirmed',\n",
    "            'payment_problem',\n",
    "            ba_state) as state\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_req():\n",
    "    column_types.add('region:category')\n",
    "    part_req  = f\"\"\"\n",
    "    multiIf(city == 'Москва', 'Moscow',\n",
    "                city == 'Санкт-Петербург', 'Saint Petersburg',\n",
    "                country == 'Россия', 'Russia', \n",
    "                isNotNull(country), 'Other countries',\n",
    "                'undefined') as region\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_phrase_req():\n",
    "    column_types.add('search_phrase:category')\n",
    "    part_req  = f\"\"\"\n",
    "    multiIf(search_phrase == 'yandex' or search_phrase == 'яндекс', \n",
    "    'yandex_cloud_direct_search', \n",
    "    search_phrase == '', '{EMPTY_TYPE}',\n",
    "    'not_direct_search_type') as search_phrase\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_features_req():\n",
    "    column_types.add('is_yandex_email:binary')\n",
    "    column_types.add('is_corporate_email:binary')\n",
    "    column_types.add('is_equal_user_settings_email_and_email:binary')\n",
    "    part_req = \"\"\"\n",
    "    multiIf(user_settings_email LIKE '%@yandex.%' OR user_settings_email LIKE '%@ya.%', 1, 0) \n",
    "    AS is_yandex_email,\n",
    "    multiIf(match(user_settings_email, \n",
    "    '.*@yandex\\..*|.*@ya\\..*|.*@gmail\\..*|.*@mail\\..*|.*@tut\\..*|.*@linqcorp\\..*'), \n",
    "    0, 1) AS is_corporate_email,\n",
    "    if (user_settings_email == email, 1, 0) as is_equal_user_settings_email_and_email\n",
    "    \"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_value_preprocess():\n",
    "    req = \"\"\n",
    "    for column_type in column_types:\n",
    "        column, curr_type = column_type.split(\":\")\n",
    "        if \"category\" == curr_type:\n",
    "            req += f\"\"\"lowerUTF8(if(\n",
    "            CAST({column} as String) == '', '{EMPTY_TYPE}', \n",
    "            replaceAll(CAST({column} as String), ' ', '_')\n",
    "            )) as {column},\\n\"\"\"\n",
    "        else:\n",
    "            req += f'{column},\\n'\n",
    "    return req[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_changer(x):\n",
    "    if x == '':\n",
    "        return '[]'\n",
    "    if not isinstance(ast.literal_eval(x), list):\n",
    "        return f'[{x}]'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_common_information_scoring_table(request_texts_array):\n",
    "    core_req = get_core_req(string_columns_NO_limits, string_columns_ONLY_in_day_use, numeric_columns)\n",
    "    func_requests = \", \".join(request_texts_array)\n",
    "    \n",
    "    full_req = f\"\"\"\n",
    "        SELECT\n",
    "            {last_value_preprocess()},\n",
    "            billing_account_id,\n",
    "            scoring_date\n",
    "        FROM (\n",
    "            SELECT\n",
    "                {func_requests},\n",
    "                billing_account_id,\n",
    "                scoring_date\n",
    "            FROM ({core_req})\n",
    "        )\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\".encode('utf-8')\n",
    "    #print(full_req.decode('utf-8'))\n",
    "    df = lib.execute_query(full_req)\n",
    "    df['ad_block'] = df['ad_block'].astype(str)\n",
    "    df['income'] = df['income'].astype(str)\n",
    "    df['general_interests'] = df['general_interests'].apply(\n",
    "        lambda x: json_changer(x)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_types(column_types):\n",
    "    rows = []\n",
    "    for column_type in column_types:\n",
    "        column, current_type = column_type.split(':')\n",
    "        rows.append([column, current_type, TABLE_NAME])\n",
    "    type_df = pd.DataFrame(np.matrix(rows), columns=['column_name', 'type',\n",
    "                                                     'table_name'])\n",
    "    lib.save_table('type_table', \"//home/cloud_analytics/scoring_v2/data_tables\", \n",
    "                   type_df, append=True)\n",
    "\n",
    "\n",
    "def add_table_to_model_to_observe():\n",
    "    tables_df = pd.DataFrame([TABLE_NAME], columns=['table_names'])\n",
    "    lib.save_table('table_names_for_scoring_model', \n",
    "               \"//home/cloud_analytics/scoring_v2/data_tables\", \n",
    "               tables_df, append=True)\n",
    "    \n",
    "\n",
    "def check_types_correspondence(df, column_types):\n",
    "    req = \"\"\"\n",
    "    SELECT\n",
    "        type,\n",
    "        checker_function\n",
    "    FROM \"//home/cloud_analytics/scoring_v2/data_tables/column_type_description\"\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    type_df = lib.execute_query(req)\n",
    "\n",
    "    checker_functions = {}\n",
    "    for func_str in type_df['checker_function']:\n",
    "        exec(func_str.replace(\"\\\\n\", '\\n'), checker_functions)\n",
    "    \n",
    "    assert len(df.columns) == len(column_types) + 2, \\\n",
    "    'difference in number of columns in dataframe and in column_types, '\n",
    "    f'{len(column_types) + 2 - len(df.columns)}'\n",
    "    \n",
    "    for column_type in column_types:\n",
    "        column, curr_type = column_type.split(\":\")\n",
    "        curr_function_name = curr_type.split(\"__\")[0]\n",
    "        if checker_functions.get(curr_function_name + \"_checker\") is None:\n",
    "            assert False, f\"no type {curr_function_name}\"\n",
    "        assert checker_functions[curr_function_name + \"_checker\"](df, column),\\\n",
    "        f'{curr_function_name} check failed for column {column}'\n",
    "        \n",
    "\n",
    "def save_all_results(df):\n",
    "    check_types_correspondence(df, column_types)\n",
    "    lib.save_table(TABLE_NAME, \"//home/cloud_analytics/scoring_v2/data_tables\", df)\n",
    "    save_types(column_types)\n",
    "    add_table_to_model_to_observe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_texts_array = [\n",
    "            is_company_by_name_req(),\n",
    "            has_master_account_id_req(),\n",
    "            email_features_req(), search_phrase_req(),\n",
    "            region_req(), state_req(), simple_req(), person_type_req(),\n",
    "            usage_status_req(), grant_sources_req(), \n",
    "            from_desktop_req(), os_req(), is_company_req(), is_already_paid()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_information_df = make_common_information_scoring_table(request_texts_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib.save_table(TABLE_NAME, \"//home/cloud_analytics/scoring_v2/data_tables\", main_information_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_results(main_information_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
