{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from dateutil.parser import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import chain\n",
    "import yt.wrapper as yt \n",
    "os.chdir('/Users/lunin-dv/Desktop/Library/')\n",
    "import importlib\n",
    "import my_library as lib\n",
    "import operator\n",
    "import re\n",
    "importlib.reload(lib)\n",
    "os.chdir('/Users/lunin-dv/Desktop/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_before(table_name):\n",
    "    if yt.row_count(\"//home/cloud_analytics/emailing/sender/\" + table_name) == 0:\n",
    "        yt.copy(\"//home/cloud_analytics/emailing/sender_copy/\" + table_name,\n",
    "                \"//home/cloud_analytics/emailing/sender/\" + table_name,\n",
    "                force=True)\n",
    "        print('saved')\n",
    "copy_before(\"Upsell-1-nurture_stream-OLD\")\n",
    "copy_before(\"Upsell-1-nurture_stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Общая информация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_req = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM \"//home/cloud_analytics/emailing/sender/drop_list\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "dropped_emails = lib.execute_query(drop_req)\n",
    "dropped_emails = set(dropped_emails['email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    billing_account_id,\n",
    "    lower(user_settings_email) as email,\n",
    "    puid,\n",
    "    event_time as console_regstration_date,\n",
    "    multiIf(first_ba_created_datetime = '0000-00-00 00:00:00', '',\n",
    "            first_ba_created_datetime) as ba_created,\n",
    "    \n",
    "    if (first_first_paid_consumption_datetime == '0000-00-00 00:00:00', '',\n",
    "        first_first_paid_consumption_datetime) as first_paid_datetime,\n",
    "    ba_usage_status as usage_status,\n",
    "    ba_state,\n",
    "    is_isv,\n",
    "    mail_feature,\n",
    "    mail_info,\n",
    "    mail_promo,\n",
    "    language,\n",
    "    segment,\n",
    "    modulo(toInt64(puid), 100) as group_index,\n",
    "    toDate(NOW()) - toDate(first_first_paid_consumption_datetime) as\n",
    "    days_since_first_paid_consumption\n",
    "FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\" as a\n",
    "ANY LEFT JOIN(\n",
    "    SELECT\n",
    "        passport_uid as puid,\n",
    "        user_settings_language as language\n",
    "    FROM \"//home/cloud_analytics/import/iam/cloud_owners_history\"\n",
    ") as b\n",
    "ON a.puid == b.puid\n",
    "WHERE\n",
    "    (\n",
    "        (event == 'cloud_created' and  billing_account_id in\n",
    "         (SELECT DISTINCT billing_account_id \n",
    "          FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "          WHERE event == 'cloud_created')\n",
    "         )\n",
    "      OR\n",
    "        (event == 'ba_created' and  billing_account_id not in\n",
    "         (SELECT DISTINCT billing_account_id \n",
    "          FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "          WHERE event == 'cloud_created')\n",
    "        )\n",
    "    )\n",
    "AND puid != ''\n",
    "AND billing_account_id != ''\n",
    "AND email != ''\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "main_df = lib.execute_query(req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mdb types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_dict = {'mssql':['mssql',\n",
    "                     'ms sql',\n",
    "                     'f2emdc91af8p8cpm4tkr',\n",
    "                     'f2e8cuqa26h8la6c33sq',\n",
    "                     'f2eovjk4uopcfrsm2e1g'],\n",
    "    'postgresql': ['postgresql'],\n",
    "    'mysql': ['mysql'],\n",
    "    'clickhouse': ['clickhouse'],\n",
    "    'mongodb': ['mongodb'],\n",
    "    'data-proc': ['data-proc', 'data proc'],\n",
    "    'yandex databases': ['ydb', 'yandex database'],\n",
    "    'redis': ['redis'],\n",
    "    'kafka': ['kafka'],\n",
    "    'elastic': ['elastic']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = [elem for elem in mdb_dict.values()]\n",
    "matching = str(list(chain.from_iterable(matching)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_requests(mdb_dict, event_col = 'event'):\n",
    "    part_req = \"\"\n",
    "    for key in mdb_dict:\n",
    "        part_req += f\"\"\"if(multiMatchAny({event_col}, {str(mdb_dict[key])}), '{key}', '') as \"{key}\",\\n\"\"\"\n",
    "    \n",
    "    part_req += '\"' + '\"||\"'.join(mdb_dict.keys()) + '\" as result,\\n'\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    puid,\n",
    "    groupUniqArray(result) as mdb_create_clusters_links\n",
    "FROM (\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        {make_if_requests(mdb_dict)}\n",
    "        event,\n",
    "        puid\n",
    "    FROM \"//home/cloud_analytics/import/console_logs/events\"\n",
    "    WHERE  multiMatchAny(event, ['create-cluster', 'create-instance', 'cluster-create', 'create-database'])\n",
    "    AND multiMatchAny(event, {matching})\n",
    "    AND event like '%console%'\n",
    "    AND response >= '200'\n",
    "    AND response < '300'\n",
    "    AND toDate(replaceRegexpOne(timestamp, '[.].*', '')) >= addDays(toDate(NOW()), -30)\n",
    ")\n",
    "GROUP BY puid\n",
    "HAVING puid != ''\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['mdb_create_clusters_links'] = df_1['mdb_create_clusters_links'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    puid,\n",
    "    groupUniqArray(result) as mdb_docs_links\n",
    "FROM (\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        {make_if_requests(mdb_dict)}\n",
    "        event,\n",
    "        puid\n",
    "    FROM \"//home/cloud_analytics/import/console_logs/events\"\n",
    "    WHERE  multiMatchAny(event, ['docs'])\n",
    "    AND multiMatchAny(event, {matching})\n",
    "    AND response >= '200'\n",
    "    AND response < '300'\n",
    "    AND toDate(replaceRegexpOne(timestamp, '[.].*', '')) >= addDays(toDate(NOW()), -30)\n",
    ")\n",
    "GROUP BY puid\n",
    "HAVING puid != ''\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['mdb_docs_links'] = df_2['mdb_docs_links'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = mdb_dict.copy()\n",
    "event_dict['1C'] = ['1c']\n",
    "matching = [elem for elem in event_dict.values()]\n",
    "matching = str(list(chain.from_iterable(matching)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_col = 'lower(event_name)'\n",
    "df_3 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    email,\n",
    "    groupUniqArray(result) as mdb_events\n",
    "FROM (\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    {make_if_requests(event_dict, event_col=event_col)}\n",
    "    email\n",
    "FROM \"//home/cloud_analytics/export/marketo/ya_attend_event\"\n",
    "WHERE multiMatchAny({event_col}, {matching})\n",
    "AND toDate(event_date) >= toDate('2020-01-01')\n",
    ")\n",
    "GROUP BY email\n",
    "HAVING email != ''\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")\n",
    "df_3['mdb_events'] = df_3['mdb_events'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "    billing_account_id,\n",
    "    arraySort(arrayDistinct(groupArray(db))) as mdb_data_bases_on_vm\n",
    "FROM \"//home/cloud_analytics/import/network-logs/db-on-vm/data\"\n",
    "WHERE\n",
    "    billing_account_id IS NOT NULL\n",
    "    AND billing_account_id != ''\n",
    "GROUP BY\n",
    "    billing_account_id\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "df_4 = lib.execute_query(req)\n",
    "df_4['mdb_data_bases_on_vm'] = df_4['mdb_data_bases_on_vm'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = lib.execute_query(\"\"\"\n",
    "SELECT\n",
    "    groupUniqArray(dimension_name) as mdb_dimensions,\n",
    "    billing_account_id\n",
    "FROM \"//home/cloud_analytics/kulaga/leads_cube\"\n",
    "WHERE dimension_name in ('Веб-сайт', 'Веб-приложение', '1С хостинг')\n",
    "GROUP BY billing_account_id\n",
    "HAVING hasAny(mdb_dimensions, ['Веб-сайт', 'Веб-приложение', '1С хостинг'])\n",
    "FORMAT TabSeparatedWithNames\"\"\".encode('utf-8'))\n",
    "df_5['mdb_dimensions'] = df_5['mdb_dimensions'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_dict = {'Веб':['web'],\n",
    "                  '1С': ['1C', 'internet-store/bitrix-shop', '1c'],\n",
    "                  'datalens': ['datalens'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    puid,\n",
    "    groupUniqArray(result) as mdb_solutions_links\n",
    "FROM (\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        {make_if_requests(solutions_dict)}\n",
    "        event,\n",
    "        puid\n",
    "    FROM \"//home/cloud_analytics/import/console_logs/events\"\n",
    "    WHERE  multiMatchAny(event, ['infrastructure-management/1c-mssql-windows',\n",
    "                                 'infrastructure-management/1c-postgresql-linux',\n",
    "                                 'internet-store/bitrix-shop',\n",
    "                                 'web/bitrix-website',\n",
    "                                 'web/joomla-postgresql',\n",
    "                                 'web/wordpress-mysql',\n",
    "                                 'solutions/dat alens'])\n",
    "    AND event like '%solutions%'\n",
    "    AND response >= '200'\n",
    "    AND response < '300'\n",
    "    AND toDate(replaceRegexpOne(timestamp, '[.].*', '')) >= addDays(toDate(NOW()), -30)\n",
    ")\n",
    "GROUP BY puid\n",
    "HAVING puid != ''\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\".encode('utf-8'))\n",
    "df_6['mdb_solutions_links'] = df_6['mdb_solutions_links'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Потребление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_dict = {'mssql':['\\.ms.sql\\.'],\n",
    "    'postgresql': ['\\.pg\\.'],\n",
    "    'mysql': ['\\.mysql\\.'],\n",
    "    'clickhouse': ['\\.clickhouse\\.'],\n",
    "    'mongodb': ['\\.mongodb\\.'],\n",
    "    'data-proc': ['\\.dataproc\\.'],\n",
    "    'redis': ['\\.redis\\.'],\n",
    "    'kafka': ['\\.kafka\\.']\n",
    "}\n",
    "matching = [elem for elem in sku_dict.values()]\n",
    "matching = str(list(chain.from_iterable(matching)))\n",
    "matching = matching.replace(\"\\\\\\\\\", '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_req(sku_dict, matching):\n",
    "    part_req = \"\"\n",
    "    for key in sku_dict:\n",
    "        curr_str = str(sku_dict[key]).replace(\"\\\\\\\\\", '\\\\')\n",
    "        part_req += f\"\"\"MAX(if(multiMatchAny(sku_name, {curr_str}), '{key}', '')) as \"{key}\",\\n\"\"\"\n",
    "    \n",
    "    part_req += '''arrayFilter(x -> x != '', [\"''' + \\\n",
    "                '\",\"'.join(sku_dict.keys()) + '\"]) as result,\\n'\n",
    "    part_req += f\"\"\"SUM(IF(multiMatchAny(sku_name, {matching}), trial_consumption, 0)) as trial_mdb_cons,\\n\"\"\"\n",
    "    part_req += f\"\"\"SUM(IF(multiMatchAny(sku_name, {matching}), real_consumption, 0)) as paid_mdb_cons,\\n\"\"\"\n",
    "    return part_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_df = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    billing_account_id,\n",
    "    result as used_mdb_last_month,\n",
    "    trial_mdb_cons,\n",
    "    paid_mdb_cons,\n",
    "    if(paid_mdb_cons < 100, 1, 0) as zero_mdb_paid_consumption,\n",
    "    if(paid_mdb_cons > 2000, 1, 0) as mdb_progress_programm,\n",
    "    is_churned\n",
    "FROM (\n",
    "SELECT\n",
    "    {cons_req(sku_dict, matching)}\n",
    "    billing_account_id,\n",
    "    if (sum(real_consumption + trial_consumption) < 1, 1, 0) as is_churned \n",
    "FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "WHERE toDate(event_time) >= addDays(toDate(NOW()), -30)\n",
    "GROUP BY billing_account_id\n",
    ")\n",
    "FORMAT TabSeparatedWithNames  \n",
    "\"\"\")\n",
    "cons_df['used_mdb_last_month'] = cons_df['used_mdb_last_month'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = [(cons_df, \"billing_account_id\"), \n",
    "          (df_1, 'puid'), (df_2, 'puid'), (df_3, 'email'), \n",
    "          (df_4, 'billing_account_id'), (df_5, 'billing_account_id'), (df_6, 'puid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_table = main_df.copy()\n",
    "for table, key in merged:\n",
    "    mdb_table = pd.merge(mdb_table, table, on=key, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuber_1 = lib.execute_query(\"\"\"\n",
    "SELECT\n",
    "    billing_account_id,\n",
    "    MAX(if(service_name == 'cr', 1, 0)) as is_container_reg_used,\n",
    "    SUM(if(service_name == 'mk8s', real_consumption, 0)) as kuber_cons,\n",
    "    IF(kuber_cons < 2000, 1, 0) as for_kuber_upsell,\n",
    "    IF(kuber_cons < 100, 1, 0) as zero_kuber_paid_consumption\n",
    "FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "WHERE toDate(event_time) >= addDays(toDate(NOW()), -30)\n",
    "GROUP BY billing_account_id\n",
    "FORMAT TabSeparatedWithNames  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuber_2 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    1 as kuber_link,\n",
    "    puid\n",
    "FROM \"//home/cloud_analytics/import/console_logs/events\"\n",
    "WHERE multiMatchAny(event, ['kubernetes'])\n",
    "AND response >= '200'\n",
    "AND response < '300'\n",
    "AND puid != ''\n",
    "AND toDate(replaceRegexpOne(timestamp, '[.].*', '')) >= addDays(toDate(NOW()), -30)\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuber_3 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    1 as kuber_event,\n",
    "    email\n",
    "FROM \"//home/cloud_analytics/export/marketo/ya_attend_event\"\n",
    "WHERE (multiMatchAny(lower(event_name), ['kuber']) \n",
    "or multiMatchAny(event_link, ['events/81', 'events/80', 'events/84']))\n",
    "AND email != ''\n",
    "AND toDate(event_date) >= toDate('2020-01-01')\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kuber_4 = lib.execute_query(f\"\"\"\n",
    "SELECT\n",
    "    ba_id as billing_account_id,\n",
    "    COUNT(DISTINCT node_az) as is_1_az\n",
    "FROM \"//home/cloud_analytics/compute_logs/vm_cube/vm_cube\"\n",
    "GROUP BY billing_account_id\n",
    "HAVING is_1_az == 1\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mergering  kuber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = [(kuber_1, \"billing_account_id\"), \n",
    "          (kuber_2, 'puid'), (kuber_3, 'email'), (kuber_4, 'billing_account_id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_table = mdb_table.copy()\n",
    "for table, key in merged:\n",
    "    all_table = pd.merge(all_table, table, on=key, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table = all_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert main_table.shape[0] == mdb_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_table.replace('[]', '', inplace=True)\n",
    "for col in main_table.columns:\n",
    "    if main_table[col].dtype == 'object':\n",
    "        main_table[col] = main_table[col].fillna('')\n",
    "    else:\n",
    "        if 'zero_' in col or 'for_kuber_upsell' in col or 'churned' in col:\n",
    "            main_table[col] = main_table[col].fillna(1)\n",
    "        else:\n",
    "            main_table[col] = main_table[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert main_table.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_group(row):\n",
    "    if row['is_churned'] == 1:\n",
    "        return \"Churn\"\n",
    "    \n",
    "    if (row['kuber_event'] == 1 or \\\n",
    "       row['is_container_reg_used'] == 1 or row['kuber_link'] == 1):\n",
    "        if row['zero_kuber_paid_consumption'] == 1:\n",
    "            return 'Upsell-Kubernetes-first'\n",
    "        if row['for_kuber_upsell'] == 1:\n",
    "            return 'Upsell-Kubernetes-start'\n",
    "        \n",
    "    mdb_type = ''\n",
    "    if row['mdb_progress_programm'] == 1:\n",
    "        mdb_type = \"Upsell-MDB-progress\"\n",
    "    if row['zero_mdb_paid_consumption'] == 1:\n",
    "        mdb_type = 'Upsell-MDB-first'\n",
    "    if row['zero_mdb_paid_consumption'] == 0 and row['mdb_progress_programm'] == 0:\n",
    "        mdb_type=\"Upsell-MDB-start\"\n",
    "\n",
    "    if row['mdb_create_clusters_links'] != '' or row['mdb_data_bases_on_vm'] != '':\n",
    "        return mdb_type\n",
    "        \n",
    "    experiment = []\n",
    "    if row['mdb_solutions_links'] != '' or row['mdb_dimensions'] != '' or\\\n",
    "       row['mdb_events'] != '' or row['mdb_docs_links'] != '':\n",
    "        experiment.append(mdb_type)\n",
    "\n",
    "    if len(experiment) == 1:\n",
    "        return experiment[0]\n",
    "    elif len(experiment) == 2:\n",
    "        ind = int(np.random.rand() > 0.5)\n",
    "        return experiment[ind]\n",
    "    else:\n",
    "        return 'Upsell-Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Upsell_type'] = df.apply(lambda row: find_group(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125809, 36)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Обновление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_current_table(table_name, path, tables_to_update):\n",
    "    full_path = path + \"/\" + table_name\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \"{full_path}\"\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    old_df = lib.execute_query(req)\n",
    "    if 'sended_mails' in old_df.columns:\n",
    "        old_df['sended_mails'] = old_df['sended_mails'].apply(\n",
    "            lambda x: x.replace(\"\\\\\", \"\"))\n",
    "    \n",
    "    if 'upsell_3_users' in old_df.columns:\n",
    "        old_df.drop(columns = ['upsell_3_users'], inplace=True)\n",
    "    old_df['is_dropped'] = (old_df['email'].isin(dropped_emails)).astype(int)\n",
    "    for table, key in tables_to_update:\n",
    "        old_df = pd.merge(old_df,\n",
    "                          table, on=key, suffixes=('', '_new'), how='left')\n",
    "        \n",
    "    new_cols = []\n",
    "    if 'Upsell_type_new' in old_df.columns:\n",
    "        old_df.drop(columns=['Upsell_type_new'], inplace=True)\n",
    "    for column in old_df.columns:\n",
    "        if \"_new\" == column[-4:]:\n",
    "            new_cols.append(column)\n",
    "            old_column = column[:-4]\n",
    "            old_df[old_column] = old_df[column].copy()\n",
    "    old_df.drop(columns=new_cols, inplace=True)\n",
    "    old_df.dropna(inplace=True)\n",
    "    old_df = old_df.groupby('email').tail(1)\n",
    "    lib.save_table(table_name, path, old_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marketo_previous_req = \"\"\"\n",
    "# SELECT\n",
    "#     DISTINCT\n",
    "#     billing_account_id,\n",
    "#     any(email) as email,\n",
    "#     groupUniqArray(if(mailing_name == 'inapplicable', null, mailing_name)) as sended_mails,\n",
    "#     if (length(sended_mails)  > 0, 'test', 'control') as Group,\n",
    "#     max(if (lower(program_name) like '%-upsell-1%', toDate(event_time), null)) as experiment_date\n",
    "# FROM \"//home/cloud_analytics/cubes/emailing_events/emailing_events\"\n",
    "# WHERE lower(program_name) like '%-upsell-1%'\n",
    "# OR lower(mailing_name) like '%-upsell-1%'\n",
    "# GROUP BY billing_account_id\n",
    "# HAVING isNotNull(experiment_date)\n",
    "# FORMAT TabSeparatedWithNames\n",
    "# \"\"\"\n",
    "# marketo_prev_df = lib.execute_query(marketo_previous_req)\n",
    "# marketo_prev_df['sended_mails'] = marketo_prev_df['sended_mails'].astype(str)\n",
    "# lib.save_table(\"Upsell-1-nurture_stream-OLD\", \"//home/cloud_analytics/emailing/sender\", \n",
    "#                marketo_prev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_update = [(main_df, \"billing_account_id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert main_df.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_current_table(\"Upsell-1-nurture_stream-OLD\",\n",
    "                     \"//home/cloud_analytics/emailing/sender\", \n",
    "                     tables_to_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_current_table(\"Upsell-1-nurture_stream\",\n",
    "                     \"//home/cloud_analytics/emailing/sender\", \n",
    "                     tables_to_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Добавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old Upsell Marketo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketo_previous_req = \"\"\"\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    billing_account_id,\n",
    "    email\n",
    "FROM \"//home/cloud_analytics/cubes/emailing_events/emailing_events\"\n",
    "WHERE lower(program_name) like '%-upsell-1%'\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "marketo_prev_df = lib.execute_query(marketo_previous_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6973, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketo_prev_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old in program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "    DISTINCT\n",
    "        email,\n",
    "        billing_account_id\n",
    "FROM \"//home/cloud_analytics/emailing/sender/Upsell-1-nurture_stream\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "old_df = lib.execute_query(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM \"//home/cloud_analytics/emailing/sender/Upsell-1-nurture_stream\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "old_df = lib.execute_query(req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7447, 39)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = main_df.copy()\n",
    "#print(\"Все пользователи:\", new_table.shape[0])\n",
    "new_table = new_table[\n",
    "    (~new_table['email'].isin(marketo_prev_df['email'])) &\n",
    "    (~new_table['billing_account_id'].isin(marketo_prev_df['billing_account_id']))\n",
    "]\n",
    "#print(\"Все пользователи после удаления тех, кто уже был в старом стриме upsell:\", new_table.shape[0])\n",
    "new_table = new_table[~new_table['email'].isin(dropped_emails)]\n",
    "#print(\"Отказались от рассылок по маркето информации:\", new_table.shape[0])\n",
    "new_table = new_table[\n",
    "    (~new_table['email'].isin(old_df['email'])) &\n",
    "    (~new_table['billing_account_id'].isin(old_df['billing_account_id']))\n",
    "]\n",
    "new_table = new_table[(new_table['is_isv'] == 0) &\n",
    "                      (new_table['first_paid_datetime'] != '')]\n",
    "#print(\"Есть платное потребление, не isv:\", new_table.shape[0])\n",
    "new_table = new_table[(new_table['mail_feature'] == 1) |\n",
    "                      (new_table['mail_info'] == 1) |\n",
    "                      (new_table['mail_promo'] == 1)]\n",
    "#print(\"Есть согласие на рассылку:\", new_table.shape[0])\n",
    "new_table = new_table[new_table['days_since_first_paid_consumption'] >= 10]\n",
    "#print(\"Прошло хотя бы 10 дней с первого платного потребления:\", new_table.shape[0])\n",
    "new_table['Group'] = new_table['puid'].astype(int).apply(\n",
    "    lambda x: 'control' if x % 100 >= 35 and x % 100 <= 44 else 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table['experiment_date'] = lib.get_current_date_as_str()\n",
    "new_table['is_dropped'] = (new_table['email'].isin(dropped_emails)).astype(int)\n",
    "new_table = new_table.groupby('email').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 39)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_table(\"Upsell-1-nurture_stream\", \"//home/cloud_analytics/emailing/sender\", \n",
    "               new_table, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_after(table_name):\n",
    "    if yt.row_count(\"//home/cloud_analytics/emailing/sender/\" + table_name) != 0:\n",
    "        yt.copy(\"//home/cloud_analytics/emailing/sender/\" + table_name,\n",
    "                \"//home/cloud_analytics/emailing/sender_copy/\" + table_name, force=True)\n",
    "copy_after(\"Upsell-1-nurture_stream-OLD\")\n",
    "copy_after(\"Upsell-1-nurture_stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 стримов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_part = \"//home/cloud_analytics/emailing/sender_copy/\" \n",
    "old_name = \"Upsell-1-nurture_stream-OLD\"\n",
    "new_name = \"Upsell-1-nurture_stream\"\n",
    "\n",
    "\n",
    "def split_in_tables(name):\n",
    "    path = common_part + name\n",
    "    final_common_df = lib.execute_query(f\"\"\"\n",
    "    SELECT\n",
    "        billing_account_id,\n",
    "        email,\n",
    "        experiment_date,\n",
    "        Group,\n",
    "        Upsell_type\n",
    "    FROM \"{path}\"\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\")\n",
    "    for exp_name, table in final_common_df.groupby('Upsell_type'):\n",
    "        lib.save_table(name + \"_\" + exp_name, \"//home/cloud_analytics/emailing/sender\",  table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_in_tables(old_name)\n",
    "split_in_tables(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
