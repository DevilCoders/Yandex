{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "import gc\n",
    "import pandas as pd\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "os.chdir('/Users/lunin-dv/Desktop/Library/')\n",
    "import importlib\n",
    "import my_library as lib\n",
    "import ast\n",
    "importlib.reload(lib)\n",
    "os.chdir('/Users/lunin-dv/Desktop/data/Upsell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt.wrapper as yt\n",
    "import numpy as np, statsmodels.stats.api as sms\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARKETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marketo_df(name, table_name):\n",
    "    path = \"//home/cloud_analytics/emailing/experiments/upsell/all_experiments/\" + name\n",
    "    try:\n",
    "        # Upsell-stream\n",
    "        req = f\"\"\"\n",
    "        SELECT\n",
    "            '{table_name}' as table_name,\n",
    "            billing_account_id,\n",
    "            billing_account_id as old_billing_account_id,\n",
    "            email,\n",
    "            Group,\n",
    "            all_experiment_size,\n",
    "            experiment_date\n",
    "        FROM \"{path}\" as a,\n",
    "        (\n",
    "        SELECT\n",
    "           count(*) as all_experiment_size \n",
    "        FROM \"{path}\"\n",
    "        ) as b\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\"\n",
    "        df = lib.execute_query(req)\n",
    "        return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # компания на новых клиентов\n",
    "        req = f\"\"\"\n",
    "        SELECT\n",
    "            '{table_name}' as table_name,\n",
    "            old_billing_account_id,\n",
    "            billing_account_id,\n",
    "            email,\n",
    "            'not applicable' as Group,\n",
    "            all_experiment_size\n",
    "        FROM \"{path}\" as a,\n",
    "        (\n",
    "        SELECT\n",
    "           count(*) as all_experiment_size \n",
    "        FROM \"{path}\"\n",
    "        ) as b\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\"\n",
    "        df = lib.execute_query(req)\n",
    "        df['old_billing_account_id'] = df['old_billing_account_id'].fillna('')\n",
    "        return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        # обычная компания без появления новых клиентов\n",
    "        req = f\"\"\"\n",
    "        SELECT\n",
    "            '{table_name}' as table_name,\n",
    "            billing_account_id,\n",
    "            billing_account_id as old_billing_account_id,\n",
    "            email,\n",
    "            Group,\n",
    "            all_experiment_size\n",
    "        FROM \"{path}\" as a,\n",
    "        (\n",
    "        SELECT\n",
    "           count(*) as all_experiment_size \n",
    "        FROM \"{path}\"\n",
    "        ) as b\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\"\n",
    "        df = lib.execute_query(req)\n",
    "        return df\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # обычная компания без появления новых клиентов и без группы\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        '{table_name}' as table_name,\n",
    "        billing_account_id,\n",
    "        billing_account_id as old_billing_account_id,\n",
    "        email,\n",
    "        'not applicable' as Group,\n",
    "        all_experiment_size\n",
    "    FROM \"{path}\" as a,\n",
    "    (\n",
    "        SELECT\n",
    "           count(*) as all_experiment_size \n",
    "        FROM \"{path}\"\n",
    "    ) as b\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    df = lib.execute_query(req)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table(path, table_name):\n",
    "    # Появился ли биллинг\n",
    "    full_path = path + '/' + table_name\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \"{full_path}\"\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    df = lib.execute_query(req)\n",
    "    if 'billing_account_id' in df.columns:\n",
    "        df = df.drop(columns = [\"billing_account_id\"])\n",
    "    req = \"\"\"\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "            argMax(billing_account_id, event_time) as billing_account_id,\n",
    "            user_settings_email as email\n",
    "    FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\"\n",
    "    GROUP BY user_settings_email\n",
    "    HAVING billing_account_id != ''\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    accs = lib.execute_query(req)\n",
    "    df = pd.merge(df, accs, on='email', how='left')\n",
    "    lib.save_table(table_name, path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table_from_marketo(path, table_name, curr_row):\n",
    "    # По тем, кто уже был в какой-то компании\n",
    "    curr_mails = curr_row['mail_name']\n",
    "    good_mails_req = \"mailing_name like '%\" +\\\n",
    "    \"%'\\nOR\\nmailing_name like '%\".join(list(set(curr_mails))) + \"%'\"\n",
    "    mailing_req = f\"\"\"\n",
    "    SELECT\n",
    "        billing_account_id,\n",
    "        any(email) as email,\n",
    "        'not applicable' as Group,\n",
    "        billing_account_id as old_billing_account_id\n",
    "    FROM \"//home/cloud_analytics_test/cubes/emailing/cube\"\n",
    "    WHERE ({good_mails_req})\n",
    "    AND isNotNull(delivery_time)\n",
    "    GROUP BY billing_account_id\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    df = lib.execute_query(mailing_req)\n",
    "    lib.save_table(table_name, \n",
    "                   path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "   *\n",
    "FROM \"//home/cloud_analytics/emailing/experiments/upsell/all_experiments/marketo_upsell_tables\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "int_name_df = lib.execute_query(req)\n",
    "int_name_df['mail_name'] =\\\n",
    "int_name_df['mail_name'].apply(lambda x: ast.literal_eval(x.replace(\"\\\\\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"//home/cloud_analytics/emailing/experiments/upsell/all_experiments\"\n",
    "for table_name in int_name_df[int_name_df['need_to_update_before_starting'] == 1]['path']:\n",
    "    update_table(path, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"//home/cloud_analytics/emailing/experiments/upsell/all_experiments\"\n",
    "for table_name in int_name_df[int_name_df['need_to_update_before_starting'] == 2]['path']:\n",
    "    curr_row = int_name_df[int_name_df['path'] == table_name].iloc[0]\n",
    "    update_table_from_marketo(path, curr_row['path'], curr_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mails = []\n",
    "for array in int_name_df['mail_name']:\n",
    "    all_mails += array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_mails_req = \"mailing_name like '%\" +\\\n",
    "    \"%'\\nOR\\nmailing_name like '%\".join(list(set(all_mails))) + \"%'\"\n",
    "mailing_req = f\"\"\"\n",
    "SELECT\n",
    "    billing_account_id,\n",
    "    mailing_name,\n",
    "    if (isNotNull(max(open_time)), 1, 0) as open_letter,\n",
    "    if (isNotNull(max(click_time)), 1, 0) as click_letter,\n",
    "    max(delivery_time) as experiment_date\n",
    "FROM \"//home/cloud_analytics_test/cubes/emailing/cube\"\n",
    "WHERE ({good_mails_req})\n",
    "AND isNotNull(delivery_time)\n",
    "GROUP BY billing_account_id, mailing_name\n",
    "HAVING isNotNull(experiment_date)\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "\n",
    "mail_df = lib.execute_query(mailing_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_mail(x, curr_names):\n",
    "    for name in curr_names:\n",
    "        if not pd.isnull(x) and name in x:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mail_df_by_many_mails_into_one(curr_mail_df):\n",
    "    grouped = curr_mail_df.groupby(\"billing_account_id\")\n",
    "    res = grouped.apply(lambda x: x.sort_values(['experiment_date'])\\\n",
    "              .sort_values(['open_letter'], ascending=False).head(1))\n",
    "    res['billing_account_id'] = np.array(res.index.to_list()).T[0]\n",
    "    res.index = np.arange(0, len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for _, row in int_name_df.iterrows():\n",
    "    curr_df = marketo_df(row['path'], row['table_name'])\n",
    "    curr_df = curr_df[~curr_df['billing_account_id'].isna()]\n",
    "    curr_names = row['mail_name']\n",
    "    curr_mail_df = mail_df[mail_df[\"mailing_name\"].apply(lambda x: is_good_mail(x, \n",
    "                                                                                curr_names))]\n",
    "    curr_mail_df = group_mail_df_by_many_mails_into_one(curr_mail_df)\n",
    "    # test group\n",
    "    test_df = curr_df[(curr_df['Group'] == 'test') |\n",
    "                           (curr_df['Group'] == 'not applicable')]\n",
    "    if 'experiment_date' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['experiment_date'])\n",
    "    test_df = pd.merge(test_df,curr_mail_df[['billing_account_id', 'experiment_date', \n",
    "                                             'open_letter', 'click_letter']], \n",
    "                       on = 'billing_account_id', how='inner')\n",
    "    \n",
    "    #date\n",
    "    test_df['experiment_date'] = test_df['experiment_date'].apply(\n",
    "        lambda x: lib.date_to_string(parse(x)))\n",
    "    control_date = test_df['experiment_date'].min()\n",
    "    columns = [\"table_name\", 'old_billing_account_id',\n",
    "               \"billing_account_id\", \"Group\", \"experiment_date\", \n",
    "               \"open_letter\", \"click_letter\", 'all_experiment_size']\n",
    "    test_df = test_df[columns]\n",
    "\n",
    "    final_table = test_df\n",
    "    \n",
    "    if 'control' in curr_df[\"Group\"].unique():\n",
    "        control_df = curr_df[curr_df[\"Group\"] == 'control']\n",
    "        if 'experiment_date' not in control_df.columns:\n",
    "            control_df.loc[:, 'experiment_date'] = [control_date] * len(control_df)\n",
    "        \n",
    "        control_df.loc[:, 'open_letter'] = [0] * len(control_df)\n",
    "        control_df.loc[:, 'click_letter'] = [0] * len(control_df)\n",
    "        control_df = control_df[columns]\n",
    "        final_table = lib.concatenate_tables([test_df, control_df])\n",
    "    \n",
    "    dfs.append(final_table)\n",
    "    print(row['table_name'], test_df.shape, final_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketo_main_df = lib.concatenate_tables(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рассылятор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_good_mail(x, curr_names, num_to_check):\n",
    "    cnt = 0\n",
    "    for name in curr_names:\n",
    "        if name in x:\n",
    "            cnt += 1\n",
    "    if cnt >= num_to_check:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = \"\"\"\n",
    "SELECT\n",
    "   *\n",
    "FROM \"//home/cloud_analytics/emailing/sender/upsell_tables\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "int_name_df = lib.execute_query(req)\n",
    "int_name_df['mail_name'] =\\\n",
    "int_name_df['mail_name'].apply(lambda x: ast.literal_eval(x.replace(\"\\\\\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = list(int_name_df['mail_name'])\n",
    "tags =  set([item for sublist in tags for item in sublist])\n",
    "\n",
    "good_mails_req = \"tags == '\" +\\\n",
    "    \"'\\nOR\\n tags == '\".join(list(set(tags))) + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mails():\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "            email,\n",
    "            tags,\n",
    "            event,\n",
    "            unixtime,\n",
    "            toDate(unixtime / 1000) as send_time,\n",
    "            halfMD5(email || '_' || message_id) as key\n",
    "    FROM \"//home/cloud_analytics/import/emails/emails_delivery_clicks\"\n",
    "    WHERE source == 'sender'\n",
    "    and event in ('click', 'px', 'send')\n",
    "    and ({good_mails_req})\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    mail_df = lib.execute_query(req)\n",
    "    mail_df['key'] = mail_df['key'].astype(str)\n",
    "    lib.save_table(\"emailing_upsell_tmp\", '//home/cloud_analytics/lunin-dv/tmp', mail_df)\n",
    "    \n",
    "    mail_df = lib.execute_query(\"\"\"\n",
    "    SELECT\n",
    "        email,\n",
    "        experiment_date,\n",
    "        open_letter,\n",
    "        click_letter,\n",
    "        mailing_name\n",
    "    FROM (\n",
    "        SELECT\n",
    "            email,\n",
    "            max(if (event == 'send', send_time, null)) as experiment_date,\n",
    "            max(if (event == 'px', 1, 0)) as open_letter,\n",
    "            max(if (event == 'click', 1, 0)) as click_letter,\n",
    "            groupUniqArray(tags) as mailing_name\n",
    "        FROM \"//home/cloud_analytics/lunin-dv/tmp/emailing_upsell_tmp\"\n",
    "        GROUP BY email, key\n",
    "        HAVING toDate(experiment_date) > toDate('2020-01-01')\n",
    "    ) as sender\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\")\n",
    "    return mail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_df = get_mails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_df['open_letter'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_df(name, table_name):\n",
    "    path = \"//home/cloud_analytics/emailing/sender/\"\n",
    "    try:\n",
    "        req = f\"\"\"\n",
    "        SELECT\n",
    "            email,\n",
    "            billing_account_id,\n",
    "            billing_account_id as old_billing_account_id,\n",
    "            time as experiment_date,\n",
    "            group as Group,\n",
    "            '{table_name}' as table_name,\n",
    "            all_experiment_size\n",
    "        FROM \"{path + name}\" as a,\n",
    "        (\n",
    "            SELECT\n",
    "               count(*) as all_experiment_size \n",
    "            FROM \"{path + name}\"\n",
    "        ) as b\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\"\n",
    "        df = lib.execute_query(req)\n",
    "    except Exception:\n",
    "        req = f\"\"\"\n",
    "        SELECT\n",
    "            email,\n",
    "            billing_account_id,\n",
    "            billing_account_id as old_billing_account_id,\n",
    "            experiment_date,\n",
    "            Group,\n",
    "            '{table_name}' as table_name,\n",
    "            all_experiment_size\n",
    "        FROM \"{path + name}\" as a,\n",
    "        (\n",
    "            SELECT\n",
    "               count(*) as all_experiment_size \n",
    "            FROM \"{path + name}\"\n",
    "        ) as b\n",
    "        FORMAT TabSeparatedWithNames\n",
    "        \"\"\"\n",
    "        df = lib.execute_query(req)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_mail_df_by_many_mails_into_one(curr_mail_df):\n",
    "    grouped = curr_mail_df.groupby(\"email\")\n",
    "    res = grouped.apply(lambda x: x.sort_values(['experiment_date']).head(1))\n",
    "\n",
    "    col = 'open_letter'\n",
    "    res = pd.merge(res.drop(columns =[col]), \n",
    "         pd.DataFrame(grouped.apply(lambda x: x[col].max()), columns=[col]),\n",
    "         left_index=True, right_index=True)\n",
    "    \n",
    "    col = 'click_letter'\n",
    "    res = pd.merge(res.drop(columns =[col]), \n",
    "         pd.DataFrame(grouped.apply(lambda x: x[col].max()), columns=[col]),\n",
    "         left_index=True, right_index=True)\n",
    "    \n",
    "    res['email'] = np.array(res.index.to_list()).T[0]\n",
    "    res.index = np.arange(0, len(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for _, row in int_name_df.iterrows():\n",
    "    curr_df = continuous_df(row['path'], row['table_name'])\n",
    "    curr_names = row['mail_name']\n",
    "    num_to_check = row['min_num_of_common_tags']\n",
    "    curr_mail_df = mail_df[mail_df[\"mailing_name\"].apply(lambda x: is_good_mail(x, \n",
    "                                                                                curr_names,\n",
    "                                                                                num_to_check))]\n",
    "    curr_mail_df = group_mail_df_by_many_mails_into_one(curr_mail_df)\n",
    "    # test group\n",
    "    test_df = pd.merge(curr_df[(curr_df['Group'] == 'test') |\n",
    "                           (curr_df['Group'] == 'not applicable')].drop(columns=['experiment_date']), \n",
    "                    curr_mail_df[\n",
    "                        ['email', 'experiment_date', 'open_letter', 'click_letter']\n",
    "                    ], \n",
    "                   on = 'email', how='inner')\n",
    "    columns = [\"table_name\", 'old_billing_account_id',\n",
    "           \"billing_account_id\", \"Group\", \"experiment_date\", \n",
    "           \"open_letter\", \"click_letter\", 'all_experiment_size']\n",
    "    test_df = test_df[columns]\n",
    "\n",
    "    \n",
    "    final_table = test_df\n",
    "    if 'control' in curr_df[\"Group\"].unique():\n",
    "        control_df = curr_df[curr_df[\"Group\"] == 'control']\n",
    "        control_df.loc[:, 'open_letter'] = [0] * len(control_df)\n",
    "        control_df.loc[:, 'click_letter'] = [0] * len(control_df)\n",
    "        control_df = control_df[columns]\n",
    "        final_table = lib.concatenate_tables([test_df, control_df])\n",
    "    dfs.append(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continious_df = lib.concatenate_tables(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = lib.concatenate_tables([marketo_main_df, continious_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОСНОВНОЕ \n",
    "\n",
    "## Гранты (старый вариант)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promos_request = f\"\"\"\n",
    "SELECT\n",
    "    DISTINCT billing_account_id,\n",
    "    source_id,\n",
    "    id as activate_id\n",
    "FROM \"//home/cloud/billing/exported-billing-tables/monetary_grants_prod\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "promos_df = lib.execute_query(promos_request)\n",
    "upsell_codes_req = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM \"//home/cloud_analytics/emailing/experiments/upsell/grant_sources/upsell_grants\"\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "upsell_codes_df = lib.execute_query(upsell_codes_req)\n",
    "\n",
    "activated_codes_df = pd.merge(upsell_codes_df, promos_df, on='source_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гранты автоматический вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_codes_new = lib.execute_query(\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM (\n",
    "SELECT\n",
    "    DISTINCT\n",
    "        source_id,\n",
    "        splitByChar(' ',  assumeNotNull(upsell_experiment_names)) as table_name,\n",
    "        billing_account_id,\n",
    "        id as activate_id\n",
    "FROM \"//home/cloud_analytics/lunin-dv/grants/offers_grants_information_table\"\n",
    "WHERE isNotNull(upsell_experiment_names)\n",
    "AND isNotNull(billing_account_id)\n",
    "AND upsell_experiment_names != '-'\n",
    ")\n",
    "ARRAY JOIN table_name\n",
    "FORMAT TabSeparatedWithNames\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_codes_df = lib.concatenate_tables([activated_codes_df, activated_codes_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_codes_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tables = []\n",
    "for name in main_df[\"table_name\"].unique():\n",
    "    curr_table = main_df[main_df[\"table_name\"] == name].copy()\n",
    "    curr_activated_codes_df = activated_codes_df[activated_codes_df[\"table_name\"] == name]\n",
    "    if len(curr_activated_codes_df) > 0:\n",
    "        activates = np.array(curr_table[\"billing_account_id\"].isin(\\\n",
    "            curr_activated_codes_df[\"billing_account_id\"]).astype(int))\n",
    "        curr_table[\"activate_grant\"] = activates\n",
    "        curr_table = pd.merge(curr_table, curr_activated_codes_df,\n",
    "                              on=['billing_account_id', 'table_name'], how='left')\n",
    "        curr_table['activate_id'] = curr_table['activate_id'].fillna('')\n",
    "    else:\n",
    "        curr_table[\"activate_grant\"] = [-1] * len(curr_table)\n",
    "        curr_table[\"source_id\"] = ''\n",
    "        curr_table[\"activate_id\"] = ''\n",
    "    new_tables.append(curr_table)\n",
    "    \n",
    "df_with_grants = lib.concatenate_tables(new_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_grants = df_with_grants.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert main_df.shape[0] == df_with_grants.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vm_new_services(table_raw, day_interval):\n",
    "    table = table_raw.copy()\n",
    "    lib.save_table(\"emailing_upsell_tmp\", '//home/cloud_analytics/lunin-dv/tmp', \n",
    "                   table)\n",
    "    time.sleep(20)\n",
    "    upper_bound = \"\"\n",
    "    if day_interval != -1:\n",
    "        upper_bound = f\"\"\"toDate(vm_start) <= addDays(toDate(experiment_date), {day_interval})\n",
    "                          AND toDate(vm_start) >= toDate(experiment_date)\"\"\"\n",
    "    else:\n",
    "        upper_bound = f\"toDate(vm_start) >= toDate(experiment_date)\"\n",
    "    lower_bound = f\"\"\"toDate(vm_start) >= addDays(toDate(experiment_date), -60) AND\n",
    "                    toDate(vm_start) < toDate(experiment_date)\"\"\"\n",
    "    name_add = day_interval\n",
    "    if name_add == -1:\n",
    "        name_add = \"all\"\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        ba_id as billing_account_id,\n",
    "        table_name,\n",
    "        count(DISTINCT if ({lower_bound}, node_az, null)) as old_az_num,\n",
    "        count(DISTINCT if ({upper_bound}, node_az, null)) as new_az_num,\n",
    "        if (old_az_num == 1 and new_az_num > 1, 1, 0) as \n",
    "        start_new_service_az_days_{name_add}\n",
    "    FROM \"//home/cloud_analytics/compute_logs/vm_cube/vm_cube\" as a\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM \"//home/cloud_analytics/lunin-dv/tmp/emailing_upsell_tmp\"\n",
    "    ) as b\n",
    "    on a.ba_id == b.billing_account_id\n",
    "    GROUP BY billing_account_id, table_name\n",
    "    FORMAT TabSeparatedWithNames\n",
    "\"\"\"\n",
    "    df = lib.execute_query(req)\n",
    "    vm_services_df = df[['billing_account_id', 'table_name', \n",
    "                                     f'start_new_service_az_days_{name_add}']]\n",
    "    table = pd.merge(table, vm_services_df, \n",
    "                     on = ['billing_account_id', 'table_name'], how='left')\n",
    "    table = table.fillna(0)\n",
    "    return table, [f'start_new_service_az_days_{name_add}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cube_new_services(table_raw, day_interval, cube_services):\n",
    "    table = table_raw.copy()\n",
    "    lib.save_table(\"emailing_upsell_tmp\", '//home/cloud_analytics/lunin-dv/tmp', \n",
    "                   table)\n",
    "    time.sleep(20)\n",
    "    after_cube_req = \"\"\n",
    "    before_cube_req = \"\"\n",
    "    diff_cube_req = \"\"\n",
    "    upper_bound_after = \"\"\n",
    "    if day_interval != -1:\n",
    "        upper_bound = f\"\"\"toDate(event_time) <= addDays(toDate(experiment_date), \n",
    "                                                {day_interval})\n",
    "                          AND toDate(event_time) >= toDate(experiment_date)\"\"\"\n",
    "    else:\n",
    "        upper_bound = f\"toDate(event_time) >= toDate(experiment_date)\"\n",
    "    lower_bound = f\"\"\"toDate(event_time) >= addDays(toDate(experiment_date), -60) AND\n",
    "                    toDate(event_time) < toDate(experiment_date)\"\"\"\n",
    "    name_add = day_interval\n",
    "    if name_add == -1:\n",
    "        name_add = \"all\"\n",
    "\n",
    "    for service, name in cube_services:\n",
    "        after_service_str = f\"max(if (sku_name like '%{service}%' \"\\\n",
    "                            f\"and {upper_bound}, 1, 0)) as after_{name},\\n\"\n",
    "\n",
    "        before_service_str = f\"max(if (sku_name like '%{service}%'\"\\\n",
    "                     f\"and {lower_bound}, 1, 0)) as before_{name},\\n\"\n",
    "        \n",
    "        diff_service_str = f\"if (before_{name} == 0 and after_{name} == 1, 1, 0) \"\\\n",
    "                           f\"as start_new_service_{name}_days_{name_add},\\n\"\n",
    "        diff_cube_req += diff_service_str\n",
    "        after_cube_req += after_service_str\n",
    "        before_cube_req += before_service_str\n",
    "\n",
    "    req = f\"\"\"\n",
    "        SELECT\n",
    "            {after_cube_req}\n",
    "            {before_cube_req}\n",
    "            {diff_cube_req}\n",
    "            billing_account_id,\n",
    "            table_name\n",
    "        FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\" as a\n",
    "        INNER JOIN (\n",
    "            SELECT\n",
    "                *\n",
    "            FROM \"//home/cloud_analytics/lunin-dv/tmp/emailing_upsell_tmp\"\n",
    "        ) as b\n",
    "        ON a.billing_account_id == b.billing_account_id\n",
    "        GROUP BY billing_account_id, table_name\n",
    "        FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    df = lib.execute_query(req)\n",
    "\n",
    "    interest_cols = [f\"start_new_service_{name}_days_{name_add}\" \n",
    "                     for service, name in cube_services]\n",
    "    \n",
    "    services_df = df[interest_cols + [\"billing_account_id\", 'table_name']]\n",
    "    table = pd.merge(table, services_df, on=[\"billing_account_id\", 'table_name'], \n",
    "                     how='left')\n",
    "    table = table.fillna(0)\n",
    "    return table, interest_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_services = [('support', 'support'), \n",
    "                 ('ms.sql', 'sql_server'), \n",
    "                 ('marketplace', 'marketplace'), \n",
    "                 ('windows', 'windows'),\n",
    "                 (\"mdb\", 'mdb'),\n",
    "                 (\"compute\", 'compute'),\n",
    "                 ('mk8s', 'mk8s'), \n",
    "                 ('mongo', 'mongo'), \n",
    "                 ('pg', 'pg'),\n",
    "                 ('clickhouse', 'clickhouse'), \n",
    "                 ('redis', 'redis'), \n",
    "                 ('mysql', 'mysql'),\n",
    "                 ('hystax', 'hystax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_to_observe = [14, 28, 63, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "service_cols = []\n",
    "full_service_compare_df = df_with_grants.copy()\n",
    "for day_interval in days_to_observe:\n",
    "    \n",
    "    full_service_compare_df, service_cols_curr_1 = \\\n",
    "        add_cube_new_services(full_service_compare_df, day_interval, cube_services)\n",
    "\n",
    "    full_service_compare_df, service_cols_curr_2 = \\\n",
    "        add_vm_new_services(full_service_compare_df, day_interval)\n",
    "    \n",
    "    service_cols_curr = service_cols_curr_1 + service_cols_curr_2\n",
    "    \n",
    "    \n",
    "    name_add = day_interval\n",
    "    if name_add == -1:\n",
    "        name_add = \"all\"\n",
    "    full_service_compare_df[f'start_new_service_all_days_{name_add}'] =\\\n",
    "    full_service_compare_df[service_cols_curr].apply(\n",
    "        lambda x: 1 if x.sum() > 0 else 0, axis=1)\n",
    "    service_cols_curr += [f'start_new_service_all_days_{name_add}']\n",
    "    service_cols += service_cols_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert full_service_compare_df.shape[0] == main_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_service_compare_df[\"days_to_now\"] = (parse(lib.get_current_date_as_str()) -\\\n",
    "                                          pd.to_datetime(\n",
    "                                            full_service_compare_df[\"experiment_date\"])\n",
    "                                          ).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_service_compare_df[\"days_to_now\"] =\\\n",
    "(full_service_compare_df[\"days_to_now\"] // 7) * 7 \n",
    "\n",
    "full_service_compare_df[\"days_to_now\"] = full_service_compare_df[\"days_to_now\"].apply(\n",
    "    lambda x: x if x >= 0 else 0)\n",
    "\n",
    "full_service_compare_df[\"real_days_to_now\"] = full_service_compare_df[\"days_to_now\"].copy()\n",
    "\n",
    "full_service_compare_df[\"days_to_now\"] = full_service_compare_df[\"days_to_now\"].apply(\n",
    "    lambda x: x if x < 63 else 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cons_df(table, day_interval, cube_services):\n",
    "    lib.save_table(\"emailing_upsell_tmp\", '//home/cloud_analytics/lunin-dv/tmp', \n",
    "                   table)\n",
    "    time.sleep(20)\n",
    "    name_add = day_interval\n",
    "    if name_add == -1:\n",
    "        name_add = \"all\"\n",
    "     \n",
    "    if day_interval > 63:\n",
    "        day_interval = 63\n",
    "\n",
    "    after_interval = f\"\"\"toDate(event_time) < addDays(toDate(experiment_date), \n",
    "                                                       to_observe)\n",
    "                  AND toDate(event_time) >= toDate(experiment_date)\"\"\"\n",
    "    before_interval = f\"\"\"toDate(event_time) >= addDays(toDate(experiment_date), \n",
    "                                                -to_observe)\n",
    "                      AND toDate(event_time) < toDate(experiment_date)\"\"\"\n",
    "    \n",
    "    after_cons_req = \"\"\n",
    "    before_cons_req = \"\"\n",
    "    diff_req = \"\"\n",
    "    for service, name in cube_services:\n",
    "        after_cons_req += f\"\"\"\n",
    "        sum(if({after_interval} and sku_name like '%{service}%', \n",
    "               real_consumption, 0)) as \n",
    "        after_consumption_{name}_{name_add},\\n\n",
    "        \"\"\"\n",
    "        \n",
    "        before_cons_req += f\"\"\"\n",
    "        sum(if({before_interval} and sku_name like '%{service}%', \n",
    "               real_consumption, 0)) \n",
    "        as before_consumption_{name}_{name_add},\\n\n",
    "        \"\"\"\n",
    "        \n",
    "        diff_req += f\"\"\"\n",
    "        (after_consumption_{name}_{name_add} - \n",
    "        before_consumption_{name}_{name_add}) / to_observe * 30\n",
    "        as difference_{name}_{name_add},\\n\n",
    "        \"\"\"\n",
    "    \n",
    "    after_cons_req += f\"\"\"\n",
    "        sum(if({after_interval}, \n",
    "               real_consumption, 0)) as \n",
    "        after_consumption_all_{name_add},\\n\n",
    "        \"\"\"\n",
    "\n",
    "    before_cons_req += f\"\"\"\n",
    "        sum(if({before_interval}, \n",
    "            real_consumption, 0)) \n",
    "        as before_consumption_all_{name_add},\\n\n",
    "        \"\"\"\n",
    "        \n",
    "    diff_req += f\"\"\"\n",
    "    (after_consumption_all_{name_add} - \n",
    "    before_consumption_all_{name_add}) / to_observe * 30\n",
    "    as difference_all_{name_add},\\n\n",
    "    \"\"\"\n",
    "    \n",
    "    cons_req = f\"\"\"\n",
    "    SELECT\n",
    "        {after_cons_req}\n",
    "        {before_cons_req}\n",
    "        {diff_req}\n",
    "        billing_account_id,\n",
    "        table_name,\n",
    "        experiment_date \n",
    "    FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\" as a\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            *,\n",
    "            if (assumeNotNull(days_to_now) > {day_interval} and {day_interval} != -1, {day_interval}, \n",
    "                days_to_now) as to_observe\n",
    "        FROM \"//home/cloud_analytics/lunin-dv/tmp/emailing_upsell_tmp\"\n",
    "    ) as b\n",
    "    ON a.billing_account_id == b.billing_account_id\n",
    "    GROUP BY billing_account_id, to_observe, table_name, experiment_date\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    cons_df = lib.execute_query(cons_req)\n",
    "    cons_df = cons_df[cons_df[\"billing_account_id\"].isin(table[\"billing_account_id\"])]\n",
    "\n",
    "    consumption_compare_df = pd.merge(table, \n",
    "                                      cons_df, \n",
    "                                      on=[\"billing_account_id\", 'table_name', \n",
    "                                          'experiment_date'], how=\"left\")\n",
    "    consumption_compare_df.replace(np.nan, 0, inplace=True)\n",
    "    return consumption_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_revenue_for_service_group(consumption_compare_df, day_interval, \n",
    "                                  service_name, name_add):\n",
    "    diff = f\"difference_{service_name}_{name_add}\"\n",
    "    if \"control\" in consumption_compare_df[\"Group\"].unique():\n",
    "\n",
    "        control_diff = consumption_compare_df[\n",
    "            (consumption_compare_df[\"Group\"] == 'control') &\n",
    "            (consumption_compare_df[\"days_to_now\"] >= day_interval)\n",
    "        ][diff]\n",
    "\n",
    "        test_diff = consumption_compare_df[\n",
    "            (consumption_compare_df[\"Group\"] == 'test') &\n",
    "            (consumption_compare_df[\"days_to_now\"] >= day_interval)\n",
    "        ][diff]\n",
    "        \n",
    "        control_avg = np.mean(np.array(control_diff))\n",
    "        test_avg = np.mean(np.array(test_diff))\n",
    "        \n",
    "        consumption_compare_df[f\"experiment_revenue_{service_name}_{name_add}\"] =\\\n",
    "        [test_avg - control_avg] * len(consumption_compare_df)\n",
    "        \n",
    "        \n",
    "        ## ttest\n",
    "        test = test_diff\n",
    "        control = control_diff\n",
    "#         print(consumption_compare_df['table_name'].iloc[0], day_interval)\n",
    "#         print('mean:', np.mean(test), \"; std:\", np.std(test), '-- TEST')\n",
    "#         print('mean:', np.mean(control), \"; std:\", np.std(control), '-- CONTROL')\n",
    "        pval = sps.ttest_ind(control, test, equal_var=False).pvalue\n",
    "        \n",
    "        consumption_compare_df[f\"revenue_{service_name}_{name_add}_pval\"] = pval\n",
    "\n",
    "        cm = sms.CompareMeans(sms.DescrStatsW(test), \n",
    "                              sms.DescrStatsW(control))\n",
    "        left, right = cm.tconfint_diff(usevar='unequal')\n",
    "        consumption_compare_df[f\"minimum_revenue_{service_name}_{name_add}\"] = left\n",
    "        consumption_compare_df[f\"maximum_revenue_{service_name}_{name_add}\"] = right\n",
    "    else:\n",
    "        consumption_compare_df[f\"experiment_revenue_{service_name}_{name_add}\"] = -1\n",
    "        consumption_compare_df[f\"revenue_{service_name}_{name_add}_pval\"] = -1\n",
    "        consumption_compare_df[f\"minimum_revenue_{service_name}_{name_add}\"] = -1\n",
    "        consumption_compare_df[f\"maximum_revenue_{service_name}_{name_add}\"] = -1\n",
    "\n",
    "    return consumption_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_revenue_for_group(consumption_compare_df, day_interval, cube_services):\n",
    "    name_add = day_interval\n",
    "    if name_add == -1:\n",
    "        name_add = \"all\"\n",
    "    if day_interval == -1:\n",
    "        day_interval = 7\n",
    "    \n",
    "    for _, service_name in cube_services:\n",
    "        consumption_compare_df =\\\n",
    "        add_revenue_for_service_group(consumption_compare_df, day_interval, \n",
    "                                      service_name, name_add)\n",
    "    \n",
    "    return consumption_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_by_day_intervals_cons_df(table, days_to_observe, cube_services):\n",
    "    consumption_compare_df = table.copy()\n",
    "    for day_interval in days_to_observe:\n",
    "        new_tables = []\n",
    "        consumption_compare_df = add_cons_df(consumption_compare_df, \n",
    "                                             day_interval,\n",
    "                                             cube_services)\n",
    "        for name in consumption_compare_df[\"table_name\"].unique():\n",
    "            curr_table = consumption_compare_df[\n",
    "                    (consumption_compare_df[\"table_name\"] == name)].copy()\n",
    "            new_tables.append(add_revenue_for_group(curr_table, \n",
    "                                                    day_interval, \n",
    "                                                    cube_services + [('all', 'all')]))\n",
    "        consumption_compare_df = lib.concatenate_tables(new_tables)\n",
    "    return consumption_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_consumption_service_compare_df= add_by_day_intervals_cons_df(\n",
    "    full_service_compare_df, days_to_observe, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert main_df.shape[0] == full_consumption_service_compare_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wald_comparison(curr_table, service_cols):\n",
    "    for service in sorted(service_cols):\n",
    "        test_df = curr_table[(curr_table[\"Group\"] == 'test') &\n",
    "                             (curr_table[service] != -1)]\n",
    "        control_df = curr_table[(curr_table[\"Group\"] == 'control') &\n",
    "                                (curr_table[service] != -1)]\n",
    "        if len(test_df) == 0:\n",
    "            curr_table[service + \"_pval\"] = [-1 for _ in range(len(curr_table))]\n",
    "            continue\n",
    "        test = np.array(test_df[service])\n",
    "        control = np.array(control_df[service])\n",
    "        pval = lib.WaldTest(len(control), np.sum(control),\n",
    "                        len(test), np.sum(test), alternative=\"less\").pvalue\n",
    "        curr_table[service + \"_pval\"] = [pval for _ in range(len(curr_table))]\n",
    "    return curr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tables = []\n",
    "for name in full_consumption_service_compare_df[\"table_name\"].unique():\n",
    "    #print(name)\n",
    "    curr_table = full_consumption_service_compare_df[\n",
    "        (full_consumption_service_compare_df[\"table_name\"] == name)\n",
    "    ].copy()\n",
    "    if \"control\" in curr_table[\"Group\"].unique():\n",
    "        curr_table = wald_comparison(curr_table, service_cols)\n",
    "    else:\n",
    "        for service in sorted(service_cols):\n",
    "            curr_table[service + \"_pval\"] = [0.5 for _ in range(len(curr_table))]\n",
    "    new_tables.append(curr_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = lib.concatenate_tables(new_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table[\"experiment_name\"] = result_table[\"table_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table.replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_table(\"upsell_emailing\", \n",
    "               \"//home/cloud_analytics/emailing/experiments/upsell/results\", \n",
    "               result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_table_from_yt_to_grafana(\n",
    "    \"//home/cloud_analytics/emailing/experiments/upsell/results/upsell_emailing\",\n",
    "    \"cloud_analytics.upsell_emailing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
