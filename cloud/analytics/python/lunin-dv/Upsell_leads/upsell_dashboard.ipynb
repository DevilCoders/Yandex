{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "from statsmodels.stats import multitest\n",
    "os.chdir('/Users/lunin-dv/Desktop/Library/')\n",
    "import importlib\n",
    "import robot_lib as lib\n",
    "importlib.reload(lib)\n",
    "os.chdir('/Users/lunin-dv/Desktop/Upsell/analysis')\n",
    "from kostyas_script import make_kostya_req\n",
    "os.chdir('/Users/lunin-dv/Desktop/data/Upsell')\n",
    "from collections import defaultdict\n",
    "import statsmodels.stats.api as sms\n",
    "import time\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_table = lib.find_tables_in_hahn_folder(\n",
    "    \"//home/cloud_analytics/dwh/raw/crm/leads\")[-1]\n",
    "oppotunities_table = lib.find_tables_in_hahn_folder(\n",
    "    \"//home/cloud_analytics/dwh/raw/crm/opportunities\")[-1]\n",
    "tag_table = lib.find_tables_in_hahn_folder(\n",
    "    \"//home/cloud_analytics/dwh/raw/crm/tags\")[-1]\n",
    "tag_lead_table = lib.find_tables_in_hahn_folder(\n",
    "    \"//home/cloud_analytics/dwh/raw/crm/tag_bean_rel\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_core_upsell_test_df_info(days_to_add_to_experiment=0):\n",
    "    \"\"\"\n",
    "    Создание таблицы с основной информацией по аккаунту, попавшему в upsell \n",
    "    (или в sales с последующей привязкой к тегам 'upsell_test')\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    days_to_add_to_experiment : int\n",
    "        Количество дней, на которые надо сместить начало эксперимента \n",
    "        (наример, чтобы впоследствии смотерть относительно новой даты разницу в чеке)\n",
    "    \n",
    "    Возвращает\n",
    "    -------\n",
    "    df: pandas DataFrame\n",
    "        Таблица со столбцами:\n",
    "        - `lead_id`\n",
    "        - `billing_account_id`\n",
    "        - `last_state` (значения: ['Disqualified', 'Converted'])\n",
    "        - `end_date_before_consumption` - дата попадания к телесейлзу, \n",
    "        - `lead_source_description` (['upsell', \n",
    "                                      'contact more then 70 days', \n",
    "                                      'upsell_test' (если lead_source == 'sales')])\n",
    "        смещенная на days_to_add_to_experiment  \n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    upsell_billings_req = f\"\"\"\n",
    "    SELECT\n",
    "        lead_id,\n",
    "        billing_account_id,\n",
    "        if(states[-1] == 'Recycled', 'Disqualified',\n",
    "                states[-1]) as last_state,\n",
    "        addDays(toDate(event_time), \n",
    "                {days_to_add_to_experiment}) as end_date_before_consumption,\n",
    "        multiIf (\n",
    "lead_source_description == 'landing page' and sales_name in ('dmtroe', 'gingerkote'), 'landing page',\n",
    "        lead_source_description == 'new from upsell', 'new from upsell',\n",
    "        lead_source_description == 'big-3', 'big-3',\n",
    "        lead_source_description == 'upsell', 'upsell',\n",
    "        lead_source_description == 'contact more then 70 days', 'contact more then 70 days',\n",
    "        lead_source == 'sales', 'sales_type', \n",
    "        '') as lead_source_description\n",
    "    FROM cloud_analytics_testing.crm_lead_cube_test as a\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            lead_id,\n",
    "            arraySort((x, y) -> y, groupArray(lead_state), \n",
    "            groupArray(event_time)) as states\n",
    "        FROM cloud_analytics_testing.crm_lead_cube_test\n",
    "        WHERE lead_state IN ('New', 'Assigned', 'In Process', 'Recycled', 'Converted')\n",
    "        GROUP BY lead_id\n",
    "    ) as b\n",
    "    ON a.lead_id == b.lead_id\n",
    "    WHERE ((lead_state == 'Assigned' and lead_source_description != 'sales_type') OR\n",
    "    (lead_state == 'New' and lead_source_description == 'sales_type'))\n",
    "    AND lead_source_description != ''\n",
    "    AND last_state in ('Disqualified', 'Converted')\n",
    "    AND isNotNull(billing_account_id)\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    upsell_billings_df = lib.grafana_execute_query(upsell_billings_req)\n",
    "    \n",
    "    assert set(upsell_billings_df.columns) == set(['lead_id', 'billing_account_id',\n",
    "                                                   'last_state', \n",
    "                                                   'end_date_before_consumption',\n",
    "                                                   \"lead_source_description\"])\n",
    "    assert set(upsell_billings_df['last_state']) == set(['Disqualified', 'Converted'])\n",
    "    return upsell_billings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_df_for_upsell():\n",
    "    req = f\"\"\"\n",
    "    SELECT\n",
    "        bean_id as lead_id,\n",
    "        name_lower\n",
    "    FROM \"{tag_lead_table}\" as a\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            id,\n",
    "            name_lower\n",
    "        FROM \"{tag_table}\"\n",
    "        WHERE \n",
    "            name_lower == 'upsell_test'\n",
    "        OR \n",
    "            name_lower == 'гипотеза_upsell'\n",
    "    ) as b\n",
    "    ON a.tag_id == b.id\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\".encode('utf-8')\n",
    "    tag_df = lib.execute_query(req)\n",
    "    return tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oppotunity_df_for_upsell():\n",
    "    \"\"\"\n",
    "    Создание таблицы с информацией о закрытых oppotunity, для всех клиентов\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    \n",
    "    Возвращает\n",
    "    -------\n",
    "    opp_df: pandas DataFrame \n",
    "            Таблица со столбцами:\n",
    "            - `lead_id`\n",
    "            - `start_date_after_consumption` - дата завершения oppotunity\n",
    "            - `status` (значение 'win')\n",
    "            В таблице только те, у кого есть статус 'Closed Won' для данного lead_id\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    oppotunity_req = f\"\"\"\n",
    "        SELECT\n",
    "            id as lead_id,\n",
    "            date_closed as start_date_after_consumption,\n",
    "            'win' as status\n",
    "        FROM (\n",
    "            SELECT\n",
    "                id,\n",
    "                opportunity_id,\n",
    "                toDate(date_entered) as date_entered\n",
    "            FROM \"{leads_table}\"\n",
    "        ) as a\n",
    "        INNER JOIN (\n",
    "            SELECT\n",
    "                id,\n",
    "                'Closed Won' as sales_status,\n",
    "                toDate(date_closed_timestamp) as date_closed\n",
    "            FROM \"{oppotunities_table}\"\n",
    "            WHERE sales_stage == 'win'\n",
    "        ) as b\n",
    "        ON a.opportunity_id == b.id\n",
    "        ORDER BY id, date_closed\n",
    "        FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    #print(oppotunity_req)\n",
    "    opp_df = lib.execute_query(oppotunity_req)\n",
    "    assert set(opp_df.columns) == set(['lead_id', 'start_date_after_consumption', \n",
    "                                       'status'])\n",
    "    assert set(opp_df['status']) == set(['win'])\n",
    "    return opp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_call_df_for_upsell():\n",
    "    \"\"\"\n",
    "    Создание таблицы с информацие, дозвонились ли до клиента и когда, по всем клиентам\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    \n",
    "    Возвращает\n",
    "    -------\n",
    "    call_df: pandas DataFrame\n",
    "             Таблица со столбцами:\n",
    "             - `lead_id` - id тех, кому НЕ дозвонились\n",
    "             - `start_date_after_consumption` - \n",
    "                дата первого недозвона по этому lead_id, если вообще не дозвонились,\n",
    "                иначе дата первого успешного звонка\n",
    "             - `status` (значение 'unreachible', 'reachible')\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    call_req = f\"\"\"\n",
    "    SELECT\n",
    "        id as lead_id,\n",
    "        start_date_after_consumption,\n",
    "        status\n",
    "    FROM (\n",
    "        SELECT\n",
    "            id\n",
    "        FROM \"{leads_table}\"\n",
    "    ) as a\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            lead_id,\n",
    "            any(billing_account_id) as billing_account_id, \n",
    "            groupUniqArray(call_status) as call_statuses,\n",
    "            min(toDate(event_time)) as min_call_date,\n",
    "            if (hasAll(['unreachible', 'unreachible,unreachible'], call_statuses) == 1, \n",
    "                'unreachible', 'reachible') as status,\n",
    "            min(if (call_status != 'unreachible' and call_status != 'unreachible,unreachible',\n",
    "                    toDate(event_time), null)) as good_call_date,\n",
    "            if (status == 'unreachible', min_call_date, good_call_date) \n",
    "            as start_date_after_consumption\n",
    "        FROM \"//home/cloud_analytics_test/cubes/crm_leads/cube\"\n",
    "        WHERE event == 'call'\n",
    "        GROUP BY lead_id\n",
    "    ) as b\n",
    "    ON a.id == b.lead_id\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    call_df = lib.execute_query(call_req)\n",
    "    assert set(call_df.columns) == set(['lead_id', 'start_date_after_consumption', \n",
    "                                       'status'])\n",
    "    assert set(call_df['status']) == set(['unreachible', 'reachible'])\n",
    "    return call_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upsell_df(days_to_add_to_experiment=0, use_one_date=False):\n",
    "    \"\"\"\n",
    "    Создание таблицы с основной информацией по upsell клиентам\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    days_to_add_to_experiment : int\n",
    "        Количество дней, на которые надо сместить начало эксперимента \n",
    "        (наример, чтобы впоследствии смотреть относительно новой даты разницу в чеке)\n",
    "    use_one_date: bool\n",
    "         Если True, то `end_date_before_consumption` = `start_date_after_consumption`\n",
    "         И разница в чеке смотрится относительно одной и той же даты \n",
    "         (`start_date_after_consumption` приравнивается к `end_date_before_consumption`)\n",
    "         Иначе этого не происходит\n",
    "    Возвращает\n",
    "    -------\n",
    "    upsell_table: pandas DataFrame\n",
    "                  Таблица со столбцами:\n",
    "                  - `lead_id`\n",
    "                  - `billing_account_id`\n",
    "                  - `lead_source_description`\n",
    "                  - `end_date_before_consumption`\n",
    "                  - `start_date_after_consumption` \n",
    "                    - дата завершения oppotunity (status='win')\n",
    "                    - дата первого недозвона по этому lead_id \n",
    "                      (если до лида ни разу не дозвонились, status='unreachible') \n",
    "                    - дата певого звонка, когда дозвонились\n",
    "                    - `end_date_before_consumption` если нет записи в таблице звонков\n",
    "                  - `last_state` - ['disqualified', 'converted'] (только маленькие буквы)\n",
    "                  - `status` (значение 'unreachible', 'win', 'converted', 'disqualified',\n",
    "                              где 2 последних эквивалетнны `last_state`, \n",
    "                              если не попали в 2 других статуса)\n",
    "                  В таблице все те, кто попал в upsell \n",
    "                  (lead_source_description == 'upsell', \n",
    "                  'upsell_test', 'contact more then 70 days')\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    # 1. Создание основной таблицы со всеми upsell\n",
    "    core_upsell_table = create_core_upsell_test_df_info()\n",
    "    core_upsell_table['last_state'] = core_upsell_table['last_state'].apply(\n",
    "        lambda x: x.lower())\n",
    "    tag_df = create_tag_df_for_upsell()\n",
    "\n",
    "\n",
    "    upsell_hypotesis = core_upsell_table[\n",
    "        core_upsell_table[\"lead_id\"].isin(\n",
    "            tag_df[tag_df['name_lower'] == 'гипотеза_upsell'][\"lead_id\"])]\n",
    "    upsell_hypotesis['lead_source_description'] = ['гипотеза_upsell'] * len(upsell_hypotesis)\n",
    "\n",
    "\n",
    "    upsell_test = core_upsell_table[\n",
    "        core_upsell_table[\"lead_id\"].isin(\n",
    "            tag_df[tag_df['name_lower'] == 'upsell_test'][\"lead_id\"])]\n",
    "    upsell_test['lead_source_description'] = ['upsell_test'] * len(upsell_test)\n",
    "\n",
    "    upsell_core = core_upsell_table[\n",
    "        (~core_upsell_table[\"lead_id\"].isin(upsell_hypotesis[\"lead_id\"])) &\n",
    "        (~core_upsell_table[\"lead_id\"].isin(upsell_test[\"lead_id\"])) &\n",
    "        (core_upsell_table['lead_source_description'] != 'sales_type')\n",
    "    ]\n",
    "\n",
    "    \n",
    "    upsell_test = upsell_test[\n",
    "        (upsell_test[\"end_date_before_consumption\"] > '2019-11-01')   \n",
    "    ]\n",
    "\n",
    "    core_upsell_table = lib.concatenate_tables([upsell_core, upsell_test, upsell_hypotesis])\n",
    "    # 2. oppotunity и call таблицы\n",
    "    oppotunity_df = create_oppotunity_df_for_upsell()\n",
    "    call_df = create_call_df_for_upsell()\n",
    "    \n",
    "    # 3. склейка\n",
    "    upsell_call = pd.merge(core_upsell_table, call_df, on='lead_id', how='inner')\n",
    "    \n",
    "    upsell_call[\"status\"] = upsell_call[[\"status\", 'lead_id']].apply(\n",
    "        lambda row: \n",
    "        'win' if row['lead_id'] in set(oppotunity_df['lead_id']) else row['status'],\n",
    "    axis=1)\n",
    "\n",
    "    upsell_call['status'] =\\\n",
    "    upsell_call[['last_state', 'status']].apply(\n",
    "        lambda row: row['status'] if row['status'] != 'reachible' else row['last_state'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 4. формирование итоговой таблицы\n",
    "    upsell_table = upsell_call\n",
    "    \n",
    "    # 4.a те, кто не попал в таблицу звонков и в опти\n",
    "    remaining_upsell =\\\n",
    "    core_upsell_table[~core_upsell_table['lead_id'].isin(upsell_table['lead_id'])]\n",
    "    \n",
    "\n",
    "    remaining_upsell.loc[:, 'start_date_after_consumption'] =\\\n",
    "    remaining_upsell.loc[:, 'end_date_before_consumption']\n",
    "    remaining_upsell.loc[:, 'status'] = remaining_upsell.loc[:, 'last_state']\n",
    "    \n",
    "    # 5 Финальное склеивание\n",
    "    upsell_table = lib.concatenate_tables([upsell_call,\n",
    "                                           remaining_upsell])\n",
    "    \n",
    "    if use_one_date:\n",
    "        upsell_table.loc[:, 'start_date_after_consumption'] =\\\n",
    "        upsell_table.loc[:, 'end_date_before_consumption']\n",
    "        \n",
    "    # Check\n",
    "    assert set(upsell_table.columns) == set(['lead_id', 'billing_account_id',\n",
    "                                             'lead_source_description',\n",
    "                                            'end_date_before_consumption',\n",
    "                                            'start_date_after_consumption',\n",
    "                                            'last_state', 'status'])\n",
    "    assert set(upsell_table[\"last_state\"]) == set(['disqualified', 'converted'])\n",
    "    assert set(upsell_table[\"status\"]) == set(['unreachible', 'win', \n",
    "                                               'converted', 'disqualified'])\n",
    "    assert set(upsell_table[\"lead_id\"]) == set(core_upsell_table[\"lead_id\"])\n",
    "    assert upsell_table[\"lead_id\"].shape[0] == core_upsell_table.shape[0]\n",
    "    assert not use_one_date or\\\n",
    "           np.array_equal(upsell_table['start_date_after_consumption'],\n",
    "                          upsell_table['end_date_before_consumption'])\n",
    "    return upsell_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_columns_for_difference_days(day):\n",
    "    req = f\"\"\"\n",
    "    SUM(if (toDate(event_time) < toDate(end_date_before_consumption)\n",
    "            AND toDate(event_time) >= addDays(toDate(end_date_before_consumption), \n",
    "                                              -{day}),\n",
    "            real_consumption + trial_consumption, 0)\n",
    "        ) as before_consumption_{day},\n",
    "\n",
    "    SUM(if (toDate(event_time) >= toDate(start_date_after_consumption)\n",
    "            AND toDate(event_time) < addDays(toDate(start_date_after_consumption), \n",
    "                                             {day}),\n",
    "            real_consumption + trial_consumption, 0)\n",
    "        ) as after_consumption_{day},\n",
    "\n",
    "    after_consumption_{day} - before_consumption_{day} as consumption_difference_period_{day},\n",
    "    \n",
    "    \"\"\"\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_columns_for_after_consumption_reversed(day):\n",
    "    req = f\"\"\"\n",
    "    SUM(if (toDate(event_time) >= toDate(start_date_after_consumption)\n",
    "            AND toDate(event_time) < addDays(toDate(NOW()), \n",
    "                                             -{day}),\n",
    "            real_consumption + trial_consumption, 0)\n",
    "        ) as after_reversed_consumption_{day},\n",
    "    \"\"\"\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_columns_for_consumption_to_day(day):\n",
    "    req = f\"\"\"\n",
    "    SUM(if (toDate(event_time) == addDays(toDate(end_date_before_consumption), -{day}),\n",
    "            real_consumption + trial_consumption, 0)\n",
    "        ) as before_consumption_in_{day},\n",
    "\n",
    "    SUM(if (toDate(event_time) == addDays(toDate(start_date_after_consumption), \n",
    "                                                 {day}),\n",
    "            real_consumption + trial_consumption, 0)\n",
    "        ) as after_consumption_in_{day},\n",
    "    \"\"\"\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_current_consumption_req(columns_in_answer, column_maker_func, periods_in_days):\n",
    "    \"\"\"\n",
    "    Создание запроса с нужной информацией про потребление\n",
    "    Параметры\n",
    "    ----------\n",
    "    columns_in_answer : list of strings\n",
    "                        Столбцы для возврата\n",
    "    column_maker_func : function\n",
    "                        Функция для создания частичного подзапроса\n",
    "    period_in_days: list\n",
    "                    массив в котором находятся числа\n",
    "                    Числа отвечают за количество дней, в течение которого \n",
    "                    считается потребление \n",
    "                    до `end_date_before_consumption` и \n",
    "                    после `start_date_after_consumption`\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "\n",
    "    part_request = \"\"\n",
    "    for day in periods_in_days:\n",
    "        part_request += column_maker_func(day)\n",
    "\n",
    "    columns_in_answer_str = \", \".join(columns_in_answer) # чтобы прописать внутри запроса\n",
    "\n",
    "    consumption_req = f\"\"\"\n",
    "    SELECT\n",
    "        {columns_in_answer_str},\n",
    "        last_active_billing,\n",
    "        lead_source_description\n",
    "    FROM (\n",
    "        SELECT\n",
    "            {part_request}\n",
    "            last_active_billing,\n",
    "            lead_source_description\n",
    "        FROM \"//home/cloud_analytics/cubes/acquisition_cube/cube\" as a\n",
    "        INNER JOIN (\n",
    "            SELECT\n",
    "                billing_account_id,\n",
    "                last_active_billing,\n",
    "                upsell_info.*\n",
    "            FROM \"//home/cloud_analytics/lunin-dv/meta_cube/meta_id_information_cube\" as a\n",
    "            inner JOIN (\n",
    "                SELECT\n",
    "                    *\n",
    "                FROM \"//home/cloud_analytics/lunin-dv/tmp/upsell_tmp\"\n",
    "            ) as upsell_info\n",
    "            ON a.last_active_billing == upsell_info.last_active_billing\n",
    "        ) as b\n",
    "        ON a.billing_account_id == b.billing_account_id\n",
    "        GROUP BY last_active_billing, lead_source_description\n",
    "    )\n",
    "    FORMAT TabSeparatedWithNames\n",
    "    \"\"\"\n",
    "    return consumption_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dataframe_difference_in_checks(df_raw, periods_in_days, \n",
    "                                          specific_columns=None):\n",
    "    \"\"\"\n",
    "    Добавление в таблицу разницы в чеке для каждого пользователя до начала некоторой даты\n",
    "    и после некоторой другой даты\n",
    "    Параметры\n",
    "    ----------\n",
    "    df_raw : pandas DataFrame\n",
    "        Таблица, в которой есть столбцы\n",
    "        - `billing_account_id`,\n",
    "        - `end_date_before_consumption`\n",
    "        - `start_date_after_consumption`\n",
    "    period_in_days: list\n",
    "        массив в котором находятся числа\n",
    "        Числа отвечают за количество дней, в течение которого считается потребление \n",
    "        до `end_date_before_consumption` и \n",
    "        после `start_date_after_consumption`\n",
    "    specific_columns: list\n",
    "        Какие столбцы вернуть\n",
    "    Возвращает\n",
    "    -------\n",
    "    df: pandas DataFrame\n",
    "        Таблица, в которой к исходным столбцам прибавляются новые столбцы\n",
    "        `consumption_difference_period_{day}` по всем days в period_in_days\n",
    "        или specific_columns\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    # Проверим, что есть нужные столбцы\n",
    "    assert \"billing_account_id\" in df.columns\n",
    "    assert \"end_date_before_consumption\" in df.columns\n",
    "    assert \"start_date_after_consumption\" in df.columns\n",
    "    \n",
    "    # Столбцы для добавления\n",
    "    new_columns = [f\"consumption_difference_period_{i}\" for i in periods_in_days]\n",
    "    if specific_columns is not None:\n",
    "        new_columns += specific_columns\n",
    "    \n",
    "    lib.save_table(\"upsell_tmp\", \"//home/cloud_analytics/lunin-dv/tmp\", df)\n",
    "    time.sleep(20)\n",
    "    consumption_req = _make_current_consumption_req(new_columns, \n",
    "                                                    _make_columns_for_difference_days, \n",
    "                                                    periods_in_days)\n",
    "    #print(consumption_req)\n",
    "    consumption_df = lib.execute_query(consumption_req)\n",
    "    df = pd.merge(df, consumption_df, on=[\"last_active_billing\",\n",
    "                                          'lead_source_description'], how='inner')\n",
    "    assert set(df.columns) == set(df_raw.columns.tolist() +\\\n",
    "                                  new_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dataframe_consumption_by_days(df_raw, periods_in_days):\n",
    "    \"\"\"\n",
    "    Добавление в таблицу потребления по дням для каждого пользователя до начала некоторой даты\n",
    "    и после некоторой другой даты\n",
    "    Параметры\n",
    "    ----------\n",
    "    df_raw : pandas DataFrame\n",
    "        Таблица, в которой есть столбцы\n",
    "        - `billing_account_id`,\n",
    "        - `end_date_before_consumption`\n",
    "        - `start_date_after_consumption`\n",
    "    period_in_days: list\n",
    "        массив в котором находятся числа\n",
    "        Числа отвечают за дни, в течение которых считается потребление \n",
    "        до `end_date_before_consumption` и \n",
    "        после `start_date_after_consumption`\n",
    "    Возвращает\n",
    "    -------\n",
    "    df: pandas DataFrame\n",
    "        Таблица, в которой к исходным столбцам прибавляются столбцы\n",
    "        `before_consumption_in_{day}`,\n",
    "        `after_consumption_in_{day}`по всем days в period_in_days\n",
    "    \"\"\"\n",
    "    ##############################################################################\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    # Проверим, что есть нужные столбцы\n",
    "    assert \"billing_account_id\" in df.columns\n",
    "    assert \"end_date_before_consumption\" in df.columns\n",
    "    assert \"start_date_after_consumption\" in df.columns\n",
    "    \n",
    "    # Столбцы для добавления\n",
    "    new_columns = [f\"before_consumption_in_{i}\" for i in periods_in_days] + \\\n",
    "                  [f\"after_consumption_in_{i}\" for i in periods_in_days]\n",
    "\n",
    "    lib.save_table(\"upsell_tmp\", \"//home/cloud_analytics/lunin-dv/tmp\", df)\n",
    "    time.sleep(20)\n",
    "    consumption_req = _make_current_consumption_req(new_columns, \n",
    "                                                    _make_columns_for_consumption_to_day, \n",
    "                                                    periods_in_days)\n",
    "    consumption_df = lib.execute_query(consumption_req)\n",
    "    df = pd.merge(df, consumption_df, on=[\"last_active_billing\",\n",
    "                                          'lead_source_description'], how='inner')\n",
    "    assert set(df.columns) == set(df_raw.columns.tolist() +\\\n",
    "                                  new_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dataframe_consumption_after_experiment_reversed(df_raw, periods_in_days):\n",
    "    ##############################################################################\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    # Проверим, что есть нужные столбцы\n",
    "    assert \"billing_account_id\" in df.columns\n",
    "    assert \"end_date_before_consumption\" in df.columns\n",
    "    assert \"start_date_after_consumption\" in df.columns\n",
    "    \n",
    "    # Столбцы для добавления\n",
    "    new_columns = [f\"after_reversed_consumption_{i}\" for i in periods_in_days]\n",
    "\n",
    "    lib.save_table(\"upsell_tmp\", \"//home/cloud_analytics/lunin-dv/tmp\", df)\n",
    "    time.sleep(20)\n",
    "    consumption_req = _make_current_consumption_req(new_columns, \n",
    "                                                _make_columns_for_after_consumption_reversed, \n",
    "                                                    periods_in_days)\n",
    "    consumption_df = lib.execute_query(consumption_req)\n",
    "    df = pd.merge(df, consumption_df, on=[\"last_active_billing\",\n",
    "                                          'lead_source_description'], how='inner')\n",
    "    assert set(df.columns) == set(df_raw.columns.tolist() +\\\n",
    "                                  new_columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = lib.MetaInformationClass(interested_columns=[])\n",
    "meta_info.create_users_id()\n",
    "res_df = meta_info.get_dataframe_with_grouped_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lunin-dv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/lunin-dv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/lunin-dv/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/lunin-dv/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "upsell_df = create_upsell_df(days_to_add_to_experiment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsell_df =\\\n",
    "upsell_df.sort_values(by='end_date_before_consumption').groupby('billing_account_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsell_df = pd.merge(upsell_df, res_df, on='billing_account_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsell_df['last_active_billing'] = upsell_df[['last_active_billing', 'billing_account_id']].apply(\n",
    "    lambda row: row['last_active_billing'] if not pd.isnull(row['last_active_billing']) else\n",
    "                row['billing_account_id'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsell_df = upsell_df[['lead_id', \n",
    "                       'billing_account_id', \n",
    "                       'last_state',\n",
    "                       'end_date_before_consumption',\n",
    "                       'lead_source_description',\n",
    "                       'start_date_after_consumption',\n",
    "                       'status',\n",
    "                       'last_active_billing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsell_grouped = upsell_df.groupby('last_active_billing')\n",
    "row_array_new  = []\n",
    "for bill, curr_df in upsell_grouped:\n",
    "    for status in [\"win\", 'converted', 'disqualified', 'unreachible']:\n",
    "        if len(curr_df[curr_df['status'] == status]) > 0:\n",
    "            curr_df = curr_df[curr_df['status'] == status]\n",
    "            curr_df = curr_df.sort_values(by=['end_date_before_consumption'])\n",
    "            row_array_new.append(curr_df.iloc[0])\n",
    "\n",
    "upsell_df = pd.DataFrame(row_array_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_in_days = [i for i in range(1, 121, 1)]\n",
    "df = add_to_dataframe_consumption_by_days(upsell_df, periods_in_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_in_days_small = [i for i in range(1, 121, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_in_days_large = [i for i in range(1, 365, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = add_to_dataframe_consumption_after_experiment_reversed(df, periods_in_days_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_to_dataframe_difference_in_checks(\n",
    "    df, periods_in_days_small,\n",
    "    specific_columns=['before_consumption_14',\n",
    "                      'after_consumption_30', \n",
    "                      'after_consumption_60', \n",
    "                      'after_consumption_90'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_array(row, indexes, start_part):\n",
    "    arr = []\n",
    "    for ind in indexes:\n",
    "        if (datetime.now() - pd.to_datetime(row[\"start_date_after_consumption\"])\n",
    "                      ).days > ind:\n",
    "            arr.append(row[start_part + f\"{ind}\"])\n",
    "        else:\n",
    "            arr.append(None)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"consumption_difference_array\"] = df.apply(lambda row: \n",
    "                        make_array(row,\n",
    "                                   periods_in_days_small,\n",
    "                                   \"consumption_difference_period_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_consumption_array(row, indexes):\n",
    "    arr = []\n",
    "    indexes = range(min(indexes), max(indexes))\n",
    "    for ind in indexes:\n",
    "        if (datetime.now() - pd.to_datetime(row[\"start_date_after_consumption\"])\n",
    "           ).days > ind and ind in indexes:\n",
    "            mul_factor = (datetime.now() -\n",
    "                          pd.to_datetime(row[\"start_date_after_consumption\"])).days - ind\n",
    "            arr.append(row[f\"after_reversed_consumption_{ind}\"] - \n",
    "                       (row[\"before_consumption_14\"] * mul_factor / 14))\n",
    "        else:\n",
    "            arr.append(None)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"consumption_difference_array_all_days\"] = df.apply(lambda row: \n",
    "                        make_all_consumption_array(row, periods_in_days_large), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"after_consumption_array\"] = df.apply(lambda row: \n",
    "                        make_array(row, periods_in_days_small, \n",
    "                                   \"after_consumption_in_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"before_consumption_array\"] = df.apply(lambda row: \n",
    "                        make_array(row, periods_in_days_small, \n",
    "                                   \"before_consumption_in_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(row):\n",
    "    return list(reversed(row[\"before_consumption_array\"])) +\\\n",
    "    [row[\"after_consumption_array\"][0]] + row[\"after_consumption_array\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"consumption_array\"] = df.apply(lambda row: concat(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"days_30_revenue\"] = df[\"after_consumption_30\"] - (df[\"before_consumption_14\"] * 30 / 14)\n",
    "\n",
    "df[\"days_60_revenue\"] = df[\"after_consumption_60\"] - (df[\"before_consumption_14\"] * 60 / 14)\n",
    "\n",
    "df[\"days_90_revenue\"] = df[\"after_consumption_90\"] - (df[\"before_consumption_14\"] * 90 / 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df[['lead_id', \n",
    "       'billing_account_id', \n",
    "       'last_state',\n",
    "       'end_date_before_consumption',\n",
    "       'lead_source_description',\n",
    "       'start_date_after_consumption',\n",
    "       'status',\n",
    "       'last_active_billing',\n",
    "       'consumption_array',\n",
    "       'consumption_difference_array_all_days',\n",
    "       'consumption_difference_array',\n",
    "       \"days_30_revenue\",\n",
    "       'days_60_revenue',\n",
    "       'days_90_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.save_table(\"upsell_call\",\n",
    "               \"//home/cloud_analytics/lunin-dv/dashboard_tables\", res,\n",
    "               schema={\"consumption_difference_array\":\"list:double\",\n",
    "                       \"consumption_array\":\"list:double\",\n",
    "                       \"consumption_difference_array_all_days\":\"list:double\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-05 12:46:31,237\tINFO\tTransfer task started: https://transfer-manager.yt.yandex-team.ru/task?id=25cdd219-faf0cd70-fc735f18-c5cd951b&tab=details&backend=production\n"
     ]
    }
   ],
   "source": [
    "lib.save_table_from_yt_to_grafana(\n",
    "    \"//home/cloud_analytics/lunin-dv/dashboard_tables/upsell_call\", \n",
    "    \"cloud_analytics.upsell_call\", sort_col=\"billing_account_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
