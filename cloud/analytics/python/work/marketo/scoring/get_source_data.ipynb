{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, datetime, ast, os,sys, pymysql, logging, requests\n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data_loader import clickhouse\n",
    "from global_variables import (\n",
    "    metrika_clickhouse_param_dict,\n",
    "    cloud_clickhouse_param_dict\n",
    ")\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, cluster, alias, token, timeout=600):\n",
    "    logger.info(\"Executing query: %s\", query)\n",
    "    proxy = \"http://{}.yt.yandex.net\".format(cluster)\n",
    "    s = requests.Session()\n",
    "    url = \"{proxy}/query?database={alias}&password={token}\".format(proxy=proxy, alias=alias, token=token)\n",
    "    resp = s.post(url, data=query, timeout=timeout)\n",
    "    if resp.status_code != 200:\n",
    "        logger.error(\"Response status: %s\", resp.status_code)\n",
    "        logger.error(\"Response headers: %s\", resp.headers)\n",
    "        logger.error(\"Response content: %s\", resp.content)\n",
    "    resp.raise_for_status()\n",
    "    rows = resp.content.strip().split('\\n')\n",
    "    logger.info(\"Time spent: %s seconds, rows returned: %s\", resp.elapsed.total_seconds(), len(rows))\n",
    "    return rows\n",
    "\n",
    "def get_last_not_empty_table(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    last_table_rows = 0\n",
    "    last_table = ''\n",
    "    for table in tables_list:\n",
    "        try:\n",
    "            table_rows = int(job.driver.get_attribute(table, 'chunk_row_count'))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if table_rows > last_table_rows:\n",
    "            last_table_rows =  table_rows\n",
    "            last_table = table\n",
    "    if last_table:\n",
    "        return last_table\n",
    "    else:\n",
    "        return tables_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chyt_execute_query(query, cluster, alias, token, columns):\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            result = execute_query(query=query, cluster=cluster, alias=alias, token=token)\n",
    "            users = pd.DataFrame([row.split('\\t') for row in result], columns = columns)\n",
    "            return users\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            i += 1\n",
    "            if i > 10:\n",
    "                print('Break Excecution')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "cluster_yt = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool'],\n",
    "    \n",
    ")\n",
    "job = cluster_yt.job()\n",
    "valid_path = get_last_not_empty_table('//home/logfeller/logs/yc-billing-export-billing-accounts-history/1h', job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 'hahn'\n",
    "alias = \"*ch_public\"\n",
    "token = '%s' % (yt_creds['value']['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    puid,\n",
    "    first_first_trial_consumption_datetime as first_trial_consumption_datetime,\n",
    "    multiIf(\n",
    "        toDate(first_first_trial_consumption_datetime) <= toDate(addDays(NOW(), -70)), 'learning_set',\n",
    "        'predict_test'\n",
    "    ) as dataset_type,\n",
    "    multiIf(\n",
    "        first_first_paid_consumption_datetime < '2020-01-01 00:00:00' AND (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')),\n",
    "        1,\n",
    "        0\n",
    "    ) as start_paid_consumption,\n",
    "    multiIf(\n",
    "        (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')),\n",
    "        0,\n",
    "        1\n",
    "    ) as is_supended,\n",
    "    multiIf(\n",
    "        ba_state = 'suspended' AND block_reason IN ('manual', 'mining'),\n",
    "        1,\n",
    "        0\n",
    "    ) as is_fraud\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        first_first_trial_consumption_datetime,\n",
    "        ba_state,\n",
    "        block_reason,\n",
    "        addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "        multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "    FROM\n",
    "        \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "    WHERE\n",
    "        event = 'first_trial_consumption'\n",
    "        AND toDate(event_time) > toDate('2018-12-10')\n",
    "        AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    ")\n",
    "WHERE\n",
    "    toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    "'''\n",
    "columns = ['puid', 'first_trial_consumption_datetime', 'dataset_type', 'start_paid_consumption', 'is_supended', 'is_fraud']\n",
    "users = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "int_cols = ['start_paid_consumption', 'is_supended']\n",
    "for col in int_cols:\n",
    "    users[col] = users[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11060\n",
       "1     6726\n",
       "Name: is_supended, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.is_supended.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14306\n",
       "1     3480\n",
       "Name: is_fraud, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.is_fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    t0.puid,\n",
    "    multiIf(start_compute < '2020-01-01 00:00:00'  AND (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')), 1,0) as start_compute,\n",
    "    multiIf(start_mdb < '2020-01-01 00:00:00'  AND (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')), 1,0) as start_mdb,\n",
    "    multiIf(start_storage < '2020-01-01 00:00:00'  AND (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')), 1,0) as start_storage,\n",
    "    multiIf(start_ai < '2020-01-01 00:00:00'  AND (ba_state != 'suspended' OR (ba_state = 'suspended' AND block_reason = 'trial_expired')), 1,0) as start_ai\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        ba_state,\n",
    "        block_reason,\n",
    "        MAX(multiIf(service_name = 'compute', time, '2020-01-01 00:00:00')) as start_compute,\n",
    "        MAX(multiIf(service_name = 'mdb', time, '2020-01-01 00:00:00')) as start_mdb,\n",
    "        MAX(multiIf(service_name = 'storage', time, '2020-01-01 00:00:00')) as start_storage,\n",
    "        MAX(multiIf(service_name = 'cloud_ai', time, '2020-01-01 00:00:00')) as start_ai\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            ba_state,\n",
    "            block_reason,\n",
    "            multiIf(service_name LIKE '%mdb%', 'mdb', service_name) as service_name,\n",
    "            MIN(event_time) as time\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            event = 'day_use'\n",
    "            AND multiIf(service_name LIKE '%mdb%', 'mdb', service_name) IN ('compute', 'mdb', 'cloud_ai', 'storage')\n",
    "            AND real_consumption > 0\n",
    "        GROUP BY\n",
    "            puid,\n",
    "            ba_state,\n",
    "            block_reason,\n",
    "            service_name\n",
    "    )\n",
    "    GROUP BY\n",
    "        puid,\n",
    "        ba_state,\n",
    "        block_reason\n",
    "    ) as t0\n",
    "ANY INNER JOIN(\n",
    "    SELECT\n",
    "        puid\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            first_first_trial_consumption_datetime,\n",
    "            addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "            multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            event = 'first_trial_consumption'\n",
    "            AND toDate(event_time) > toDate('2018-12-10')\n",
    "            AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "    )\n",
    "    WHERE\n",
    "        toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    ") as t1\n",
    "ON t0.puid = t1.puid\n",
    "'''\n",
    "\n",
    "columns = ['puid', 'start_compute', 'start_mdb', 'start_storage', 'start_ai']\n",
    "\n",
    "users_services = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "int_cols = ['start_compute', 'start_mdb', 'start_storage', 'start_ai']\n",
    "for col in int_cols:\n",
    "    users_services[col] = users_services[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'puid',\n",
    "    'all_paid_consumption',\n",
    "    'all_trial_consumption_count',\n",
    "    'all_trial_consumption_sum',\n",
    "    'all_trial_consumption_avg',\n",
    "    'all_trial_consumption_max',\n",
    "    'all_trial_consumption_min',\n",
    "    'all_trial_consumption_median',\n",
    "    'all_trial_consumption_std',\n",
    "    'all_trial_consumption_count_more_avg',\n",
    "    'mdb_trial_consumption_count',\n",
    "    'mdb_trial_consumption_sum',\n",
    "    'mdb_trial_consumption_avg',\n",
    "    'mdb_trial_consumption_max',\n",
    "    'mdb_trial_consumption_min',\n",
    "    'mdb_trial_consumption_median',\n",
    "    'mdb_trial_consumption_std',\n",
    "    'mdb_trial_consumption_count_more_avg',\n",
    "    'ai_trial_consumption_count',\n",
    "    'ai_trial_consumption_sum',\n",
    "    'ai_trial_consumption_avg',\n",
    "    'ai_trial_consumption_max',\n",
    "    'ai_trial_consumption_min',\n",
    "    'ai_trial_consumption_median',\n",
    "    'ai_trial_consumption_std',\n",
    "    'ai_trial_consumption_count_more_avg',\n",
    "    'storage_trial_consumption_count',\n",
    "    'storage_trial_consumption_sum',\n",
    "    'storage_trial_consumption_avg',\n",
    "    'storage_trial_consumption_max',\n",
    "    'storage_trial_consumption_min',\n",
    "    'storage_trial_consumption_median',\n",
    "    'storage_trial_consumption_std',\n",
    "    'storage_trial_consumption_count_more_avg',\n",
    "    'network_trial_consumption_count',\n",
    "    'network_trial_consumption_sum',\n",
    "    'network_trial_consumption_avg',\n",
    "    'network_trial_consumption_max',\n",
    "    'network_trial_consumption_min',\n",
    "    'network_trial_consumption_median',\n",
    "    'network_trial_consumption_std',\n",
    "    'network_trial_consumption_count_more_avg',\n",
    "    'nlb_trial_consumption_count',\n",
    "    'nlb_trial_consumption_sum',\n",
    "    'nlb_trial_consumption_avg',\n",
    "    'nlb_trial_consumption_max',\n",
    "    'nlb_trial_consumption_min',\n",
    "    'nlb_trial_consumption_median',\n",
    "    'nlb_trial_consumption_std',\n",
    "    'nlb_trial_consumption_count_more_avg',\n",
    "    'marketplace_trial_consumption_count',\n",
    "    'marketplace_trial_consumption_sum',\n",
    "    'marketplace_trial_consumption_avg',\n",
    "    'marketplace_trial_consumption_max',\n",
    "    'marketplace_trial_consumption_min',\n",
    "    'marketplace_trial_consumption_median',\n",
    "    'marketplace_trial_consumption_std',\n",
    "    'marketplace_trial_consumption_count_more_avg',\n",
    "    'nbs_trial_consumption_count',\n",
    "    'nbs_trial_consumption_sum',\n",
    "    'nbs_trial_consumption_avg',\n",
    "    'nbs_trial_consumption_max',\n",
    "    'nbs_trial_consumption_min',\n",
    "    'nbs_trial_consumption_median',\n",
    "    'nbs_trial_consumption_std',\n",
    "    'nbs_trial_consumption_count_more_avg',\n",
    "    'snapshot_trial_consumption_count',\n",
    "    'snapshot_trial_consumption_sum',\n",
    "    'snapshot_trial_consumption_avg',\n",
    "    'snapshot_trial_consumption_max',\n",
    "    'snapshot_trial_consumption_min',\n",
    "    'snapshot_trial_consumption_median',\n",
    "    'snapshot_trial_consumption_std',\n",
    "    'snapshot_trial_consumption_count_more_avg',\n",
    "    'image_trial_consumption_count',\n",
    "    'image_trial_consumption_sum',\n",
    "    'image_trial_consumption_avg',\n",
    "    'image_trial_consumption_max',\n",
    "    'image_trial_consumption_min',\n",
    "    'image_trial_consumption_median',\n",
    "    'image_trial_consumption_std',\n",
    "    'image_trial_consumption_count_more_avg'\n",
    "]\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    puid,\n",
    "    SUM(all_paid_consumption) as all_paid_consumption,\n",
    "    SUM(multiIf(all_trial_consumption > 0, 1,0)) as all_trial_consumption_count,\n",
    "    SUM(all_trial_consumption) as all_trial_consumption_sum,\n",
    "    AVG(all_trial_consumption) as all_trial_consumption_avg,\n",
    "    MAX(all_trial_consumption) as all_trial_consumption_max,\n",
    "    MIN(all_trial_consumption) as all_trial_consumption_min,\n",
    "    median(all_trial_consumption) as all_trial_consumption_median,\n",
    "    stddevPop(all_trial_consumption) as all_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > all_trial_consumption_avg, groupArray(all_trial_consumption))) as all_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(mdb_trial_consumption > 0, 1,0)) as mdb_trial_consumption_count,\n",
    "    SUM(mdb_trial_consumption) as mdb_trial_consumption_sum,\n",
    "    AVG(mdb_trial_consumption) as mdb_trial_consumption_avg,\n",
    "    MAX(mdb_trial_consumption) as mdb_trial_consumption_max,\n",
    "    MIN(mdb_trial_consumption) as mdb_trial_consumption_min,\n",
    "    median(mdb_trial_consumption) as mdb_trial_consumption_median,\n",
    "    stddevPop(mdb_trial_consumption) as mdb_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > mdb_trial_consumption_avg, groupArray(mdb_trial_consumption))) as mdb_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(ai_trial_consumption > 0, 1,0)) as ai_trial_consumption_count,\n",
    "    SUM(ai_trial_consumption) as ai_trial_consumption_sum,\n",
    "    AVG(ai_trial_consumption) as ai_trial_consumption_avg,\n",
    "    MAX(ai_trial_consumption) as ai_trial_consumption_max,\n",
    "    MIN(ai_trial_consumption) as ai_trial_consumption_min,\n",
    "    median(ai_trial_consumption) as ai_trial_consumption_median,\n",
    "    stddevPop(ai_trial_consumption) as ai_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > ai_trial_consumption_avg, groupArray(ai_trial_consumption))) as ai_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(storage_trial_consumption > 0, 1,0)) as storage_trial_consumption_count,\n",
    "    SUM(storage_trial_consumption) as storage_trial_consumption_sum,\n",
    "    AVG(storage_trial_consumption) as storage_trial_consumption_avg,\n",
    "    MAX(storage_trial_consumption) as storage_trial_consumption_max,\n",
    "    MIN(storage_trial_consumption) as storage_trial_consumption_min,\n",
    "    median(storage_trial_consumption) as storage_trial_consumption_median,\n",
    "    stddevPop(storage_trial_consumption) as storage_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > storage_trial_consumption_avg, groupArray(storage_trial_consumption))) as storage_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(network_trial_consumption > 0, 1,0)) as network_trial_consumption_count,\n",
    "    SUM(network_trial_consumption) as network_trial_consumption_sum,\n",
    "    AVG(network_trial_consumption) as network_trial_consumption_avg,\n",
    "    MAX(network_trial_consumption) as network_trial_consumption_max,\n",
    "    MIN(network_trial_consumption) as network_trial_consumption_min,\n",
    "    median(network_trial_consumption) as network_trial_consumption_median,\n",
    "    stddevPop(network_trial_consumption) as network_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > network_trial_consumption_avg, groupArray(network_trial_consumption))) as network_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(nlb_trial_consumption > 0, 1,0)) as nlb_trial_consumption_count,\n",
    "    SUM(nlb_trial_consumption) as nlb_trial_consumption_sum,\n",
    "    AVG(nlb_trial_consumption) as nlb_trial_consumption_avg,\n",
    "    MAX(nlb_trial_consumption) as nlb_trial_consumption_max,\n",
    "    MIN(nlb_trial_consumption) as nlb_trial_consumption_min,\n",
    "    median(nlb_trial_consumption) as nlb_trial_consumption_median,\n",
    "    stddevPop(nlb_trial_consumption) as nlb_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > nlb_trial_consumption_avg, groupArray(nlb_trial_consumption))) as nlb_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(marketplace_trial_consumption > 0, 1,0)) as marketplace_trial_consumption_count,\n",
    "    SUM(marketplace_trial_consumption) as marketplace_trial_consumption_sum,\n",
    "    AVG(marketplace_trial_consumption) as marketplace_trial_consumption_avg,\n",
    "    MAX(marketplace_trial_consumption) as marketplace_trial_consumption_max,\n",
    "    MIN(marketplace_trial_consumption) as marketplace_trial_consumption_min,\n",
    "    median(marketplace_trial_consumption) as marketplace_trial_consumption_median,\n",
    "    stddevPop(marketplace_trial_consumption) as marketplace_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > marketplace_trial_consumption_avg, groupArray(marketplace_trial_consumption))) as marketplace_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(nbs_trial_consumption > 0, 1,0)) as nbs_trial_consumption_count,\n",
    "    SUM(nbs_trial_consumption) as nbs_trial_consumption_sum,\n",
    "    AVG(nbs_trial_consumption) as nbs_trial_consumption_avg,\n",
    "    MAX(nbs_trial_consumption) as nbs_trial_consumption_max,\n",
    "    MIN(nbs_trial_consumption) as nbs_trial_consumption_min,\n",
    "    median(nbs_trial_consumption) as nbs_trial_consumption_median,\n",
    "    stddevPop(nbs_trial_consumption) as nbs_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > nbs_trial_consumption_avg, groupArray(nbs_trial_consumption))) as nbs_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(snapshot_trial_consumption > 0, 1,0)) as snapshot_trial_consumption_count,\n",
    "    SUM(snapshot_trial_consumption) as snapshot_trial_consumption_sum,\n",
    "    AVG(snapshot_trial_consumption) as snapshot_trial_consumption_avg,\n",
    "    MAX(snapshot_trial_consumption) as snapshot_trial_consumption_max,\n",
    "    MIN(snapshot_trial_consumption) as snapshot_trial_consumption_min,\n",
    "    median(snapshot_trial_consumption) as snapshot_trial_consumption_median,\n",
    "    stddevPop(snapshot_trial_consumption) as snapshot_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > snapshot_trial_consumption_avg, groupArray(snapshot_trial_consumption))) as snapshot_trial_consumption_count_more_avg,\n",
    "    SUM(multiIf(image_trial_consumption > 0, 1,0)) as image_trial_consumption_count,\n",
    "    SUM(image_trial_consumption) as image_trial_consumption_sum,\n",
    "    AVG(image_trial_consumption) as image_trial_consumption_avg,\n",
    "    MAX(image_trial_consumption) as image_trial_consumption_max,\n",
    "    MIN(image_trial_consumption) as image_trial_consumption_min,\n",
    "    median(image_trial_consumption) as image_trial_consumption_median,\n",
    "    stddevPop(image_trial_consumption) as image_trial_consumption_std,\n",
    "    arraySum(arrayMap(x -> x > image_trial_consumption_avg, groupArray(image_trial_consumption))) as image_trial_consumption_count_more_avg\n",
    "FROM(\n",
    "    SELECT\n",
    "        *\n",
    "    FROM(\n",
    "        SELECT\n",
    "            t0.puid,\n",
    "            toDate(event_time) as date,\n",
    "            SUM(trial_consumption) as all_trial_consumption,\n",
    "            SUM(real_consumption) as all_paid_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%compute%', trial_consumption, 0)) as compute_trial_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%mdb%', trial_consumption, 0)) as mdb_trial_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%_ai%', trial_consumption, 0)) as ai_trial_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%storage%', trial_consumption, 0)) as storage_trial_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%network%', trial_consumption, 0)) as network_trial_consumption,\n",
    "            SUM(multiIf(service_name LIKE '%nlb%', trial_consumption, 0)) as nlb_trial_consumption,\n",
    "            SUM(multiIf(name LIKE '%marketplace%', trial_consumption, 0)) as marketplace_trial_consumption,\n",
    "            SUM(multiIf(name LIKE '%nbs.%', trial_consumption, 0)) as nbs_trial_consumption,\n",
    "            SUM(multiIf(name LIKE '%snapshot%', trial_consumption, 0)) as snapshot_trial_consumption,\n",
    "            SUM(multiIf(name LIKE '%image%', trial_consumption, 0)) as image_trial_consumption\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\" as t0\n",
    "        WHERE\n",
    "            event = 'day_use'\n",
    "        GROUP BY\n",
    "            puid,\n",
    "            date\n",
    "    ) as t0\n",
    "    ANY INNER JOIN (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM(\n",
    "            SELECT\n",
    "                puid,\n",
    "                first_first_trial_consumption_datetime,\n",
    "                addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "                multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "            FROM\n",
    "                \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "            WHERE\n",
    "                event = 'first_trial_consumption'\n",
    "                AND toDate(event_time) > toDate('2018-12-10')\n",
    "                AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "        )\n",
    "        WHERE\n",
    "            toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    "    ) as t1 \n",
    "    ON t0.puid = t1.puid\n",
    "    WHERE  \n",
    "         t0.date < toDate(t1.last_event_datetime)\n",
    "    ORDER BY\n",
    "        puid,\n",
    "        date\n",
    ")\n",
    "GROUP BY\n",
    "    puid\n",
    "'''\n",
    "cunsumption_stat = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "float_cols = [\n",
    "    'all_paid_consumption',\n",
    "    'all_trial_consumption_count',\n",
    "    'all_trial_consumption_sum',\n",
    "    'all_trial_consumption_avg',\n",
    "    'all_trial_consumption_max',\n",
    "    'all_trial_consumption_min',\n",
    "    'all_trial_consumption_median',\n",
    "    'all_trial_consumption_std',\n",
    "    'all_trial_consumption_count_more_avg',\n",
    "    'mdb_trial_consumption_count',\n",
    "    'mdb_trial_consumption_sum',\n",
    "    'mdb_trial_consumption_avg',\n",
    "    'mdb_trial_consumption_max',\n",
    "    'mdb_trial_consumption_min',\n",
    "    'mdb_trial_consumption_median',\n",
    "    'mdb_trial_consumption_std',\n",
    "    'mdb_trial_consumption_count_more_avg',\n",
    "    'ai_trial_consumption_count',\n",
    "    'ai_trial_consumption_sum',\n",
    "    'ai_trial_consumption_avg',\n",
    "    'ai_trial_consumption_max',\n",
    "    'ai_trial_consumption_min',\n",
    "    'ai_trial_consumption_median',\n",
    "    'ai_trial_consumption_std',\n",
    "    'ai_trial_consumption_count_more_avg',\n",
    "    'storage_trial_consumption_count',\n",
    "    'storage_trial_consumption_sum',\n",
    "    'storage_trial_consumption_avg',\n",
    "    'storage_trial_consumption_max',\n",
    "    'storage_trial_consumption_min',\n",
    "    'storage_trial_consumption_median',\n",
    "    'storage_trial_consumption_std',\n",
    "    'storage_trial_consumption_count_more_avg',\n",
    "    'network_trial_consumption_count',\n",
    "    'network_trial_consumption_sum',\n",
    "    'network_trial_consumption_avg',\n",
    "    'network_trial_consumption_max',\n",
    "    'network_trial_consumption_min',\n",
    "    'network_trial_consumption_median',\n",
    "    'network_trial_consumption_std',\n",
    "    'network_trial_consumption_count_more_avg',\n",
    "    'nlb_trial_consumption_count',\n",
    "    'nlb_trial_consumption_sum',\n",
    "    'nlb_trial_consumption_avg',\n",
    "    'nlb_trial_consumption_max',\n",
    "    'nlb_trial_consumption_min',\n",
    "    'nlb_trial_consumption_median',\n",
    "    'nlb_trial_consumption_std',\n",
    "    'nlb_trial_consumption_count_more_avg',\n",
    "    'marketplace_trial_consumption_count',\n",
    "    'marketplace_trial_consumption_sum',\n",
    "    'marketplace_trial_consumption_avg',\n",
    "    'marketplace_trial_consumption_max',\n",
    "    'marketplace_trial_consumption_min',\n",
    "    'marketplace_trial_consumption_median',\n",
    "    'marketplace_trial_consumption_std',\n",
    "    'marketplace_trial_consumption_count_more_avg',\n",
    "    'nbs_trial_consumption_count',\n",
    "    'nbs_trial_consumption_sum',\n",
    "    'nbs_trial_consumption_avg',\n",
    "    'nbs_trial_consumption_max',\n",
    "    'nbs_trial_consumption_min',\n",
    "    'nbs_trial_consumption_median',\n",
    "    'nbs_trial_consumption_std',\n",
    "    'nbs_trial_consumption_count_more_avg',\n",
    "    'snapshot_trial_consumption_count',\n",
    "    'snapshot_trial_consumption_sum',\n",
    "    'snapshot_trial_consumption_avg',\n",
    "    'snapshot_trial_consumption_max',\n",
    "    'snapshot_trial_consumption_min',\n",
    "    'snapshot_trial_consumption_median',\n",
    "    'snapshot_trial_consumption_std',\n",
    "    'snapshot_trial_consumption_count_more_avg',\n",
    "    'image_trial_consumption_count',\n",
    "    'image_trial_consumption_sum',\n",
    "    'image_trial_consumption_avg',\n",
    "    'image_trial_consumption_max',\n",
    "    'image_trial_consumption_min',\n",
    "    'image_trial_consumption_median',\n",
    "    'image_trial_consumption_std',\n",
    "    'image_trial_consumption_count_more_avg'\n",
    "]\n",
    "for col in float_cols:\n",
    "    cunsumption_stat[col] = cunsumption_stat[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    t0.puid,\n",
    "    multiIf(unreachible_count = calls, 0, 1) as is_reachible\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        groupArray(event_time) as event_times,\n",
    "        groupArray(call_status) as call_statuses,\n",
    "        arraySum(arrayMap(x -> x LIKE '%unreachible%', call_statuses)) as unreachible_count,\n",
    "        arrayCount(arrayMap(x -> x IS NOT NULL, call_statuses)) as calls,\n",
    "        event_times[1] as first_call_dt\n",
    "    FROM(\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/crm_leads/cube\"\n",
    "        WHERE\n",
    "            event = 'call'\n",
    "            AND puid != ''\n",
    "            AND puid != '0'\n",
    "        ORDER BY\n",
    "            puid,\n",
    "            event_time\n",
    "    )\n",
    "    GROUP BY \n",
    "        puid\n",
    ") as t0\n",
    "ANY INNER JOIN (\n",
    "    SELECT\n",
    "        *\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            first_first_trial_consumption_datetime,\n",
    "            addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "            multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            event = 'first_trial_consumption'\n",
    "            AND toDate(event_time) > toDate('2018-12-10')\n",
    "            AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "    )\n",
    "    WHERE\n",
    "        toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    ") as t1 \n",
    "ON t0.puid = t1.puid\n",
    "WHERE  \n",
    "     toDate(t0.first_call_dt) > toDate(t1.last_event_datetime)\n",
    "'''\n",
    "columns = ['puid', 'is_reachible']\n",
    "calls = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "calls['is_reachible'] = calls['is_reachible'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'puid',\n",
    "    'segment',\n",
    "    'is_yandex_email',\n",
    "    'is_corporate_email',\n",
    "    'mobile_phone_vendor',\n",
    "    'device_type',\n",
    "    'days_between_first_visit_cloud',\n",
    "    'days_between_cloud_ba',\n",
    "    'hits',\n",
    "    'os',\n",
    "    'is_robot',\n",
    "    'total_visits',\n",
    "    'interests',\n",
    "    'sex',\n",
    "    'age',\n",
    "    'session_start_time',\n",
    "    'ad_block',\n",
    "    'country',\n",
    "    'search_phrase',\n",
    "     'visit_version',\n",
    "    'income',\n",
    "    'channel',\n",
    "    'promocode_source',\n",
    "    'resolution_width',\n",
    "    'resolution_height',\n",
    "    'size_cat'\n",
    "]\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    t0.*\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        segment,\n",
    "        multiIf(email LIKE '%@yandex.%' OR email LIKE '%@ya.%', 1, 0) AS is_yandex_email,\n",
    "        multiIf(match(email,'.*@yandex\\..*|.*@ya\\..*|.*@gmail\\..*|.*@mail\\..*|.*@tut\\..*|.*@linqcorp\\..*'), 0, 1) AS is_corporate_email,\n",
    "        mobile_phone_vendor as mobile_phone_vendor,\n",
    "        multiIf(device_type = '', 'unknown', device_type) as device_type,\n",
    "        toDate(first_cloud_created_datetime) - toDate(multiIf(first_visit_datetime = '','2030-01-01 00:00:00',first_visit_datetime)) as days_between_first_visit_cloud,\n",
    "        toDate(multiIf(first_ba_created_datetime = '','2030-01-01 00:00:00',first_ba_created_datetime)) - toDate(multiIf(first_cloud_created_datetime = '','2030-01-01 00:00:00',first_cloud_created_datetime)) as days_between_cloud_ba,\n",
    "        hits,\n",
    "        lowerUTF8(multiIf(os = '', 'unknown', os)) as os,\n",
    "        CAST(multiIf(is_robot = '', '-1', is_robot) as Int32) as is_robot,\n",
    "        total_visits,\n",
    "        CAST(multiIf(interests = '', '-1', interests) as Int32) as interests,\n",
    "        multiIf(sex = '', 'unknown', sex) as sex,\n",
    "        multiIf(age = '', 'unknown', age) as age,\n",
    "        session_start_time,\n",
    "        ad_block,\n",
    "        lowerUTF8(multiIf(country = '', 'unknown', country)) as country,\n",
    "        lowerUTF8(multiIf(search_phrase = '', 'unknown', search_phrase)) as search_phrase,\n",
    "        CAST(multiIf(visit_version = '', '-1', visit_version) as Int32) as visit_version,\n",
    "        income,\n",
    "        channel,\n",
    "        promocode_source,\n",
    "        resolution_width,\n",
    "        resolution_height,\n",
    "        multiIf( resolution_height > 0, resolution_width/resolution_height, 0) as size_cat\n",
    "    FROM\n",
    "        \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "    WHERE\n",
    "        event = 'cloud_created'\n",
    ") as t0\n",
    "ANY INNER JOIN (\n",
    "    SELECT\n",
    "        *\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            first_first_trial_consumption_datetime,\n",
    "            addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "            multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            event = 'first_trial_consumption'\n",
    "            AND toDate(event_time) > toDate('2018-12-10')\n",
    "            AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "    )\n",
    "    WHERE\n",
    "        toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    ") as t1 \n",
    "ON t0.puid = t1.puid\n",
    "'''\n",
    "\n",
    "user_meta_info = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "int_cols = [\n",
    "    'is_yandex_email',\n",
    "    'mobile_phone_vendor',\n",
    "    'hits',\n",
    "    'is_robot',\n",
    "    'total_visits',\n",
    "    'interests',\n",
    "    'ad_block',\n",
    "    'visit_version',\n",
    "    'income',\n",
    "    'resolution_width',\n",
    "    'resolution_height',\n",
    "    'is_corporate_email',\n",
    "    'days_between_first_visit_cloud',\n",
    "    'days_between_cloud_ba'\n",
    "]\n",
    "float_cols = [\n",
    "    'size_cat'\n",
    "]\n",
    "for col in int_cols:\n",
    "    user_meta_info[col] = user_meta_info[col].astype(int)\n",
    "    \n",
    "for col in float_cols:\n",
    "    user_meta_info[col] = user_meta_info[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    t1.puid as puid,\n",
    "    groupArray(payment_cycle_type)[1] as ba_payment_cycle_type,\n",
    "    groupArray(state)[1] as ba_state,\n",
    "    groupArray(person_type)[1] as ba_person_type,\n",
    "    groupArray(payment_type)[1] as ba_payment_type,\n",
    "    groupArray(usage_status)[1] as ba_usage_status,\n",
    "    groupArray(type)[1] as ba_type\n",
    "FROM (\n",
    "    SELECT\n",
    "        t0.*,\n",
    "        t1.puid,\n",
    "        t1.last_event_datetime as last_event_datetime\n",
    "    FROM(\n",
    "        SELECT\n",
    "            toDateTime(updated_at) as datetime,\n",
    "            *\n",
    "        FROM\n",
    "            \"{0}\"\n",
    "    ) as t0\n",
    "    ANY INNER JOIN (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM(\n",
    "            SELECT\n",
    "                puid,\n",
    "                billing_account_id,\n",
    "                first_first_trial_consumption_datetime,\n",
    "                addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "                multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "            FROM\n",
    "                \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "            WHERE\n",
    "                event = 'first_trial_consumption'\n",
    "                AND puid != ''\n",
    "                AND toDate(event_time) > toDate('2018-12-10')\n",
    "                AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "        )\n",
    "        WHERE\n",
    "            toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    "    ) as t1 \n",
    "    ON t0.billing_account_id = t1.billing_account_id\n",
    "    WHERE\n",
    "        toDate(t0.datetime) < toDate(t1.last_event_datetime)\n",
    "    ORDER BY\n",
    "        puid,\n",
    "        datetime DESC\n",
    ")\n",
    "GROUP BY\n",
    "    puid\n",
    "'''.format(valid_path)\n",
    "\n",
    "columns = ['puid','ba_payment_cycle_type','ba_state','ba_person_type','ba_payment_type','ba_usage_status','ba_type']\n",
    "\n",
    "ba_meta_info = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    puid,\n",
    "    is_see_in_metriks\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        1 as is_see_in_metriks\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            splitByString(' ', event_time)[1] as date\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            puid != ''\n",
    "            AND event = 'visit'\n",
    "    ) as t0\n",
    "    ANY INNER JOIN (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM(\n",
    "            SELECT\n",
    "                DISTINCT puid,\n",
    "                first_first_trial_consumption_datetime,\n",
    "                addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "                multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "            FROM\n",
    "                \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "            WHERE\n",
    "                event = 'first_trial_consumption'\n",
    "                AND toDate(event_time) > toDate('2018-12-10')\n",
    "                AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "        )\n",
    "        WHERE\n",
    "            toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    "    ) as t1 \n",
    "    ON t0.puid = t1.puid\n",
    "    WHERE \n",
    "        toDate(t0.date) < toDate(t1.last_event_datetime)\n",
    ")\n",
    "'''\n",
    "\n",
    "columns = ['puid', 'is_see_in_metriks']\n",
    "metrika_site_events = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "metrika_site_events['is_see_in_metriks'] = metrika_site_events['is_see_in_metriks'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = pd.merge(\n",
    "    users,\n",
    "    users_services,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna(0)\n",
    "\n",
    "targets = pd.merge(\n",
    "    targets,\n",
    "    calls,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna(-1)\n",
    "targets\n",
    "\n",
    "cluster_yt.write('//home/cloud_analytics/scoring/targets', targets)\n",
    "\n",
    "data = pd.merge(\n",
    "    users[['puid']],\n",
    "    cunsumption_stat.drop('all_paid_consumption', axis = 1),\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna(0)\n",
    "\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    user_meta_info,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna(0)\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    ba_meta_info,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna('unknown')\n",
    "data = pd.merge(\n",
    "    data,\n",
    "    metrika_site_events,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna(0)\n",
    "\n",
    "cluster_yt.write('//home/cloud_analytics/scoring/meta_info', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    t0.*,\n",
    "    runningDifference(t0.ts) as delta\n",
    "FROM(\n",
    "    SELECT\n",
    "        puid,\n",
    "        event_type,\n",
    "        event,\n",
    "        timestamp,\n",
    "        ts,\n",
    "        splitByString('T', timestamp)[1] as date\n",
    "    FROM\n",
    "        \"//home/cloud_analytics/import/console_logs/events\"\n",
    "    WHERE\n",
    "        puid != ''\n",
    "    ORDER BY\n",
    "        puid,\n",
    "        timestamp\n",
    ") as t0\n",
    "ANY INNER JOIN (\n",
    "    SELECT\n",
    "        *\n",
    "    FROM(\n",
    "        SELECT\n",
    "            puid,\n",
    "            first_first_trial_consumption_datetime,\n",
    "            addDays(toDateTime(first_first_trial_consumption_datetime), 7) AS last_event_datetime,\n",
    "            multiIf(first_first_paid_consumption_datetime IS NULL OR first_first_paid_consumption_datetime = '','2020-01-01 00:00:00',first_first_paid_consumption_datetime) as first_first_paid_consumption_datetime\n",
    "        FROM\n",
    "            \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "        WHERE\n",
    "            event = 'first_trial_consumption'\n",
    "            AND toDate(event_time) > toDate('2018-12-10')\n",
    "            AND toDate(event_time) <= toDate(addDays(NOW(), -8))\n",
    "    )\n",
    "    WHERE\n",
    "        toDateTime(first_first_paid_consumption_datetime) > toDateTime(last_event_datetime)\n",
    ") as t1 \n",
    "ON t0.puid = t1.puid\n",
    "WHERE \n",
    "    toDate(t0.date) < toDate(t1.last_event_datetime)\n",
    "'''\n",
    "\n",
    "columns=['puid','event_type','event','timestamp','ts','date', 'delta']\n",
    "site_events = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "\n",
    "cluster_yt.write('//home/cloud_analytics/scoring/events', site_events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
