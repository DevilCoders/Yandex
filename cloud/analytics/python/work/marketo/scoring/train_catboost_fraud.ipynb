{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, catboost, logging, os, sys, requests, datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, roc_auc_score\n",
    "import scipy.stats as stats \n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_loader import clickhouse\n",
    "from global_variables import (\n",
    "    metrika_clickhouse_param_dict,\n",
    "    cloud_clickhouse_param_dict\n",
    ")\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances\n",
    "\n",
    "def execute_query(query, cluster, alias, token, timeout=600):\n",
    "    proxy = \"http://{}.yt.yandex.net\".format(cluster)\n",
    "    s = requests.Session()\n",
    "    url = \"{proxy}/query?database={alias}&password={token}\".format(proxy=proxy, alias=alias, token=token)\n",
    "    resp = s.post(url, data=query, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    rows = resp.content.strip().split('\\n')\n",
    "    return rows\n",
    "\n",
    "def chyt_execute_query(query, cluster, alias, token, columns):\n",
    "    i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            result = execute_query(query=query, cluster=cluster, alias=alias, token=token)\n",
    "            users = pd.DataFrame([row.split('\\t') for row in result], columns = columns)\n",
    "            return users\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            i += 1\n",
    "            if i > 10:\n",
    "                print('Break Excecution')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "\n",
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "cluster_yt = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool'],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 'hahn'\n",
    "alias = \"*ch_public\"\n",
    "token = '%s' % (yt_creds['value']['token'])\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    billing_account_id,\n",
    "    puid\n",
    "FROM \"//home/cloud_analytics_test/cubes/acquisition_cube/cube\"\n",
    "WHERE \n",
    "    event = 'ba_created'\n",
    "    AND puid != ''\n",
    "'''\n",
    "\n",
    "columns = ['billing_account_id', 'puid']\n",
    "puids = chyt_execute_query(query=query, cluster=cluster, alias=alias, token=token, columns = columns)\n",
    "\n",
    "features = cluster_yt.read('//home/cloud_analytics/scoring/learning_dataset').as_dataframe()\n",
    "targets = cluster_yt.read('//home/cloud_analytics/scoring/targets').as_dataframe()\n",
    "\n",
    "train_data = pd.merge(\n",
    "    targets[targets['dataset_type'] == 'learning_set'][['puid', 'first_trial_consumption_datetime', 'is_fraud']],\n",
    "    features,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna('0')\n",
    "\n",
    "to_predict = pd.merge(\n",
    "    targets[targets['dataset_type'] != 'learning_set'][['puid', 'first_trial_consumption_datetime', 'is_fraud']],\n",
    "    features,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna('0')\n",
    "\n",
    "train_data = shuffle(train_data).reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( train_data, train_data['is_fraud'], test_size=0.33)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split( X_train, y_train, test_size=0.25)\n",
    "positive = X_train[y_train == 1]\n",
    "res = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    X_train = pd.concat(\n",
    "        [\n",
    "            X_train,\n",
    "            positive\n",
    "        ]\n",
    "    )\n",
    "    y_train = pd.concat(\n",
    "        [\n",
    "            y_train,\n",
    "            pd.Series([1]*positive.shape[0])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "cat_col = [\n",
    "    'ba_payment_type',\n",
    "    'ba_usage_status',\n",
    "    'ba_state',\n",
    "    'device_type',\n",
    "    'ba_person_type',\n",
    "    'age',\n",
    "    'ba_payment_cycle_type',\n",
    "    'ba_type',\n",
    "    'channel',\n",
    "    'country',\n",
    "    'os',\n",
    "    'promocode_source',\n",
    "    'segment',\n",
    "    'sex',\n",
    "    'first_trial_consumption_datetime',\n",
    "    'session_start_time',\n",
    "    'search_phrase',\n",
    "    'is_fraud',\n",
    "    'puid'\n",
    "]\n",
    "cat_indexes = []\n",
    "for col in cat_col:\n",
    "    cat_indexes.append(X_train.columns.get_loc(col))\n",
    "\n",
    "ignore_col = [\n",
    "'first_trial_consumption_datetime','session_start_time','search_phrase','is_fraud', 'puid'\n",
    "]\n",
    "ignore_indexes = []\n",
    "for col in ignore_col:\n",
    "    ignore_indexes.append(X_train.columns.get_loc(col))\n",
    "\n",
    "site_metrics = []\n",
    "other_metrics = []\n",
    "for col in X_test:\n",
    "    if 'count_v' in col or 'tfidf_' in col:\n",
    "        site_metrics.append(col)\n",
    "    else:\n",
    "        other_metrics.append(col)\n",
    "\n",
    "features.shape[0]\n",
    "site_metric_new = []\n",
    "for col in site_metrics:\n",
    "    temp = features[col].value_counts()[0]\n",
    "    if features[col].value_counts()[0]/float(features.shape[0]) < 0.95:\n",
    "        site_metric_new.append(col)\n",
    "\n",
    "list_columns = other_metrics + site_metric_new\n",
    "\n",
    "\n",
    "X_train['rand'] = np.random.rand(X_train.shape[0])\n",
    "X_eval['rand'] = np.random.rand(X_eval.shape[0])\n",
    "X_test['rand'] = np.random.rand(X_test.shape[0])\n",
    "to_predict['rand'] = np.random.rand(to_predict.shape[0])\n",
    "\n",
    "train_pool = catboost.Pool(X_train, y_train, cat_features = cat_indexes)\n",
    "eval_pool = catboost.Pool(X_eval, y_eval, cat_features = cat_indexes)\n",
    "test_pool = catboost.Pool(X_test, cat_features = cat_indexes)\n",
    "predict_pool = catboost.Pool(to_predict, cat_features = cat_indexes)\n",
    "\n",
    "learning_rate = 0.5\n",
    "subsample = 0.3\n",
    "bootstrap_type = 'Bernoulli'\n",
    "depth = 1\n",
    "\n",
    "model = catboost.CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=depth,\n",
    "    learning_rate=learning_rate,\n",
    "    bootstrap_type = bootstrap_type,\n",
    "    subsample = subsample,\n",
    "    loss_function='Logloss',\n",
    "    ignored_features = ignore_indexes,\n",
    "    verbose=False\n",
    ")\n",
    "model.fit(train_pool, eval_set = eval_pool, plot = False, early_stopping_rounds = 20,use_best_model = True)\n",
    "\n",
    "metris_dict = {\n",
    "    'confusion_matrix': confusion_matrix(y_test, model.predict(test_pool)),\n",
    "    'recall': recall_score(y_test, model.predict(test_pool)),\n",
    "    'precision': precision_score(y_test, model.predict(test_pool)),\n",
    "    'roc_auc': roc_auc_score(y_test, model.predict(test_pool))\n",
    "}\n",
    "print('confusion_matrix = \\n%s\\n' % (metris_dict['confusion_matrix']))\n",
    "print('recall = %s\\n' % (metris_dict['recall']))\n",
    "print('precision = %s' % (metris_dict['precision']))\n",
    "print('roc_auc = %s' % (metris_dict['roc_auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame([model.feature_names_,model.feature_importances_]).T.rename(columns={0:'feature', 1: 'score'}).sort_values(by = 'score', ascending = False)\n",
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
