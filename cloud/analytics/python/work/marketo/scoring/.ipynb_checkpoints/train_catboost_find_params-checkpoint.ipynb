{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, catboost, logging, os, sys, requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data_loader import clickhouse\n",
    "from global_variables import (\n",
    "    metrika_clickhouse_param_dict,\n",
    "    cloud_clickhouse_param_dict\n",
    ")\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "cluster_yt = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool'],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = cluster_yt.read('//home/cloud_analytics/scoring/learning_dataset').as_dataframe()\n",
    "targets = cluster_yt.read('//home/cloud_analytics/scoring/targets').as_dataframe()\n",
    "\n",
    "train_data = pd.merge(\n",
    "    targets[targets['dataset_type'] == 'learning_set'][['puid', 'first_trial_consumption_datetime', 'start_paid_consumption']],\n",
    "    features,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna('0')\n",
    "\n",
    "to_predict = pd.merge(\n",
    "    targets[targets['dataset_type'] != 'learning_set'][['puid', 'first_trial_consumption_datetime', 'start_paid_consumption']],\n",
    "    features,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ").fillna('0')\n",
    "\n",
    "train_data = shuffle(train_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( train_data, train_data['start_paid_consumption'], test_size=0.33, random_state=42)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split( X_train, y_train, test_size=0.25, random_state=42)\n",
    "positive = X_train[y_train == 1]\n",
    "res = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    X_train = pd.concat(\n",
    "        [\n",
    "            X_train,\n",
    "            positive\n",
    "        ]\n",
    "    )\n",
    "    y_train = pd.concat(\n",
    "        [\n",
    "            y_train,\n",
    "            pd.Series([1]*positive.shape[0])\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "cat_col = [\n",
    "    'ba_payment_type',\n",
    "    'ba_usage_status',\n",
    "    'ba_state',\n",
    "    'device_type',\n",
    "    'ba_person_type',\n",
    "    'age',\n",
    "    'ba_payment_cycle_type',\n",
    "    'ba_type',\n",
    "    'channel',\n",
    "    'country',\n",
    "    'os',\n",
    "    'promocode_source',\n",
    "    'segment',\n",
    "    'sex',\n",
    "    'first_trial_consumption_datetime',\n",
    "    'session_start_time',\n",
    "    'search_phrase',\n",
    "    'start_paid_consumption',\n",
    "    'puid'\n",
    "]\n",
    "cat_indexes = []\n",
    "for col in cat_col:\n",
    "    cat_indexes.append(X_train.columns.get_loc(col))\n",
    "    \n",
    "ignore_col = [\n",
    "'first_trial_consumption_datetime','session_start_time','search_phrase','start_paid_consumption', 'puid'\n",
    "]\n",
    "ignore_indexes = []\n",
    "for col in ignore_col:\n",
    "    ignore_indexes.append(X_train.columns.get_loc(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ktereshin/yandex/venv/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "X_train['rand'] = np.random.rand(X_train.shape[0])\n",
    "X_eval['rand'] = np.random.rand(X_eval.shape[0])\n",
    "X_test['rand'] = np.random.rand(X_test.shape[0])\n",
    "to_predict['rand'] = np.random.rand(to_predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = catboost.Pool(X_train, y_train, cat_features = cat_indexes)\n",
    "eval_pool = catboost.Pool(X_eval, y_eval, cat_features = cat_indexes)\n",
    "test_pool = catboost.Pool(X_test, cat_features = cat_indexes)\n",
    "predict_pool = catboost.Pool(to_predict, cat_features = cat_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'bootstrap_type': ['Bernoulli','Bayesian'],\n",
    "    'subsample': [0.3, 0.5, 0.65, 0.8],\n",
    "    'depth': [1,2,3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3           0.01  0.376289   0.480263   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.662055  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3           0.05  0.469072   0.448276   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.697548  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3            0.1  0.458763   0.440594   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.692063  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3            0.5  0.494845    0.40678   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.701188  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3              1  0.427835   0.333333   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.659096  \n",
      "=============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "for val in grid['learning_rate']:\n",
    "    '''\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": grid['depth'][0],\n",
    "        \"learning_rate\": val,\n",
    "        \"bootstrap_type\": grid['bootstrap_type'][0],\n",
    "        \"subsample\": grid['subsample'][0],\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 20,\n",
    "        #'ignored_features': ignore_indexes\n",
    "    }\n",
    "\n",
    "    scores = catboost.cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=3,\n",
    "        shuffle = True,\n",
    "        verbose = False,\n",
    "        plot=False\n",
    "    )\n",
    "    '''\n",
    "    #scores = scores[scores['test-AUC-mean'] == scores['test-AUC-mean'].max()]\n",
    "    scores = pd.DataFrame([grid['depth'][0]]).rename(columns = {0: 'depth'})\n",
    "    scores['bootstrap_type'] = grid['bootstrap_type'][0]\n",
    "    scores['subsample'] = grid['subsample'][0]\n",
    "    scores['learning_rate'] = val\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=grid['depth'][0],\n",
    "        learning_rate=val,\n",
    "        bootstrap_type = grid['bootstrap_type'][0],\n",
    "        subsample = grid['subsample'][0],\n",
    "        loss_function='Logloss',\n",
    "        ignored_features = ignore_indexes,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_pool, eval_set = eval_pool, plot = False, early_stopping_rounds = 20, use_best_model = True)\n",
    "    scores['recall'] = recall_score(y_test, model.predict(test_pool))\n",
    "    scores['precision'] = precision_score(y_test, model.predict(test_pool))\n",
    "    scores['roc_auc_score'] = roc_auc_score(y_test, model.predict(test_pool))\n",
    "    res = pd.concat(\n",
    "        [\n",
    "            res,\n",
    "            scores\n",
    "        ]\n",
    "    )\n",
    "    print(scores)\n",
    "    print('=============================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3            0.5  0.494845    0.40678   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.701188  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.5            0.5  0.427835   0.342975   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.661408  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli       0.65            0.5  0.443299   0.346774   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.668149  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.8            0.5  0.463918   0.344828   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.675486  \n",
      "=============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "for val in grid['subsample']:\n",
    "    '''\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": grid['depth'][0],\n",
    "        \"learning_rate\": val,\n",
    "        \"bootstrap_type\": grid['bootstrap_type'][0],\n",
    "        \"subsample\": grid['subsample'][0],\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 20,\n",
    "        #'ignored_features': ignore_indexes\n",
    "    }\n",
    "\n",
    "    scores = catboost.cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=3,\n",
    "        shuffle = True,\n",
    "        verbose = False,\n",
    "        plot=False\n",
    "    )\n",
    "    '''\n",
    "    #scores = scores[scores['test-AUC-mean'] == scores['test-AUC-mean'].max()]\n",
    "    scores = pd.DataFrame([grid['depth'][0]]).rename(columns = {0: 'depth'})\n",
    "    scores['bootstrap_type'] = grid['bootstrap_type'][0]\n",
    "    scores['subsample'] = val\n",
    "    scores['learning_rate'] = learning_rate\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=grid['depth'][0],\n",
    "        learning_rate=learning_rate,\n",
    "        bootstrap_type = grid['bootstrap_type'][0],\n",
    "        subsample = val,\n",
    "        loss_function='Logloss',\n",
    "        ignored_features = ignore_indexes,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_pool, eval_set = eval_pool, plot = False, early_stopping_rounds = 20, use_best_model = True)\n",
    "    scores['recall'] = recall_score(y_test, model.predict(test_pool))\n",
    "    scores['precision'] = precision_score(y_test, model.predict(test_pool))\n",
    "    scores['roc_auc_score'] = roc_auc_score(y_test, model.predict(test_pool))\n",
    "    res = pd.concat(\n",
    "        [\n",
    "            res,\n",
    "            scores\n",
    "        ]\n",
    "    )\n",
    "    print(scores)\n",
    "    print('=============================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3            0.5  0.515464        0.4   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.708194  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1       Bayesian        0.3            0.5  0.458763   0.366255   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.678523  \n",
      "=============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "for val in grid['bootstrap_type']:\n",
    "    '''\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": grid['depth'][0],\n",
    "        \"learning_rate\": val,\n",
    "        \"bootstrap_type\": grid['bootstrap_type'][0],\n",
    "        \"subsample\": grid['subsample'][0],\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 20,\n",
    "        #'ignored_features': ignore_indexes\n",
    "    }\n",
    "\n",
    "    scores = catboost.cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=3,\n",
    "        shuffle = True,\n",
    "        verbose = False,\n",
    "        plot=False\n",
    "    )\n",
    "    '''\n",
    "    #scores = scores[scores['test-AUC-mean'] == scores['test-AUC-mean'].max()]\n",
    "    scores = pd.DataFrame([grid['depth'][0]]).rename(columns = {0: 'depth'})\n",
    "    scores['bootstrap_type'] = val\n",
    "    scores['subsample'] = subsample\n",
    "    scores['learning_rate'] = learning_rate\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=grid['depth'][0],\n",
    "        learning_rate=learning_rate,\n",
    "        bootstrap_type = val,\n",
    "        #subsample = val,\n",
    "        loss_function='Logloss',\n",
    "        ignored_features = ignore_indexes,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_pool, eval_set = eval_pool, plot = False, early_stopping_rounds = 20, use_best_model = True)\n",
    "    scores['recall'] = recall_score(y_test, model.predict(test_pool))\n",
    "    scores['precision'] = precision_score(y_test, model.predict(test_pool))\n",
    "    scores['roc_auc_score'] = roc_auc_score(y_test, model.predict(test_pool))\n",
    "    res = pd.concat(\n",
    "        [\n",
    "            res,\n",
    "            scores\n",
    "        ]\n",
    "    )\n",
    "    print(scores)\n",
    "    print('=============================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_type = 'Bernoulli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      1      Bernoulli        0.3            0.5  0.494845    0.40678   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.701188  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate    recall  precision  \\\n",
      "0      2      Bernoulli        0.3            0.5  0.350515   0.371585   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.637279  \n",
      "=============================\n",
      "\n",
      "\n",
      "   depth bootstrap_type  subsample  learning_rate   recall  precision  \\\n",
      "0      3      Bernoulli        0.3            0.5  0.28866   0.325581   \n",
      "\n",
      "   roc_auc_score  \n",
      "0       0.606021  \n",
      "=============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame()\n",
    "for val in grid['depth']:\n",
    "    '''\n",
    "    params = {\n",
    "        \"iterations\": 300,\n",
    "        \"depth\": grid['depth'][0],\n",
    "        \"learning_rate\": val,\n",
    "        \"bootstrap_type\": grid['bootstrap_type'][0],\n",
    "        \"subsample\": grid['subsample'][0],\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"verbose\": False,\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 20,\n",
    "        #'ignored_features': ignore_indexes\n",
    "    }\n",
    "\n",
    "    scores = catboost.cv(\n",
    "        train_pool,\n",
    "        params,\n",
    "        fold_count=3,\n",
    "        shuffle = True,\n",
    "        verbose = False,\n",
    "        plot=False\n",
    "    )\n",
    "    '''\n",
    "    #scores = scores[scores['test-AUC-mean'] == scores['test-AUC-mean'].max()]\n",
    "    scores = pd.DataFrame([val]).rename(columns = {0: 'depth'})\n",
    "    scores['bootstrap_type'] = bootstrap_type\n",
    "    scores['subsample'] = subsample\n",
    "    scores['learning_rate'] = learning_rate\n",
    "\n",
    "    model = catboost.CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        depth=val,\n",
    "        learning_rate=learning_rate,\n",
    "        bootstrap_type = bootstrap_type,\n",
    "        subsample = subsample,\n",
    "        loss_function='Logloss',\n",
    "        ignored_features = ignore_indexes,\n",
    "        verbose=False\n",
    "    )\n",
    "    model.fit(train_pool, eval_set = eval_pool, plot = False, early_stopping_rounds = 20, use_best_model = True)\n",
    "    scores['recall'] = recall_score(y_test, model.predict(test_pool))\n",
    "    scores['precision'] = precision_score(y_test, model.predict(test_pool))\n",
    "    scores['roc_auc_score'] = roc_auc_score(y_test, model.predict(test_pool))\n",
    "    res = pd.concat(\n",
    "        [\n",
    "            res,\n",
    "            scores\n",
    "        ]\n",
    "    )\n",
    "    print(scores)\n",
    "    print('=============================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fc512e46250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = catboost.CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=depth,\n",
    "    learning_rate=learning_rate,\n",
    "    bootstrap_type = bootstrap_type,\n",
    "    subsample = subsample,\n",
    "    loss_function='Logloss',\n",
    "    ignored_features = ignore_indexes,\n",
    "    verbose=False\n",
    ")\n",
    "model.fit(train_pool, eval_set = eval_pool, plot = False,early_stopping_rounds = 20,use_best_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      "[[1374  140]\n",
      " [  98   96]]\n",
      "\n",
      "recall = 0.4948453608247423\n",
      "\n",
      "precision = 0.4067796610169492\n",
      "roc_auc_score = 0.7011875417069551\n"
     ]
    }
   ],
   "source": [
    "print('confusion_matrix = \\n%s\\n' % (confusion_matrix(y_test, model.predict(test_pool))))\n",
    "print('recall = %s\\n' % (recall_score(y_test, model.predict(test_pool))))\n",
    "print('precision = %s' % (precision_score(y_test, model.predict(test_pool))))\n",
    "print('roc_auc_score = %s' % (roc_auc_score(y_test, model.predict(test_pool))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ba_person_type</td>\n",
       "      <td>19.2495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ba_state</td>\n",
       "      <td>14.1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/folder...</td>\n",
       "      <td>6.95909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>marketplace_trial_consumption_count</td>\n",
       "      <td>6.56764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>tfidf_/api/compute/createinstance</td>\n",
       "      <td>4.53955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>all_trial_consumption_std</td>\n",
       "      <td>3.00656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>is_corporate_email</td>\n",
       "      <td>2.78128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>all_trial_consumption_count</td>\n",
       "      <td>2.59237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>all_trial_consumption_sum</td>\n",
       "      <td>2.54364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru</td>\n",
       "      <td>2.37391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>count_v_/api/billing/setpaidaccount</td>\n",
       "      <td>1.77958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>storage_trial_consumption_std</td>\n",
       "      <td>1.56798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>income</td>\n",
       "      <td>1.46283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>tfidf_https://cloud.yandex.ru/docs/api-design-...</td>\n",
       "      <td>1.34761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>tfidf_/api/compute/deletenetwork</td>\n",
       "      <td>1.32394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>count_v_https://cloud.yandex.ru/docs/compute</td>\n",
       "      <td>1.32259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>event2vec_47</td>\n",
       "      <td>1.26836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/billin...</td>\n",
       "      <td>1.26025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>tfidf_https://cloud.yandex.ru/docs/billing/con...</td>\n",
       "      <td>1.00558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>all_trial_consumption_min</td>\n",
       "      <td>0.951001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>event2vec_38</td>\n",
       "      <td>0.903549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>event2vec_46</td>\n",
       "      <td>0.856579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>size_cat</td>\n",
       "      <td>0.819629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>count_v_https://cloud.yandex.ru/docs/compute/q...</td>\n",
       "      <td>0.800639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>nbs_trial_consumption_std</td>\n",
       "      <td>0.781117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>tfidf_https://console.cloud.yandex.ru/folders/...</td>\n",
       "      <td>0.743425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>tfidf_https://console.cloud.yandex.ru/folders/...</td>\n",
       "      <td>0.735116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>count_v_https://cloud.yandex.ru/docs/speechkit...</td>\n",
       "      <td>0.676256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3578</th>\n",
       "      <td>tfidf_https://cloud.yandex.ru/docs/vpc/concepts</td>\n",
       "      <td>0.671942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>network_trial_consumption_avg</td>\n",
       "      <td>0.662785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>count_v_https://console.cloud.yandex.ru/_/invo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>rand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature    weight\n",
       "23                                       ba_person_type   19.2495\n",
       "24                                             ba_state   14.1254\n",
       "2157  count_v_https://console.cloud.yandex.ru/folder...   6.95909\n",
       "2263                marketplace_trial_consumption_count   6.56764\n",
       "2358                  tfidf_/api/compute/createinstance   4.53955\n",
       "19                            all_trial_consumption_std   3.00656\n",
       "2258                                 is_corporate_email   2.78128\n",
       "14                          all_trial_consumption_count   2.59237\n",
       "20                            all_trial_consumption_sum   2.54364\n",
       "1437            count_v_https://console.cloud.yandex.ru   2.37391\n",
       "37                  count_v_/api/billing/setpaidaccount   1.77958\n",
       "2326                      storage_trial_consumption_std   1.56798\n",
       "2256                                             income   1.46283\n",
       "2659  tfidf_https://cloud.yandex.ru/docs/api-design-...   1.34761\n",
       "2369                   tfidf_/api/compute/deletenetwork   1.32394\n",
       "442        count_v_https://cloud.yandex.ru/docs/compute   1.32259\n",
       "2239                                       event2vec_47   1.26836\n",
       "1533  count_v_https://console.cloud.yandex.ru/billin...   1.26025\n",
       "2680  tfidf_https://cloud.yandex.ru/docs/billing/con...   1.00558\n",
       "18                            all_trial_consumption_min  0.951001\n",
       "2229                                       event2vec_38  0.903549\n",
       "2238                                       event2vec_46  0.856579\n",
       "2311                                           size_cat  0.819629\n",
       "557   count_v_https://cloud.yandex.ru/docs/compute/q...  0.800639\n",
       "2285                          nbs_trial_consumption_std  0.781117\n",
       "3949  tfidf_https://console.cloud.yandex.ru/folders/...  0.743425\n",
       "4456  tfidf_https://console.cloud.yandex.ru/folders/...  0.735116\n",
       "1119  count_v_https://cloud.yandex.ru/docs/speechkit...  0.676256\n",
       "3578    tfidf_https://cloud.yandex.ru/docs/vpc/concepts  0.671942\n",
       "2287                      network_trial_consumption_avg  0.662785\n",
       "...                                                 ...       ...\n",
       "1480  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1481  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1482  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1483  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1484  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1485  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1486  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1487  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1488  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1489  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1490  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1491  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1492  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1494  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1509  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1495  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1496  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1497  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1498  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1499  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1500  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1501  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1502  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1503  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1504  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1505  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1506  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1507  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "1508  count_v_https://console.cloud.yandex.ru/_/invo...         0\n",
       "4495                                               rand         0\n",
       "\n",
       "[4496 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([model.feature_names_,model.feature_importances_]).T.rename(columns = {0:'feature', 1:'weight'}).sort_values(by = 'weight', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'all_trial_consumption_avg',\n",
    "    'mdb_trial_consumption_avg',\n",
    "    'ai_trial_consumption_avg',\n",
    "    'storage_trial_consumption_avg',\n",
    "    'network_trial_consumption_avg',\n",
    "    'nlb_trial_consumption_avg',\n",
    "    'marketplace_trial_consumption_avg',\n",
    "    'snapshot_trial_consumption_avg',\n",
    "    'image_trial_consumption_avg'\n",
    "]\n",
    "research = pd.concat(\n",
    "    [\n",
    "        X_test.reset_index(drop=True),\n",
    "        pd.DataFrame(model.predict_proba(test_pool)).rename(columns={0:'not_paid_prob', 1: 'paid_prob'})\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "research['paid_consumption'] = y_test\n",
    "research['prob_cat'] = research['paid_prob'].apply(lambda x: str(int(x*10)*10) + '% - ' + str(int(x*10 + 1)*10) + '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_research = pd.concat(\n",
    "    [\n",
    "        to_predict.reset_index(drop=True),\n",
    "        pd.DataFrame(model.predict_proba(predict_pool)).rename(columns={0:'not_paid_prob', 1: 'paid_prob'})\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "#predict_research['paid_consumption'] = y_test\n",
    "predict_research['prob_cat'] = predict_research['paid_prob'].apply(lambda x: str(int(x*10)*10) + '% - ' + str(int(x*10 + 1)*10) + '%' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research['prob_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = [0.0,0.1,0.2,0.3,0.4,0.5,0.6, 0.7, 0.8,0.9]\n",
    "for thr in threshold:\n",
    "    \n",
    "    research['trh_prediction'] = research['paid_prob'].apply(lambda x: 1 if x >= thr else 0)\n",
    "    print(thr, research['trh_prediction'].sum(), precision_score(y_test, research['trh_prediction']), recall_score(y_test, research['trh_prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_cluster(research, col, col_by):\n",
    "    to_vis = pd.merge(\n",
    "        research.groupby([col_by, col])['promocode_source'].count().reset_index().rename(columns = {'promocode_source':'local'}),\n",
    "        research.groupby(col_by)['promocode_source'].count().reset_index().rename(columns = {'promocode_source':'all'}),\n",
    "        on = col_by,\n",
    "        how = 'left'\n",
    "    )\n",
    "    to_vis['share'] = to_vis['local']*100/to_vis['all']\n",
    "    data = []\n",
    "    for cl in to_vis[col].unique():\n",
    "        data.append({\n",
    "            'x': list(to_vis[to_vis[col] == cl][col_by]),\n",
    "            'y': list(to_vis[to_vis[col] == cl]['share']),\n",
    "            'name': cl,\n",
    "            'type': 'bar'\n",
    "        })\n",
    "    layout = {\n",
    "      'xaxis': {'title': 'Prob Group'},\n",
    "      'yaxis': {'title': 'Share'},\n",
    "      'barmode': 'relative',\n",
    "      'title': 'Prob Group by %s' % (col)\n",
    "    }\n",
    "    iplot({'data': data, 'layout': layout})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for col in ['ba_payment_type','device_type','ba_person_type','age','channel','country','os','segment','sex']:\n",
    "    describe_cluster(research, col, 'prob_cat')\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "metric = 'all_trial_consumption_sum'\n",
    "for metric in ['all_trial_consumption_sum']:\n",
    "    data = []\n",
    "    for prob_cat in sorted(research['prob_cat'].unique()):\n",
    "        data.append(go.Box(\n",
    "            y=np.log1p(research[(research['prob_cat'] == prob_cat) & (research[metric] > 0)][metric]),\n",
    "            name = prob_cat,\n",
    "            boxpoints=False\n",
    "        ))\n",
    "    layout = go.Layout(\n",
    "        title = \"%s By %s, %s\" % (metric, 'prob_cat', research[research[metric] > 0].shape[0])\n",
    "    )\n",
    "    iplot(go.Figure(data=data,layout=layout))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_research['prob_cat'].value_counts()/predict_research.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data = []\n",
    "data.append(\n",
    "    go.Scatter(\n",
    "        x = predict_research.groupby(['first_trial_consumption_datetime'])['puid'].nunique().reset_index()['first_trial_consumption_datetime'],\n",
    "        y = predict_research.groupby(['first_trial_consumption_datetime'])['puid'].nunique().reset_index()['puid']\n",
    "    )\n",
    ")\n",
    "iplot(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data = []\n",
    "data.append(\n",
    "    go.Scatter(\n",
    "        x = predict_research[predict_research['paid_prob']>0.20].groupby(['first_trial_consumption_datetime'])['puid'].nunique().reset_index()['first_trial_consumption_datetime'],\n",
    "        y = predict_research[predict_research['paid_prob']>0.20].groupby(['first_trial_consumption_datetime'])['puid'].nunique().reset_index()['puid']\n",
    "    )\n",
    ")\n",
    "iplot(data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''describe_cluster(research, 'prob_cat', 'first_trial_consumption_datetime')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(predict_research, 'prob_cat', 'first_trial_consumption_datetime')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(query, cluster, alias, token, timeout=600):\n",
    "    logger.info(\"Executing query: %s\", query)\n",
    "    proxy = \"http://{}.yt.yandex.net\".format(cluster)\n",
    "    s = requests.Session()\n",
    "    url = \"{proxy}/query?database={alias}&password={token}\".format(proxy=proxy, alias=alias, token=token)\n",
    "    resp = s.post(url, data=query, timeout=timeout)\n",
    "    if resp.status_code != 200:\n",
    "        logger.error(\"Response status: %s\", resp.status_code)\n",
    "        logger.error(\"Response headers: %s\", resp.headers)\n",
    "        logger.error(\"Response content: %s\", resp.content)\n",
    "    resp.raise_for_status()\n",
    "    rows = resp.content.strip().split('\\n')\n",
    "    logger.info(\"Time spent: %s seconds, rows returned: %s\", resp.elapsed.total_seconds(), len(rows))\n",
    "    return rows\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 'hahn'\n",
    "alias = \"*ch_public\"\n",
    "token = '%s' % (yt_creds['value']['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    t1.puid,\n",
    "    t0.lead_source,\n",
    "    t0.call_status,\n",
    "    t1.state\n",
    "FROM(\n",
    "    SELECT\n",
    "        DISTINCT\n",
    "        billing_account_id,\n",
    "        lead_source,\n",
    "        call_status\n",
    "    FROM \"//home/cloud_analytics_test/cubes/crm_leads/cube\"\n",
    "    WHERE \n",
    "        event = 'call'\n",
    "        AND billing_account_id != ''\n",
    ") as t0\n",
    "ANY LEFT JOIN (\n",
    "    SELECT\n",
    "        DISTINCT id as billing_account_id,\n",
    "        owner_id as puid,\n",
    "        state\n",
    "    FROM \"//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-10T09:00:00\"\n",
    ") as t1 \n",
    "ON t0.billing_account_id = t1.billing_account_id\n",
    "WHERE \n",
    "    t1.puid NOT IN ('', '0')\n",
    "'''\n",
    "\n",
    "result = execute_query(query=query, cluster=cluster, alias=alias, token=token)\n",
    "\n",
    "calls = pd.DataFrame([row.split('\\t') for row in result], columns = ['puid', 'lead_source', 'call_status', 'state_calls_users'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls['puid'] = calls['puid'].astype(int)\n",
    "temp = pd.merge(\n",
    "    predict_research,\n",
    "    calls,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ")\n",
    "temp['lead_source'] = temp['lead_source'].fillna(\"doesn't lead\")\n",
    "temp['state_calls_users'] = temp['state_calls_users'].fillna(\"doesn't lead\")\n",
    "temp['call_status'] = temp['call_status'].fillna(\"doesn't lead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_research['prob_cat'].value_counts()/predict_research.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(temp, 'lead_source', 'prob_cat')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(temp, 'call_status', 'prob_cat')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    owner_id as puid,\n",
    "    state\n",
    "FROM \"//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-10T09:00:00\"\n",
    "WHERE \n",
    "    puid NOT IN ('', '0')\n",
    "'''\n",
    "\n",
    "result = execute_query(query=query, cluster=cluster, alias=alias, token=token)\n",
    "\n",
    "ba = pd.DataFrame([row.split('\\t') for row in result], columns = ['puid', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba['puid'] = ba['puid'].astype(int)\n",
    "temp = pd.merge(\n",
    "    temp,\n",
    "    ba,\n",
    "    on = 'puid',\n",
    "    how = 'left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(temp[temp['state'] != 'suspended'], 'lead_source', 'prob_cat')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(temp[(temp['state'] != 'suspended') & (temp['call_status'] != \"doesn't lead\")], 'call_status', 'prob_cat')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''describe_cluster(temp, 'state', 'prob_cat')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
