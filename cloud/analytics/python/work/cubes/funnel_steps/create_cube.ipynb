{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, datetime, ast, numpy as np, telebot, json, requests, os, sys\n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances\n",
    "\n",
    "from init_funnel_steps import (\n",
    "    paths_dict_prod,\n",
    "    paths_dict_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service(name_):\n",
    "    return str(name_).split('.')[0]\n",
    "\n",
    "\n",
    "def convert_metric_to_float(num):\n",
    "    try:\n",
    "        return float(num)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def get_payment_type(context):\n",
    "    try:\n",
    "        return ast.literal_eval(context)['payment_type']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_reason(metadata_):\n",
    "    if metadata_ not in ['', None]:\n",
    "        metadata =  json.loads(metadata_)\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    if metadata:\n",
    "        if 'block_reason' in metadata:\n",
    "            return metadata['block_reason']\n",
    "        if 'suspend_reason' in metadata:\n",
    "            return metadata['suspend_reason']\n",
    "        #if 'fraud_detected_by' in metadata:\n",
    "            #if isinstance(metadata['fraud_detected_by'], list):\n",
    "                #return metadata['fraud_detected_by'][0]\n",
    "            #else:\n",
    "                #return metadata['fraud_detected_by'].replace('[', '').replace(']', '').replace(\"u'\", '').replace(\"'\", '')\n",
    "    return 'unknown'\n",
    "\n",
    "def get_datetime_from_epoch(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "    return date_list\n",
    "\n",
    "def get_last_not_empty_table(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    last_table_rows = 0\n",
    "    last_table = ''\n",
    "    for table in tables_list:\n",
    "        try:\n",
    "            table_rows = int(job.driver.get_attribute(table, 'chunk_row_count'))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if table_rows > last_table_rows:\n",
    "            last_table_rows =  table_rows\n",
    "            last_table = table\n",
    "    if last_table:\n",
    "        return last_table\n",
    "    else:\n",
    "        return tables_list[0]\n",
    "\n",
    "\n",
    "def get_table_list(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    return '{%s}' % (','.join(tables_list))\n",
    "\n",
    "def apply_types_in_project(schema_):\n",
    "    apply_types_dict = {}\n",
    "    for col in schema_:\n",
    "        \n",
    "        if schema_[col] == str:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: str(x).replace('\"', '').replace(\"'\", '').replace('\\\\','') if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == int:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: int(x) if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == float:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: float(x) if x not in ['', None] else None, col)\n",
    "    return apply_types_dict\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def convert_epoch_to_date(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).date())\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "        \n",
    "    return date_list\n",
    "\n",
    "\n",
    "def get_ba_history(groups):\n",
    "    for key, records in groups:\n",
    "        \n",
    "        rec_list = list(records)\n",
    "        result_dict = {}\n",
    "        start_date = ''\n",
    "        owner_id = ''\n",
    "        for rec in rec_list:\n",
    "            rec_ = rec.to_dict()\n",
    "            rec_['date'] = convert_epoch_to_date(rec_['updated_at'])\n",
    "            if not start_date:\n",
    "                start_date = rec_['date']\n",
    "                \n",
    "            if 'owner_id' in rec_:\n",
    "                owner_id = rec_['owner_id']\n",
    "                \n",
    "            result_dict[rec_['date']] = rec_\n",
    "        \n",
    "        \n",
    "        \n",
    "        date_range = date_range_by_days(start_date, str(datetime.date.today()))\n",
    "        res = {}\n",
    "        for date in date_range:\n",
    "            \n",
    "            for date_ in sorted(result_dict):\n",
    "                \n",
    "                if date_ <= date:\n",
    "                    result_dict[date_]['date'] = date\n",
    "                    res = result_dict[date_]\n",
    "                else:\n",
    "                    break\n",
    "            res['owner_id'] = owner_id\n",
    "            yield Record(key, **res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/logfeller/logs/yc-billing-export-monetary-grants/1h/2019-04-17T17:00:00\n",
      "//home/cloud_analytics/import/iam/cloud_owners/1h/2019-04-17T08:50:55\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-17T17:00:00\n",
      "//home/logfeller/logs/yc-billing-export-sku/1h/2019-04-14T17:00:00\n",
      "//home/logfeller/logs/yc-billing-export-services/1d/2019-03-20\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-17T17:00:00\n",
      "//home/logfeller/logs/yc-billing-export-usage-reports/1h/2019-04-17T16:00:00\n",
      "//home/logfeller/logs/yc-billing-export-transactions/1h/2019-04-17T17:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 19:04:16,571\tWARNING\tHTTP GET request http://hahn.yt.yandex.net/api/v3/get has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: '('Connection aborted.', error(104, 'Connection reset by peer'))', headers: {'X-YT-Correlation-Id': 'e766675f-106e62f1-407c4f4c-ae18533c', 'X-YT-Parameters': '{\"path\"=\"//home/logfeller/logs/yc-billing-export-billing-accounts-history/1h/2019-04-06T01:00:00/@chunk_row_count\";\"output_format\"=\"json\";\"max_size\"=65535;}', 'Accept-Encoding': 'gzip, identity', 'X-Started-By': '{\"pid\"=195137;\"user\"=\"root\";}', 'X-YT-Header-Format': '<format=text>yson', 'User-Agent': 'Python wrapper 0.9.9'}\n",
      "2019-04-17 19:04:16,572\tWARNING\tSleep for 5.00 seconds before next retry\n",
      "2019-04-17 19:04:21,578\tWARNING\tNew retry (2) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/logfeller/logs/yc-billing-export-billing-accounts-history/1h/2019-04-17T15:00:00\n"
     ]
    }
   ],
   "source": [
    "mode = 'test'\n",
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "telebot_creds = client.get_version('ver-01d4wza60ns43j5mqktvvvwdnx')\n",
    "bot = telebot.TeleBot(telebot_creds['value']['token'])\n",
    "cluster = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool']\n",
    ")\n",
    "if mode == 'test':\n",
    "    paths_dict_temp = paths_dict_test\n",
    "elif mode == 'prod':\n",
    "    paths_dict_temp = paths_dict_prod\n",
    "paths_dict = paths_dict_temp.copy()\n",
    "\n",
    "job = cluster.job()\n",
    "for path in ['billing_grants','cloud_owner_path', 'billing_accounts_path', 'sku_path', 'service_dict_path', 'billing_accounts_path', 'billing_records_path','transactions_path', 'billing_accounts_history_path']:\n",
    "    valid_path = get_last_not_empty_table(paths_dict_temp[path], job)\n",
    "    print(valid_path)\n",
    "    paths_dict[path] = valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_grant_history(groups):\\n    for key, records in groups:\\n        rec_list = list(records)\\n        result_dict = {}\\n        start_date = \\'\\'\\n        for rec in rec_list:\\n            rec_ = rec.to_dict()\\n            rec_[\\'start_date\\'] = convert_epoch_to_date(rec_[\\'start_time\\'])\\n            rec_[\\'end_date\\'] = convert_epoch_to_date(rec_[\\'end_time\\'])\\n            rec_[\\'start_time\\'] = get_datetime_from_epoch(rec_[\\'start_time\\'])\\n            rec_[\\'end_time\\'] = get_datetime_from_epoch(rec_[\\'end_time\\'])\\n            rec_[\\'initial_amount\\'] = float(rec_[\\'initial_amount\\'])\\n            \\n            if not start_date:\\n                start_date = rec_[\\'start_date\\']\\n                \\n            result_dict[str(rec_[\\'start_time\\']) + \\'_\\' + str(rec_[\\'id\\'])] = rec_\\n        #yield Record(key, **rec_)\\n        date_range = date_range_by_days(start_date, str(datetime.date.today()))\\n        grant_rec = {}\\n        \\n        for date in date_range:\\n            \\n            net_grant = 0\\n            active_grant = 0\\n            \\n            for key in sorted(result_dict):\\n                #row_ = result_dict[date_].copy()\\n                if result_dict[key][\\'start_date\\'] <= date:\\n                    \\n                    result_dict[key][\\'date\\'] = date\\n                    \\n                    if result_dict[key][\\'end_date\\'] <= date:\\n                        net_grant += result_dict[key][\\'initial_amount\\']\\n                        active_grant += 1\\n                        \\n                    grant_rec = result_dict[key].copy()\\n                    \\n                else:\\n                    break\\n            grant_rec[\\'net_grant\\'] = net_grant\\n            grant_rec[\\'active_grants\\'] = active_grant\\n            grant_rec[\\'start_date\\'] = start_date\\n            grants_list = []\\n            for key in result_dict:\\n                grants_info = {}\\n                for opt in [\\'id\\', \\'initial_amount\\', \\'start_time\\', \\'end_time\\', \\'source\\', \\'source_id\\']:\\n                    grants_info[opt] = result_dict[key][opt]\\n                grants_list.append(grants_info)\\n                \\n            grant_rec[\\'grants_info\\'] = str(grants_list)\\n            yield Record(key, **grant_rec)\\n\\nschema = {\\n    \"active_grant\": int,\\n    \"billing_account_id\": str,\\n    \"date\": str,\\n    \"end_date\": str,\\n    \"initial_amount\": float,\\n    \"net_grant\": float,\\n    \"start_date\": str,\\n    \\'grants_info\\': str\\n}\\n\\njob = cluster.job()\\njob.table(paths_dict[\\'billing_grants\\']) .groupby(\\n    \\'billing_account_id\\'\\n) .sort(\\n    \\'start_time\\'\\n) .reduce(\\n    get_grant_history\\n) .put(\\n    paths_dict[\\'grants\\'],\\n    #schema = schema\\n)\\njob.run()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_grant_history(groups):\n",
    "    for key, records in groups:\n",
    "        rec_list = list(records)\n",
    "        result_dict = {}\n",
    "        start_date = ''\n",
    "        for rec in rec_list:\n",
    "            rec_ = rec.to_dict()\n",
    "            rec_['start_date'] = convert_epoch_to_date(rec_['start_time'])\n",
    "            rec_['end_date'] = convert_epoch_to_date(rec_['end_time'])\n",
    "            rec_['start_time'] = get_datetime_from_epoch(rec_['start_time'])\n",
    "            rec_['end_time'] = get_datetime_from_epoch(rec_['end_time'])\n",
    "            rec_['initial_amount'] = float(rec_['initial_amount'])\n",
    "            \n",
    "            if not start_date:\n",
    "                start_date = rec_['start_date']\n",
    "                \n",
    "            result_dict[str(rec_['start_time']) + '_' + str(rec_['id'])] = rec_\n",
    "        #yield Record(key, **rec_)\n",
    "        date_range = date_range_by_days(start_date, str(datetime.date.today()))\n",
    "        grant_rec = {}\n",
    "        \n",
    "        for date in date_range:\n",
    "            \n",
    "            net_grant = 0\n",
    "            active_grant = 0\n",
    "            \n",
    "            for key in sorted(result_dict):\n",
    "                #row_ = result_dict[date_].copy()\n",
    "                if result_dict[key]['start_date'] <= date:\n",
    "                    \n",
    "                    result_dict[key]['date'] = date\n",
    "                    \n",
    "                    if result_dict[key]['end_date'] <= date:\n",
    "                        net_grant += result_dict[key]['initial_amount']\n",
    "                        active_grant += 1\n",
    "                        \n",
    "                    grant_rec = result_dict[key].copy()\n",
    "                    \n",
    "                else:\n",
    "                    break\n",
    "            grant_rec['net_grant'] = net_grant\n",
    "            grant_rec['active_grants'] = active_grant\n",
    "            grant_rec['start_date'] = start_date\n",
    "            grants_list = []\n",
    "            for key in result_dict:\n",
    "                grants_info = {}\n",
    "                for opt in ['id', 'initial_amount', 'start_time', 'end_time', 'source', 'source_id']:\n",
    "                    grants_info[opt] = result_dict[key][opt]\n",
    "                grants_list.append(grants_info)\n",
    "                \n",
    "            grant_rec['grants_info'] = str(grants_list)\n",
    "            yield Record(key, **grant_rec)\n",
    "\n",
    "schema = {\n",
    "    \"active_grant\": int,\n",
    "    \"billing_account_id\": str,\n",
    "    \"date\": str,\n",
    "    \"end_date\": str,\n",
    "    \"initial_amount\": float,\n",
    "    \"net_grant\": float,\n",
    "    \"start_date\": str,\n",
    "    'grants_info': str\n",
    "}\n",
    "\n",
    "job = cluster.job()\n",
    "job.table(paths_dict['billing_grants']) \\\n",
    ".groupby(\n",
    "    'billing_account_id'\n",
    ") \\\n",
    ".sort(\n",
    "    'start_time'\n",
    ") \\\n",
    ".reduce(\n",
    "    get_grant_history\n",
    ") \\\n",
    ".put(\n",
    "    paths_dict['grants'],\n",
    "    #schema = schema\n",
    ")\n",
    "job.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da451080adb4f46a8f4a7f72af95897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-15 09:20:09,452\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ee4f6148-bc538f47-3fe03e8-a9e54d25&tab=details\n",
      "2019-04-15 09:20:31,040\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1b117335-37eddb9-3fe03e8-8e7bb20&tab=details\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    \"balance\": float,\n",
    "    \"balance_client_id\": str,\n",
    "    \"balance_contract_id\": str,\n",
    "    \"billing_account_id\": str,\n",
    "    \"billing_threshold\": str,\n",
    "    \"client_id\": str,\n",
    "    \"currency\": str,\n",
    "    \"date\": str,\n",
    "    \"feature_flags\": str,\n",
    "    \"iso_eventtime\": str,\n",
    "    \"master_account_id\": str,\n",
    "    \"metadata\": str,\n",
    "    \"name\": str,\n",
    "    \"owner_id\": str,\n",
    "    \"payment_cycle_type\": str,\n",
    "    \"payment_method_id\": str,\n",
    "    \"payment_type\": str,\n",
    "    \"person_type\": str,\n",
    "    \"state\": str,\n",
    "    \"type\": str,\n",
    "    \"updated_at\": int,\n",
    "    \"usage_status\": str,\n",
    "    \"block_reason\": str\n",
    "}\n",
    "\n",
    "job = cluster.job()\n",
    "job.table(paths_dict['billing_accounts_history_path']) \\\n",
    ".project(\n",
    "    ne.all(),\n",
    "    block_reason = ne.custom(lambda x,y:get_reason(y) if x == 'suspended' else 'Unlocked', 'state', 'metadata')\n",
    ") \\\n",
    ".groupby(\n",
    "    'billing_account_id'\n",
    ") \\\n",
    ".sort(\n",
    "    'updated_at'\n",
    ") \\\n",
    ".reduce(\n",
    "    get_ba_history\n",
    ") \\\n",
    ".project(\n",
    "    **apply_types_in_project(schema)\n",
    ") \\\n",
    ".put(paths_dict['ba_hist'], schema = schema)\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 19:14:23,995\tWARNING\tHTTP post request http://hahn.yt.yandex.net/auth/whoami has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: 'HTTPConnectionPool(host='hahn.yt.yandex.net', port=80): Max retries exceeded with url: /auth/whoami (Caused by NewConnectionError('<yt.packages.urllib3.connection.HTTPConnection object at 0x7f1e3d3ff410>: Failed to establish a new connection: [Errno 110] Connection timed out',))', headers: {'X-YT-Correlation-Id': 'a9efe82f-84d0e78b-ee7d48ee-56f582e2', 'Authorization': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'}\n",
      "2019-04-17 19:14:23,996\tWARNING\tSleep for 5.05 seconds before next retry\n",
      "2019-04-17 19:14:29,051\tWARNING\tNew retry (2) ...\n",
      "2019-04-17 19:14:36,283\tWARNING\tHTTP post request http://hahn.yt.yandex.net/auth/whoami has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: 'HTTPConnectionPool(host='hahn.yt.yandex.net', port=80): Max retries exceeded with url: /auth/whoami (Caused by NewConnectionError('<yt.packages.urllib3.connection.HTTPConnection object at 0x7f1e3d3ff650>: Failed to establish a new connection: [Errno 110] Connection timed out',))', headers: {'X-YT-Correlation-Id': 'a9efe82f-84d0e78b-ee7d48ee-56f582e2', 'Authorization': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'}\n",
      "2019-04-17 19:14:36,285\tWARNING\tSleep for 9.92 seconds before next retry\n",
      "2019-04-17 19:14:46,218\tWARNING\tNew retry (3) ...\n",
      "2019-04-17 19:14:53,435\tWARNING\tHTTP post request http://hahn.yt.yandex.net/auth/whoami has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: 'HTTPConnectionPool(host='hahn.yt.yandex.net', port=80): Max retries exceeded with url: /auth/whoami (Caused by NewConnectionError('<yt.packages.urllib3.connection.HTTPConnection object at 0x7f1e3d3ff690>: Failed to establish a new connection: [Errno 110] Connection timed out',))', headers: {'X-YT-Correlation-Id': 'a9efe82f-84d0e78b-ee7d48ee-56f582e2', 'Authorization': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'}\n",
      "2019-04-17 19:14:53,436\tWARNING\tSleep for 17.84 seconds before next retry\n",
      "2019-04-17 19:15:11,297\tWARNING\tNew retry (4) ...\n",
      "2019-04-17 19:15:18,523\tWARNING\tHTTP post request http://hahn.yt.yandex.net/auth/whoami has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: 'HTTPConnectionPool(host='hahn.yt.yandex.net', port=80): Max retries exceeded with url: /auth/whoami (Caused by NewConnectionError('<yt.packages.urllib3.connection.HTTPConnection object at 0x7f1e3d3ff890>: Failed to establish a new connection: [Errno 110] Connection timed out',))', headers: {'X-YT-Correlation-Id': 'a9efe82f-84d0e78b-ee7d48ee-56f582e2', 'Authorization': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'}\n",
      "2019-04-17 19:15:18,524\tWARNING\tSleep for 22.46 seconds before next retry\n",
      "2019-04-17 19:15:40,991\tWARNING\tNew retry (5) ...\n",
      "2019-04-17 19:15:48,219\tWARNING\tHTTP post request http://hahn.yt.yandex.net/auth/whoami has failed with error <class 'yt.packages.requests.exceptions.ConnectionError'>, message: 'HTTPConnectionPool(host='hahn.yt.yandex.net', port=80): Max retries exceeded with url: /auth/whoami (Caused by NewConnectionError('<yt.packages.urllib3.connection.HTTPConnection object at 0x7f1e3d3ff790>: Failed to establish a new connection: [Errno 110] Connection timed out',))', headers: {'X-YT-Correlation-Id': 'a9efe82f-84d0e78b-ee7d48ee-56f582e2', 'Authorization': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'}\n",
      "2019-04-17 19:15:48,221\tWARNING\tSleep for 20.00 seconds before next retry\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "\n",
    "\n",
    "#cloud created event\n",
    "clouds = job.table(paths_dict['cloud_owner_path']) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        mail_tech = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_testing = ne.custom(lambda x: 1 if x else 0, 'mail_testing'),\n",
    "        mail_info = ne.custom(lambda x: 1 if x else 0, 'mail_info'),\n",
    "        mail_feature = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_event = ne.custom(lambda x: 1 if x else 0, 'mail_event'),\n",
    "        mail_promo = ne.custom(lambda x: 1 if x else 0, 'mail_promo'),\n",
    "        mail_billing = ne.custom(lambda x: 1 if x else 0, 'mail_billing'),\n",
    "        cloud_id = 'id',\n",
    "        event = ne.const('cloud_created'),\n",
    "        event_time = ne.custom(lambda x: ' '.join(str(x).split('+')[0].split('T')), 'cloud_created_at'),\n",
    "        puid = 'passport_uid'\n",
    "    \n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        email = na.first('email', by='event_time'),\n",
    "        first_name = na.first('first_name', by='event_time'),\n",
    "        last_name = na.first('last_name', by='event_time'),\n",
    "        login = na.first('login', by='event_time'),\n",
    "        phone = na.first('phone', by='event_time'),\n",
    "        user_settings_email = na.first('user_settings_email', by='event_time'),\n",
    "        cloud_status = na.first('cloud_status', by='event_time'),\n",
    "        cloud_name = na.first('cloud_name', by='event_time'),\n",
    "        event = na.first('event', by='cloud_created_at'),\n",
    "        event_time = na.first('event_time', by='cloud_created_at'),\n",
    "        cloud_id = na.first('cloud_id', by='cloud_created_at'),\n",
    "        mail_tech = na.first('mail_tech', by='cloud_created_at'),\n",
    "        mail_testing = na.first('mail_testing', by='cloud_created_at'),\n",
    "        mail_info = na.first('mail_info', by='cloud_created_at'),\n",
    "        mail_feature = na.first('mail_feature', by='cloud_created_at'),\n",
    "        mail_event = na.first('mail_event', by='cloud_created_at'),\n",
    "        mail_promo = na.first('mail_promo', by='cloud_created_at'),\n",
    "        mail_billing = na.first('mail_billing', by='cloud_created_at')\n",
    "    )\n",
    "\n",
    "clouds_ = clouds \\\n",
    "    .unique(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        'cloud_id',\n",
    "        'puid',\n",
    "        'mail_tech',\n",
    "        'mail_testing',\n",
    "        'mail_info',\n",
    "        'mail_feature',\n",
    "        'mail_event',\n",
    "        'mail_promo',\n",
    "        'mail_billing'\n",
    "    )\n",
    "\n",
    "offers = job.table(paths_dict['offers_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in [None, ''], 'passport_uid')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'passport_uid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        promocode_client_name = 'client_name',\n",
    "        promocode_type = 'type',\n",
    "        puid = 'passport_uid',\n",
    "        promocode_source = 'client_source',\n",
    "        promocode_client_type = ne.custom(lambda x: 'Enterprise/ISV' if x == 'direct_offer' else 'Direct')\n",
    "    )\n",
    "\n",
    "segments = job.table(paths_dict['client_segments']) \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    )\n",
    "\n",
    "passports = job.table(paths_dict['balance']) \\\n",
    "    .unique(\n",
    "        'PASSPORT_ID'\n",
    "    ) \\\n",
    "    .project(\n",
    "        puid = 'PASSPORT_ID',\n",
    "        balance_name = 'NAME'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = job.table(paths_dict['billing_accounts_path']) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ba_created_at = 'created_at',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = ne.custom(lambda x,y:get_reason(y) if x == 'suspended' else 'Unlocked', 'state', 'metadata')\n",
    "    ) \\\n",
    "    .join(\n",
    "        offers,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        segments,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        passports,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = ba_puid_dict_ \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        segment = ne.custom(lambda x: x.lower() if x not in ['', None] else 'mass', 'segment')\n",
    "    )\n",
    "\n",
    "\n",
    "ba_puid_dict_hist = job.table(paths_dict['ba_hist']) \\\n",
    "    .unique(\n",
    "        'billing_account_id',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .project(\n",
    "        date = 'date',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'billing_account_id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = 'block_reason'\n",
    "    ) \\\n",
    "    .join(\n",
    "        offers,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        segments,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        passports,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_hist = ba_puid_dict_hist \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        segment = ne.custom(lambda x: x.lower() if x not in ['', None] else 'mass', 'segment')\n",
    "    ) \\\n",
    "    .unique('billing_account_id', 'date')\n",
    "\n",
    "\n",
    "\n",
    "sku_dict = job.table(paths_dict['sku_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'name',\n",
    "        'service_id',\n",
    "        sku_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "service_dict = job.table(paths_dict['service_dict_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        service_name = 'name',\n",
    "        service_description = 'description',\n",
    "        service_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "sku_dict = sku_dict \\\n",
    "    .join(\n",
    "        service_dict,\n",
    "        by = 'service_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict = ba_puid_dict_ \\\n",
    "    .join(\n",
    "        clouds_,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "bas = ba_puid_dict \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        event = ne.const('ba_created'),\n",
    "        event_time = ne.custom(get_datetime_from_epoch, 'ba_created_at')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_puid_dict__ = ba_puid_dict_.unique('puid')\n",
    "visits = job.table(paths_dict['visits_path'])\n",
    "calls = job.table(paths_dict['calls'])\n",
    "click_mail = job.table(paths_dict['click_email']) \n",
    "#open_mail = job.table(paths_dict['open_mail']) \n",
    "\n",
    "puid_sets = job.concat(\n",
    "    clouds,\n",
    "    visits,\n",
    "    calls,\n",
    "    click_mail\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict__,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        ba_name = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_name'),\n",
    "        ba_payment_cycle_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_payment_cycle_type'),\n",
    "        ba_person_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_person_type'),\n",
    "        ba_state = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_state'),\n",
    "        ba_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_type'),\n",
    "        ba_usage_status = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_usage_status'),\n",
    "        block_reason = ne.custom(lambda x: x if x else 'ba_not_created', 'block_reason'),\n",
    "        segment = ne.custom(lambda x: x if x else 'unknown', 'segment'),\n",
    "        promocode_client_name = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_name'),\n",
    "        promocode_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_type'),\n",
    "        promocode_source = ne.custom(lambda x: x if x else 'unknown', 'promocode_source'),\n",
    "        promocode_client_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_type'),\n",
    "        balance_name = ne.custom(lambda x: x if x else 'unknown', 'balance_name'),\n",
    "        sales = ne.custom(lambda x: x if x else 'unknown', 'sales'),\n",
    "        crm_client_name = ne.custom(lambda x: x if x else 'unknown', 'crm_client_name')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_became_paid = job.table(paths_dict['billing_accounts_history_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: str(x).lower() == 'paid', 'usage_status')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.min('updated_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('ba_became_paid')\n",
    "    )\n",
    "\n",
    "first_trial_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: float(x) < 0, 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:57','event_time'),\n",
    "        event = ne.const('first_trial_consumption')\n",
    "    )\n",
    "\n",
    "\n",
    "first_paid_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x, y: float(x) + float(y) > 0, 'cost', 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:58','event_time'),\n",
    "        event = ne.const('first_paid_consumption')\n",
    "    )\n",
    "\n",
    "first_payment = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        payment_type = ne.custom(get_payment_type, 'context')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('modified_at', by='modified_at'),\n",
    "        amount = na.first('amount', by='modified_at'),\n",
    "        currency = na.first('currency', by='modified_at'),\n",
    "        payment_type = na.first('payment_type', by='modified_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'amount',\n",
    "        'currency',\n",
    "        'payment_type',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('first_payment')\n",
    "    )\n",
    "\n",
    "day_use_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        trial_consumption = ne.custom(lambda x: convert_metric_to_float(x)*-1, 'credit'),\n",
    "        trial_consumption_vat = ne.custom(lambda x,y: convert_metric_to_float(x)*-1/1.18 if y < '2019-01-01' else convert_metric_to_float(x)*-1/1.2, 'credit', 'date'),\n",
    "        real_consumption = ne.custom(lambda x, y: convert_metric_to_float(x) + convert_metric_to_float(y) if x not in [None, ''] and y not in [None, ''] else 0.0,'cost', 'credit'),\n",
    "        real_consumption_vat = ne.custom(lambda x, y, z: (convert_metric_to_float(x) + convert_metric_to_float(y))/1.18 if z < '2019-01-01' else (convert_metric_to_float(x) + convert_metric_to_float(y))/1.2,'cost', 'credit', 'date'),    \n",
    "        event_time = ne.custom(lambda x: str(x) + ' 23:59:59', 'date'),\n",
    "        date = 'date',\n",
    "        event = ne.const('day_use'),\n",
    "        real_payment = ne.const(0),\n",
    "        real_payment_vat = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'event',\n",
    "        'event_time',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        trial_consumption_vat = na.sum('trial_consumption_vat'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_consumption_vat = na.sum('real_consumption_vat'),\n",
    "        real_payment = na.sum('real_payment'),\n",
    "        real_payment_vat = na.sum('real_payment_vat')\n",
    "    )\n",
    "\n",
    "day_use_payments = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'currency',\n",
    "        sku_id = ne.const(''),\n",
    "        event_time = ne.custom(convert_epoch_to_end_day, 'modified_at'),\n",
    "        real_payment = ne.custom(lambda x: convert_metric_to_float(x), 'amount'),\n",
    "        real_payment_vat = ne.custom(lambda x, y: convert_metric_to_float(x)/1.18 if convert_epoch_to_end_day(y).split(' ')[0] < '2019-01-01' else convert_metric_to_float(x)/1.2, 'amount', 'modified_at'),\n",
    "        event = ne.const('day_use'),\n",
    "        date = ne.custom(lambda x: convert_epoch_to_end_day(x).split(' ')[0], 'modified_at'),\n",
    "        trial_consumption = ne.const(0),\n",
    "        trial_consumption_vat = ne.const(0),\n",
    "        real_consumption = ne.const(0),\n",
    "        real_consumption_vat = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'event_time',\n",
    "        'event',\n",
    "        'sku_id',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        trial_consumption_vat = na.sum('trial_consumption_vat'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_consumption_vat = na.sum('real_consumption_vat'),\n",
    "        real_payment = na.sum('real_payment'),\n",
    "        real_payment_vat = na.sum('real_payment_vat')\n",
    "    )\n",
    "\n",
    "ba_sets_hist = job.concat(\n",
    "    day_use_consumption,\n",
    "    day_use_payments,\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict_hist,\n",
    "        by = ['billing_account_id', 'date'],\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        sku_dict,\n",
    "        by = 'sku_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_sets = job.concat(\n",
    "    first_payment,\n",
    "    first_paid_consumption,\n",
    "    first_trial_consumption,\n",
    "    ba_became_paid\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        sku_dict,\n",
    "        by = 'sku_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "result = job.concat(\n",
    "        bas,\n",
    "        puid_sets,\n",
    "        ba_sets,\n",
    "        ba_sets_hist\n",
    "    )\n",
    "\n",
    "result.put('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_delta(new_date, old_date):\n",
    "    try:\n",
    "        return (datetime.datetime.strptime(new_date, '%Y-%m-%d %H:%M:%S') - datetime.datetime.strptime(old_date, '%Y-%m-%d %H:%M:%S')).seconds\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def apply_attr(result_dict_, last_visit_dict_):\n",
    "    for col in last_visit_dict_:\n",
    "        try:\n",
    "            result_dict_[col] = last_visit_dict_[col]\n",
    "            \n",
    "        except:\n",
    "            result_dict_[col ] = None\n",
    "    \n",
    "    result_dict_['session_start_time'] = last_visit_dict_['session_start_time']\n",
    "    return result_dict_\n",
    "\n",
    "def apply_attribution_reduce(groups):\n",
    "    for key, records in groups:\n",
    "        is_first_event = 1\n",
    "        attr_window = 7776000\n",
    "        utms = [\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"channel\"\n",
    "        ]\n",
    "        metrics = {\n",
    "            'real_consumption': 0.0,\n",
    "            'real_consumption_vat': 0.0,\n",
    "            'real_payment': 0.0,\n",
    "            'real_payment_vat': 0.0,\n",
    "            'trial_consumption': 0.0,\n",
    "            'trial_consumption_vat': 0.0\n",
    "        }\n",
    "        metric_sku = {}\n",
    "        \n",
    "        visits_settings = [\n",
    "            \"ad_block\",\n",
    "            \"age\",\n",
    "            \"area\",\n",
    "            \"channel\",\n",
    "            \"channel_detailed\",\n",
    "            \"city\",\n",
    "            \"client_ip\",\n",
    "            \"counter_id\",\n",
    "            \"country\",\n",
    "            \"device_model\",\n",
    "            \"device_type\",\n",
    "            \"duration\",\n",
    "            \"first_visit_dt\",\n",
    "            \"general_interests\",\n",
    "            \"hits\",\n",
    "            \"income\",\n",
    "            \"interests\",\n",
    "            \"is_bounce\",\n",
    "            \"mobile_phone_vendor\",\n",
    "            \"os\",\n",
    "            \"page_views\",\n",
    "            \"referer\",\n",
    "            \"remote_ip\",\n",
    "            \"resolution_depth\",\n",
    "            \"resolution_height\",\n",
    "            \"resolution_width\",\n",
    "            \"search_phrase\",\n",
    "            \"sex\",\n",
    "            \"start_time\",\n",
    "            \"total_visits\",\n",
    "            \"user_id\",\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"visit_id\",\n",
    "            \"visit_version\",\n",
    "            \"window_client_height\",\n",
    "            \"window_client_width\",\n",
    "            \"is_robot\",\n",
    "            \"start_url\"\n",
    "        ]\n",
    "        \n",
    "        '''\n",
    "        meta_data_dict = {\n",
    "            \"segment\": None,\n",
    "            \"ba_currency\": None,\n",
    "            \"ba_name\": None,\n",
    "            \"ba_payment_cycle_type\": None,\n",
    "            \"ba_person_type\": None,\n",
    "            \"ba_state\": None,\n",
    "            \"ba_type\": None,\n",
    "            \"ba_usage_status\": None,\n",
    "            \"balance_name\": None,\n",
    "            \"billing_account_id\": None,\n",
    "            \"login\": None,\n",
    "            \"cloud_id\": None,\n",
    "            \"cloud_name\": None,\n",
    "            \"cloud_status\": None,\n",
    "            \"mail_tech\": None,\n",
    "            \"mail_testing\": None,\n",
    "            \"mail_info\": None,\n",
    "            \"mail_feature\": None,\n",
    "            \"mail_event\": None,\n",
    "            \"mail_promo\": None,\n",
    "            \"mail_billing\": None,\n",
    "            \"crm_client_name\": None,\n",
    "            \"sales\": None\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        last_visit_dict = {}\n",
    "        last_direct_visit_dict = {}\n",
    "        funnel_steps = {}\n",
    "        record_list = []\n",
    "        for rec in records:\n",
    "            \n",
    "            if not rec['event_time']:\n",
    "                continue\n",
    "            \n",
    "            result_dict = rec.to_dict().copy()\n",
    "            \n",
    "            '''\n",
    "            for meta in meta_data_dict:\n",
    "                if meta in rec:\n",
    "                    if rec[meta]:\n",
    "                        meta_data_dict[meta] = rec[meta]\n",
    "            '''\n",
    "            \n",
    "            if not rec['event'] in funnel_steps:\n",
    "                funnel_steps[rec['event']] = rec['event_time']\n",
    "            \n",
    "            for metric in metrics:\n",
    "                if metric in result_dict:\n",
    "                    result_dict[metric] = convert_metric_to_float(result_dict[metric])\n",
    "                else:\n",
    "                    result_dict[metric] = 0.0\n",
    "                    \n",
    "                if 'name' in result_dict and metric in result_dict:\n",
    "                    if result_dict['name'] + '_' + metric in metric_sku:\n",
    "                        metric_sku[result_dict['name'] + '_' + metric] += result_dict[metric]\n",
    "                    else:\n",
    "                         metric_sku[result_dict['name'] + '_' + metric] = 0.0\n",
    "                #metrics[metric] += result_dict[metric]\n",
    "                try:\n",
    "                    result_dict[metric + '_cum'] = metric_sku[result_dict['name'] + '_' + metric]\n",
    "                except:\n",
    "                    result_dict[metric + '_cum'] = 0.0\n",
    "                \n",
    "            \n",
    "            if is_first_event == 1:\n",
    "                \n",
    "                is_first_event = 0\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    for utm in utms:\n",
    "                        result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "                else:\n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        \n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and 'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                            \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    if last_direct_visit_dict or last_visit_dict:\n",
    "                        \n",
    "                        if last_direct_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_direct_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_direct_visit_dict)\n",
    "\n",
    "                        elif last_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_visit_dict)\n",
    "                            else:\n",
    "                                for utm in utms:\n",
    "                                    result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    else:\n",
    "                        for utm in utms:\n",
    "                            result_dict[utm] = 'Unknown'\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                                \n",
    "                else:\n",
    "                    \n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and  'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "        \n",
    "        for rec_dict in record_list:\n",
    "            for event in funnel_steps:\n",
    "                rec_dict['first_' + event + '_datetime'] = funnel_steps[event]\n",
    "            #for meta in meta_data_dict:\n",
    "                #rec_dict[meta] = meta_data_dict[meta]\n",
    "                \n",
    "            yield Record(key, **rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"ad_block\": int,\n",
    "    \"age\": str,\n",
    "    \"amount\": str,\n",
    "    \"area\": str,\n",
    "    \"ba_currency\": str,\n",
    "    \"ba_name\": str,\n",
    "    \"ba_payment_cycle_type\": str,\n",
    "    \"ba_person_type\": str,\n",
    "    \"ba_state\": str,\n",
    "    \"ba_type\": str,\n",
    "    \"ba_usage_status\": str,\n",
    "    \"balance_name\": str,\n",
    "    \"billing_account_id\": str,\n",
    "    \"channel\": str,\n",
    "    \"channel_detailed\": str,\n",
    "    \"city\": str,\n",
    "    \"client_ip\": str,\n",
    "    \"cloud_id\": str,\n",
    "    \"cloud_name\": str,\n",
    "    \"cloud_status\": str,\n",
    "    \"cost\": float,\n",
    "    \"counter_id\": str,\n",
    "    \"country\": str,\n",
    "    \"credit\": float,\n",
    "    \"currency\": str,\n",
    "    \"device_model\": str,\n",
    "    \"device_type\": str,\n",
    "    \"duration\": int,\n",
    "    \"email\": str,\n",
    "    \"event\": str,\n",
    "    \"event_time\": str,\n",
    "    \"first_ba_became_paid_datetime\": str,\n",
    "    \"first_ba_created_datetime\": str,\n",
    "    \"first_cloud_created_datetime\": str,\n",
    "    \"first_day_use_datetime\": str,\n",
    "    \"first_first_paid_consumption_datetime\": str,\n",
    "    \"first_first_payment_datetime\": str,\n",
    "    \"first_first_trial_consumption_datetime\": str,\n",
    "    \"first_name\": str,\n",
    "    \"first_visit_datetime\": str,\n",
    "    \"first_visit_dt\": str,\n",
    "    \"general_interests\": str,\n",
    "    \"hits\": int,\n",
    "    \"income\": int,\n",
    "    \"interests\": str,\n",
    "    \"is_bounce\": int,\n",
    "    \"is_robot\": str,\n",
    "    \"last_name\": str,\n",
    "    \"login\": str,\n",
    "    \"mobile_phone_vendor\": int,\n",
    "    \"name\": str,\n",
    "    \"os\": str,\n",
    "    \"page_views\": int,\n",
    "    \"payment_type\": str,\n",
    "    \"phone\": str,\n",
    "    \"promocode_client_name\": str,\n",
    "    \"promocode_client_type\": str,\n",
    "    \"promocode_source\": str,\n",
    "    \"promocode_type\": str,\n",
    "    \"puid\": str,\n",
    "    \"real_consumption\": float,\n",
    "    \"real_consumption_cum\": float,\n",
    "    \"real_payment\": float,\n",
    "    \"real_payment_cum\": float,\n",
    "    \"referer\": str,\n",
    "    \"remote_ip\": str,\n",
    "    \"resolution_depth\": int,\n",
    "    \"resolution_height\": int,\n",
    "    \"resolution_width\": int,\n",
    "    \"search_phrase\": str,\n",
    "    \"segment\": str,\n",
    "    \"service_description\": str,\n",
    "    \"service_id\": str,\n",
    "    \"service_name\": str,\n",
    "    \"session_start_time\": str,\n",
    "    \"sex\": str,\n",
    "    \"sku_id\": str,\n",
    "    \"start_time\": str,\n",
    "    \"start_url\": str,\n",
    "    \"total_visits\": int,\n",
    "    \"trial_consumption\": float,\n",
    "    \"trial_consumption_cum\": float,\n",
    "    \"user_id\": str,\n",
    "    \"user_settings_email\": str,\n",
    "    \"utm_campaign\": str,\n",
    "    \"utm_content\": str,\n",
    "    \"utm_medium\": str,\n",
    "    \"utm_source\": str,\n",
    "    \"utm_term\": str,\n",
    "    \"visit_id\": str,\n",
    "    \"visit_version\": str,\n",
    "    \"window_client_height\": int,\n",
    "    \"window_client_width\": int,\n",
    "    \"mail_tech\": int,\n",
    "    \"mail_testing\": int,\n",
    "    \"mail_info\": int,\n",
    "    \"mail_feature\": int,\n",
    "    \"mail_event\": int,\n",
    "    \"mail_promo\": int,\n",
    "    \"mail_billing\": int,\n",
    "    \"crm_client_name\": str,\n",
    "    \"sales\": str,\n",
    "    \"block_reason\": str,\n",
    "    \"trial_consumption_vat\": float,\n",
    "    \"trial_consumption_vat_cum\": float,\n",
    "    \"real_consumption_vat\": float,\n",
    "    \"real_consumption_vat_cum\": float,\n",
    "    \"real_payment_vat\": float,\n",
    "    \"real_payment_vat_cum\": float,\n",
    "}\n",
    "\n",
    "job = cluster.job()\n",
    "cube = job.table('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date()))) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .sort(\n",
    "        'event_time'\n",
    "    ) \\\n",
    "    .reduce(\n",
    "        apply_attribution_reduce,\n",
    "        memory_limit = 2048\n",
    "    ) \\\n",
    "    .project(\n",
    "        **apply_types_in_project(schema)\n",
    "    )\n",
    "cube \\\n",
    ".put('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())), schema = schema)\n",
    "#cube \\\n",
    "#.put('%s/%s' % (paths_dict['funnel_cube'],'cube'), schema = schema)\n",
    "job.run()\n",
    "\n",
    "job = cluster.job()\n",
    "to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date()))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 2)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption_to_validate = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption_to_validate = na.sum('trial_consumption', missing=0),\n",
    "        call_to_validate = na.sum('call', missing=0),\n",
    "        visit_to_validate = na.sum('visit', missing=0),\n",
    "        ba_created_to_validate = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption_to_validate = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created_to_validate = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption_to_validate = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid_to_validate = na.sum('ba_became_paid', missing=0),\n",
    "        day_use_to_validate = na.sum('day_use', missing=0),\n",
    "        first_payment_to_validate = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "\n",
    "control = job.table('%s/%s' % (paths_dict['funnel_cube'],str(datetime.date.today() - datetime.timedelta(days = 1)))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 2)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption = na.sum('trial_consumption', missing=0),\n",
    "        call = na.sum('call', missing=0),\n",
    "        visit = na.sum('visit', missing=0),\n",
    "        ba_created = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid = na.sum('ba_became_paid', missing=0),\n",
    "        day_use = na.sum('day_use', missing=0),\n",
    "        first_payment = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "to_val.join(\n",
    "        control,\n",
    "        by = 'date',\n",
    "        type = 'full'\n",
    "    ) \\\n",
    "    .sort('date') \\\n",
    "    .put('%s/validation' % (paths_dict['cube_tmp']))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = cluster.read('%s/validation' % (paths_dict['cube_tmp'])).as_dataframe().sort_values(by = 'date')\n",
    "\n",
    "col_list = ['ba_became_paid',\n",
    " 'ba_created',\n",
    " 'call',\n",
    " 'cloud_created',\n",
    " 'day_use',\n",
    " 'first_paid_consumption',\n",
    " 'first_payment',\n",
    " 'first_trial_consumption',\n",
    " 'real_consumption',\n",
    " 'trial_consumption',\n",
    " 'visit']\n",
    "\n",
    "diff_col = {}\n",
    "for col in col_list:\n",
    "    val_df[col + '_diff'] = val_df[col] - val_df[col + '_to_validate']\n",
    "    if val_df[col + '_diff'].sum() >= 1 or val_df[col + '_diff'].sum() <= -1:\n",
    "        print(col, val_df[col + '_diff'].sum())\n",
    "        diff_col[col] = val_df[col + '_diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "if ('visit' in diff_col or 'call' in diff_col or 'day_use' in diff_col):\n",
    "    ok = 1\n",
    "if 'real_consumption' in diff_col:\n",
    "    if abs(diff_col['real_consumption']) < 500:\n",
    "        ok = 1\n",
    "if 'trial_consumption' in diff_col:\n",
    "    if abs(diff_col['trial_consumption']) < 500:\n",
    "        ok = 1\n",
    "\n",
    "if not diff_col:\n",
    "    ok = 1\n",
    "\n",
    "if ok == 1:\n",
    "    try:\n",
    "        cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    except:\n",
    "        pass\n",
    "    job = cluster.job()\n",
    "    to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    job.run()\n",
    "\n",
    "    #cluster.driver.remove('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "    #cluster.driver.remove('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "\n",
    "    tables_to_save = date_range_by_days(str(datetime.date.today() - datetime.timedelta(days = 14)), str(datetime.date.today())) + ['cube', 'validation']\n",
    "    tables_to_save = [paths_dict['cube_tmp'] + '/' + table for table in tables_to_save]\n",
    "    for table in get_table_list(paths_dict['cube_tmp'], job).replace('{', '').replace('}', '').split(','):\n",
    "        if table not in tables_to_save:\n",
    "            cluster.driver.remove(table)\n",
    "\n",
    "    text = ['''\n",
    "    Acquisition Cube: Success at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    text = ['''\n",
    "    Acquisition Cube: Fail at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
