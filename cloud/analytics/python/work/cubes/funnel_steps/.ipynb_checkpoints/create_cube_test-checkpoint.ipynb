{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, datetime, ast, numpy as np, telebot, json, requests, os, sys\n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances\n",
    "\n",
    "from init_funnel_steps import (\n",
    "    paths_dict_prod,\n",
    "    paths_dict_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service(name_):\n",
    "    return str(name_).split('.')[0]\n",
    "\n",
    "\n",
    "def convert_metric_to_float(num):\n",
    "    try:\n",
    "        return float(num)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def get_payment_type(context):\n",
    "    try:\n",
    "        return ast.literal_eval(context)['payment_type']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_reason(metadata_):\n",
    "    if metadata_ not in ['', None]:\n",
    "        metadata =  json.loads(metadata_)\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    if metadata:\n",
    "        if 'block_reason' in metadata:\n",
    "            return metadata['block_reason']\n",
    "        if 'suspend_reason' in metadata:\n",
    "            return metadata['suspend_reason']\n",
    "        #if 'fraud_detected_by' in metadata:\n",
    "            #if isinstance(metadata['fraud_detected_by'], list):\n",
    "                #return metadata['fraud_detected_by'][0]\n",
    "            #else:\n",
    "                #return metadata['fraud_detected_by'].replace('[', '').replace(']', '').replace(\"u'\", '').replace(\"'\", '')\n",
    "    return 'unknown'\n",
    "\n",
    "def get_datetime_from_epoch(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "    return date_list\n",
    "\n",
    "def get_last_not_empty_table(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    last_table_rows = 0\n",
    "    last_table = ''\n",
    "    for table in tables_list:\n",
    "        try:\n",
    "            table_rows = int(job.driver.get_attribute(table, 'chunk_row_count'))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if table_rows > last_table_rows:\n",
    "            last_table_rows =  table_rows\n",
    "            last_table = table\n",
    "    if last_table:\n",
    "        return last_table\n",
    "    else:\n",
    "        return tables_list[0]\n",
    "\n",
    "\n",
    "def get_table_list(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    return '{%s}' % (','.join(tables_list))\n",
    "\n",
    "def apply_types_in_project(schema_):\n",
    "    apply_types_dict = {}\n",
    "    for col in schema_:\n",
    "        \n",
    "        if schema_[col] == str:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: str(x).replace('\"', '').replace(\"'\", '').replace('\\\\','') if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == int:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: int(x) if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == float:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: float(x) if x not in ['', None] else None, col)\n",
    "    return apply_types_dict\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def convert_epoch_to_date(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).date())\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "        \n",
    "    return date_list\n",
    "\n",
    "\n",
    "def get_ba_history(groups):\n",
    "    for key, records in groups:\n",
    "        \n",
    "        rec_list = list(records)\n",
    "        result_dict = {}\n",
    "        start_date = ''\n",
    "        owner_id = ''\n",
    "        for rec in rec_list:\n",
    "            rec_ = rec.to_dict()\n",
    "            rec_['date'] = convert_epoch_to_date(rec_['updated_at'])\n",
    "            if not start_date:\n",
    "                start_date = rec_['date']\n",
    "                \n",
    "            if 'owner_id' in rec_:\n",
    "                owner_id = rec_['owner_id']\n",
    "                \n",
    "            result_dict[rec_['date']] = rec_\n",
    "        \n",
    "        \n",
    "        \n",
    "        date_range = date_range_by_days(start_date, str(datetime.date.today()))\n",
    "        res = {}\n",
    "        for date in date_range:\n",
    "            \n",
    "            for date_ in sorted(result_dict):\n",
    "                \n",
    "                if date_ <= date:\n",
    "                    result_dict[date_]['date'] = date\n",
    "                    res = result_dict[date_]\n",
    "                else:\n",
    "                    break\n",
    "            res['owner_id'] = owner_id\n",
    "            yield Record(key, **res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "telebot_creds = client.get_version('ver-01d4wza60ns43j5mqktvvvwdnx')\n",
    "bot = telebot.TeleBot(telebot_creds['value']['token'])\n",
    "cluster = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool']\n",
    ")\n",
    "if mode == 'test':\n",
    "    paths_dict_temp = paths_dict_test\n",
    "elif mode == 'prod':\n",
    "    paths_dict_temp = paths_dict_prod\n",
    "paths_dict = paths_dict_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/logfeller/logs/yc-billing-export-monetary-grants/1h/2019-04-11T05:00:00\n",
      "//home/cloud_analytics/import/iam/cloud_owners/1h/2019-04-11T02:01:08\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-sku/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-services/1d/2019-03-20\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-usage-reports/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-transactions/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts-history/1h/2019-04-11T07:00:00\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "for path in['billing_grants','cloud_owner_path', 'billing_accounts_path', 'sku_path', 'service_dict_path', 'billing_accounts_path', 'billing_records_path','transactions_path', 'billing_accounts_history_path']:\n",
    "    valid_path = get_last_not_empty_table(paths_dict_temp[path], job)\n",
    "    print(valid_path)\n",
    "    paths_dict[path] = valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_grant_history(groups):\\n    for key, records in groups:\\n        rec_list = list(records)\\n        result_dict = {}\\n        start_date = \\'\\'\\n        for rec in rec_list:\\n            rec_ = rec.to_dict()\\n            rec_[\\'start_date\\'] = convert_epoch_to_date(rec_[\\'start_time\\'])\\n            rec_[\\'end_date\\'] = convert_epoch_to_date(rec_[\\'end_time\\'])\\n            rec_[\\'start_time\\'] = get_datetime_from_epoch(rec_[\\'start_time\\'])\\n            rec_[\\'end_time\\'] = get_datetime_from_epoch(rec_[\\'end_time\\'])\\n            rec_[\\'initial_amount\\'] = float(rec_[\\'initial_amount\\'])\\n            \\n            if not start_date:\\n                start_date = rec_[\\'start_date\\']\\n                \\n            result_dict[str(rec_[\\'start_time\\']) + \\'_\\' + str(rec_[\\'id\\'])] = rec_\\n        #yield Record(key, **rec_)\\n        date_range = date_range_by_days(start_date, str(datetime.date.today()))\\n        grant_rec = {}\\n        \\n        for date in date_range:\\n            \\n            net_grant = 0\\n            active_grant = 0\\n            \\n            for key in sorted(result_dict):\\n                #row_ = result_dict[date_].copy()\\n                if result_dict[key][\\'start_date\\'] <= date:\\n                    \\n                    result_dict[key][\\'date\\'] = date\\n                    \\n                    if result_dict[key][\\'end_date\\'] <= date:\\n                        net_grant += result_dict[key][\\'initial_amount\\']\\n                        active_grant += 1\\n                        \\n                    grant_rec = result_dict[key].copy()\\n                    \\n                else:\\n                    break\\n            grant_rec[\\'net_grant\\'] = net_grant\\n            grant_rec[\\'active_grants\\'] = active_grant\\n            grant_rec[\\'start_date\\'] = start_date\\n            grants_list = []\\n            for key in result_dict:\\n                grants_info = {}\\n                for opt in [\\'id\\', \\'initial_amount\\', \\'start_time\\', \\'end_time\\', \\'source\\', \\'source_id\\']:\\n                    grants_info[opt] = result_dict[key][opt]\\n                grants_list.append(grants_info)\\n                \\n            grant_rec[\\'grants_info\\'] = str(grants_list)\\n            yield Record(key, **grant_rec)\\n\\nschema = {\\n    \"active_grant\": int,\\n    \"billing_account_id\": str,\\n    \"date\": str,\\n    \"end_date\": str,\\n    \"initial_amount\": float,\\n    \"net_grant\": float,\\n    \"start_date\": str,\\n    \\'grants_info\\': str\\n}\\n\\njob = cluster.job()\\njob.table(paths_dict[\\'billing_grants\\']) .groupby(\\n    \\'billing_account_id\\'\\n) .sort(\\n    \\'start_time\\'\\n) .reduce(\\n    get_grant_history\\n) .put(\\n    paths_dict[\\'grants\\'],\\n    #schema = schema\\n)\\njob.run()\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def get_grant_history(groups):\n",
    "    for key, records in groups:\n",
    "        rec_list = list(records)\n",
    "        result_dict = {}\n",
    "        start_date = ''\n",
    "        for rec in rec_list:\n",
    "            rec_ = rec.to_dict()\n",
    "            rec_['start_date'] = convert_epoch_to_date(rec_['start_time'])\n",
    "            rec_['end_date'] = convert_epoch_to_date(rec_['end_time'])\n",
    "            rec_['start_time'] = get_datetime_from_epoch(rec_['start_time'])\n",
    "            rec_['end_time'] = get_datetime_from_epoch(rec_['end_time'])\n",
    "            rec_['initial_amount'] = float(rec_['initial_amount'])\n",
    "            \n",
    "            if not start_date:\n",
    "                start_date = rec_['start_date']\n",
    "                \n",
    "            result_dict[str(rec_['start_time']) + '_' + str(rec_['id'])] = rec_\n",
    "        #yield Record(key, **rec_)\n",
    "        date_range = date_range_by_days(start_date, str(datetime.date.today()))\n",
    "        grant_rec = {}\n",
    "        \n",
    "        for date in date_range:\n",
    "            \n",
    "            net_grant = 0\n",
    "            active_grant = 0\n",
    "            \n",
    "            for key in sorted(result_dict):\n",
    "                #row_ = result_dict[date_].copy()\n",
    "                if result_dict[key]['start_date'] <= date:\n",
    "                    \n",
    "                    result_dict[key]['date'] = date\n",
    "                    \n",
    "                    if result_dict[key]['end_date'] <= date:\n",
    "                        net_grant += result_dict[key]['initial_amount']\n",
    "                        active_grant += 1\n",
    "                        \n",
    "                    grant_rec = result_dict[key].copy()\n",
    "                    \n",
    "                else:\n",
    "                    break\n",
    "            grant_rec['net_grant'] = net_grant\n",
    "            grant_rec['active_grants'] = active_grant\n",
    "            grant_rec['start_date'] = start_date\n",
    "            grants_list = []\n",
    "            for key in result_dict:\n",
    "                grants_info = {}\n",
    "                for opt in ['id', 'initial_amount', 'start_time', 'end_time', 'source', 'source_id']:\n",
    "                    grants_info[opt] = result_dict[key][opt]\n",
    "                grants_list.append(grants_info)\n",
    "                \n",
    "            grant_rec['grants_info'] = str(grants_list)\n",
    "            yield Record(key, **grant_rec)\n",
    "\n",
    "schema = {\n",
    "    \"active_grant\": int,\n",
    "    \"billing_account_id\": str,\n",
    "    \"date\": str,\n",
    "    \"end_date\": str,\n",
    "    \"initial_amount\": float,\n",
    "    \"net_grant\": float,\n",
    "    \"start_date\": str,\n",
    "    'grants_info': str\n",
    "}\n",
    "\n",
    "job = cluster.job()\n",
    "job.table(paths_dict['billing_grants']) \\\n",
    ".groupby(\n",
    "    'billing_account_id'\n",
    ") \\\n",
    ".sort(\n",
    "    'start_time'\n",
    ") \\\n",
    ".reduce(\n",
    "    get_grant_history\n",
    ") \\\n",
    ".put(\n",
    "    paths_dict['grants'],\n",
    "    #schema = schema\n",
    ")\n",
    "job.run()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"balance\": float,\n",
    "    \"balance_client_id\": str,\n",
    "    \"balance_contract_id\": str,\n",
    "    \"billing_account_id\": str,\n",
    "    \"billing_threshold\": str,\n",
    "    \"client_id\": str,\n",
    "    \"currency\": str,\n",
    "    \"date\": str,\n",
    "    \"feature_flags\": str,\n",
    "    \"iso_eventtime\": str,\n",
    "    \"master_account_id\": str,\n",
    "    \"metadata\": str,\n",
    "    \"name\": str,\n",
    "    \"owner_id\": str,\n",
    "    \"payment_cycle_type\": str,\n",
    "    \"payment_method_id\": str,\n",
    "    \"payment_type\": str,\n",
    "    \"person_type\": str,\n",
    "    \"state\": str,\n",
    "    \"type\": str,\n",
    "    \"updated_at\": int,\n",
    "    \"usage_status\": str,\n",
    "    \"block_reason\": str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2080981b48da434cbdd29c3a934718e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 15:15:03,878\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4f1644b2-34b4039a-3fe03e8-f35debd6&tab=details\n",
      "2019-04-11 15:15:31,482\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2fedb6d2-67a1d89b-3fe03e8-b5416c5e&tab=details\n",
      "2019-04-11 15:18:14,464\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=818ab286-6c5efc06-3fe03e8-bd82fbbf&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "job.table(paths_dict['billing_accounts_history_path']) \\\n",
    ".project(\n",
    "    ne.all(),\n",
    "    block_reason = ne.custom(lambda x,y:get_reason(y) if x == 'suspended' else 'Unlocked', 'state', 'metadata')\n",
    ") \\\n",
    ".groupby(\n",
    "    'billing_account_id'\n",
    ") \\\n",
    ".sort(\n",
    "    'updated_at'\n",
    ") \\\n",
    ".reduce(\n",
    "    get_ba_history\n",
    ") \\\n",
    ".project(\n",
    "    **apply_types_in_project(schema)\n",
    ") \\\n",
    ".put(paths_dict['ba_hist'], schema = schema)\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f8dac27cb646c7947f04d78e51d4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 15:20:21,777\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=13d22eab-5ef6a30b-3fe03e8-c9f485d3&tab=details\n",
      "2019-04-11 15:21:28,676\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e469f196-f8204fbb-3fe03e8-724f47ff&tab=details\n",
      "2019-04-11 15:23:18,883\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=95f63839-6247a59f-3fe03e8-57000a40&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "ba_puid_dict_hist = job.table(paths_dict['ba_hist']) \\\n",
    "    .unique(\n",
    "        'billing_account_id',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .project(\n",
    "        date = 'date',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'billing_account_id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = 'block_reason'\n",
    "    ) \\\n",
    "    .put('%s/%s_check' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837ea6ce92cb45c69e39c486256013a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 15:26:02,016\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=de99a283-7ed9bb1b-3fe03e8-a5a5d402&tab=details\n",
      "2019-04-11 15:28:06,784\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=adc1cd0b-ac6e4cd-3fe03e8-ce473bee&tab=details\n",
      "2019-04-11 15:28:51,413\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ae50fc64-86c26b5a-3fe03e8-a86cd85c&tab=details\n",
      "2019-04-11 15:29:38,318\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=506656fc-891326c3-3fe03e8-4dbd9873&tab=details\n",
      "2019-04-11 15:30:30,779\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5bce3e4a-955ce177-3fe03e8-a0c49b66&tab=details\n",
      "2019-04-11 15:30:50,183\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6a670166-77c46433-3fe03e8-c8f9ab7e&tab=details\n",
      "2019-04-11 15:31:28,693\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=98cfed2e-a12b46fd-3fe03e8-88f6da4d&tab=details\n",
      "2019-04-11 15:31:53,824\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=3f03cab-77aa1c2e-3fe03e8-b911ce17&tab=details\n",
      "2019-04-11 15:32:30,715\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=83b801b7-79593199-3fe03e8-a3f60666&tab=details\n",
      "2019-04-11 15:32:52,357\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5ed1a329-11b4bead-3fe03e8-5dd64491&tab=details\n",
      "2019-04-11 15:34:07,915\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1c356ef2-be06cc83-3fe03e8-bfa2081e&tab=details\n",
      "2019-04-11 15:34:51,713\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=bff807a5-c4307f4-3fe03e8-f69c2a9a&tab=details\n",
      "2019-04-11 15:35:14,688\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=fc65ec55-79c0a42f-3fe03e8-ab3df2ee&tab=details\n",
      "2019-04-11 15:37:19,738\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5765ec65-e45f802-3fe03e8-659da6ac&tab=details\n",
      "2019-04-11 15:43:51,615\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=db91c7aa-4958b231-3fe03e8-66bfbde1&tab=details\n",
      "2019-04-11 15:45:29,108\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ef1ba2f-8df7711f-3fe03e8-c7cf2920&tab=details\n",
      "2019-04-11 15:45:49,527\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=7be082ee-da9f9d8a-3fe03e8-f8f9a9cf&tab=details\n",
      "2019-04-11 15:46:17,095\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=f7ce664c-e8ad7185-3fe03e8-5a350768&tab=details\n",
      "2019-04-11 15:46:52,147\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=57391bbb-75193448-3fe03e8-aa93dce9&tab=details\n",
      "2019-04-11 15:47:26,394\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=480d77bf-41fa0c2d-3fe03e8-c4a5d1e7&tab=details\n",
      "2019-04-11 15:47:43,741\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c78bf3ef-23f2c356-3fe03e8-66e9809&tab=details\n",
      "2019-04-11 15:48:19,547\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4bb76891-39f548f8-3fe03e8-9511f055&tab=details\n",
      "2019-04-11 15:49:23,350\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b6067c5a-bbaaaade-3fe03e8-93ca0069&tab=details\n",
      "2019-04-11 15:49:58,405\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=125c6ae2-b0cb18a8-3fe03e8-c321722a&tab=details\n",
      "2019-04-11 15:50:13,859\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6eaf84d4-a0c917a0-3fe03e8-f125cd06&tab=details\n",
      "2019-04-11 15:51:03,969\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c1683106-3db016c7-3fe03e8-5e51a1dd&tab=details\n",
      "2019-04-11 15:51:38,595\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c969588c-cd017cbf-3fe03e8-a14bb94a&tab=details\n",
      "2019-04-11 15:52:21,012\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6a1e4d95-645a52f3-3fe03e8-87adf83&tab=details\n",
      "2019-04-11 15:53:24,201\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=74ea3e0d-f71732a7-3fe03e8-6694b08d&tab=details\n",
      "2019-04-11 15:54:27,998\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=76a8f0ba-fbef7af8-3fe03e8-aa9894b5&tab=details\n",
      "2019-04-11 15:54:47,278\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d6e4a4ac-5ca5658-3fe03e8-ec81c3f&tab=details\n",
      "2019-04-11 15:55:17,295\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=f126cf39-ab146b-3fe03e8-2d9ad574&tab=details\n",
      "2019-04-11 15:56:04,436\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5b49ec61-799691da-3fe03e8-c620ab08&tab=details\n",
      "2019-04-11 15:56:54,449\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=86415445-27c9b8b3-3fe03e8-1423df5e&tab=details\n",
      "2019-04-11 15:57:13,989\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2407d460-ec0fa79b-3fe03e8-9df13fb8&tab=details\n",
      "2019-04-11 15:57:41,636\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=41897c7e-99d7bd7d-3fe03e8-4c58d3a6&tab=details\n",
      "2019-04-11 15:58:04,152\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=eac009db-cdaa54da-3fe03e8-99dfbbd2&tab=details\n",
      "2019-04-11 15:58:21,639\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=f0089ad4-e6db39ec-3fe03e8-73c42cc6&tab=details\n",
      "2019-04-11 15:59:18,631\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e311639-de6067a3-3fe03e8-c92c1586&tab=details\n",
      "2019-04-11 16:00:19,694\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=372fbb0a-1d99f533-3fe03e8-c6bec227&tab=details\n",
      "2019-04-11 16:00:54,932\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=cb226683-480ca927-3fe03e8-6a456dde&tab=details\n",
      "2019-04-11 16:01:58,767\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=159a5eb5-136c073b-3fe03e8-b638704b&tab=details\n",
      "2019-04-11 16:02:37,497\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e6ce9017-a5e37e3d-3fe03e8-ced65efc&tab=details\n",
      "2019-04-11 16:04:10,964\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=58e8585-15688893-3fe03e8-1be11280&tab=details\n",
      "2019-04-11 16:04:26,229\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4cfc6956-17babdc1-3fe03e8-a95fc4f7&tab=details\n",
      "2019-04-11 16:04:47,915\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ac95ac71-c42a9093-3fe03e8-99c4a0b4&tab=details\n",
      "2019-04-11 16:05:30,834\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=cfdc4c47-66244054-3fe03e8-143f5f29&tab=details\n",
      "2019-04-11 16:06:16,246\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2964d597-b73bed68-3fe03e8-46b101ee&tab=details\n",
      "2019-04-11 16:07:03,546\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=dfb837e0-d5cf4bb6-3fe03e8-399ddf20&tab=details\n",
      "2019-04-11 16:09:08,840\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5a9c84bd-79d83c7f-3fe03e8-a687f7fd&tab=details\n",
      "2019-04-11 16:10:42,231\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=cfca2906-267749fa-3fe03e8-6a144621&tab=details\n",
      "2019-04-11 16:14:37,504\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ba900-1d500852-3fe03e8-8c9bb5ba&tab=details\n",
      "2019-04-11 16:15:26,011\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=34f4e991-8b11edb5-3fe03e8-fe00bd6b&tab=details\n",
      "2019-04-11 16:16:17,039\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a5340270-fd62b804-3fe03e8-6017c35d&tab=details\n",
      "2019-04-11 16:16:47,498\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d34d2c56-6167fb96-3fe03e8-ede6ef56&tab=details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 16:18:29,565\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=39e6ffb4-ae7f1394-3fe03e8-5dbd956e&tab=details\n",
      "2019-04-11 16:19:26,862\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d66d874e-b77fffa6-3fe03e8-4d4b6e9a&tab=details\n",
      "2019-04-11 16:21:08,789\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=8de29fdb-249efacb-3fe03e8-5a9247e9&tab=details\n",
      "2019-04-11 16:23:00,829\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=579a42c1-a61c1088-3fe03e8-cadc7230&tab=details\n",
      "2019-04-11 16:24:56,525\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=debf1c96-e1d3842f-3fe03e8-5cc0606a&tab=details\n",
      "2019-04-11 16:27:18,504\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4571544e-162fc053-3fe03e8-66b9f40b&tab=details\n",
      "2019-04-11 16:28:27,366\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ebc3bcea-dba94f1-3fe03e8-1715dda8&tab=details\n",
      "2019-04-11 16:29:44,219\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=7094f59d-7c4daaf1-3fe03e8-c775917c&tab=details\n",
      "2019-04-11 16:32:19,375\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a68d1a52-4500c9ab-3fe03e8-8bc5ed83&tab=details\n",
      "2019-04-11 16:35:34,333\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d9fea805-68c9cdd4-3fe03e8-16d487e1&tab=details\n",
      "2019-04-11 16:38:05,535\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c0287b88-d588edb-3fe03e8-fbb78874&tab=details\n",
      "2019-04-11 16:39:41,245\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a5b66d53-803d8f77-3fe03e8-6499faa7&tab=details\n",
      "2019-04-11 16:40:54,009\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a43cd80-a22d9dee-3fe03e8-9c7a669e&tab=details\n",
      "2019-04-11 16:41:27,814\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=575b6bc7-e68fe0d-3fe03e8-fb585f3c&tab=details\n",
      "2019-04-11 16:42:25,763\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=792c4a75-50248730-3fe03e8-e56cb879&tab=details\n",
      "2019-04-11 16:43:22,625\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1dd94bf1-4215d947-3fe03e8-302a31b0&tab=details\n",
      "2019-04-11 16:43:36,023\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5f08286b-17ed2f39-3fe03e8-4dc2b07d&tab=details\n",
      "2019-04-11 16:44:16,379\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=59c0052-3561fc9b-3fe03e8-e466900b&tab=details\n",
      "2019-04-11 16:45:13,428\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d15bab63-b8881233-3fe03e8-4e80c908&tab=details\n",
      "2019-04-11 16:47:40,108\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=78bf6470-d16c2ef7-3fe03e8-248c5c3&tab=details\n",
      "2019-04-11 16:49:08,058\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=bc1f6453-e49d23dc-3fe03e8-68a7ede7&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "\n",
    "\n",
    "#cloud created event\n",
    "clouds = job.table(paths_dict['cloud_owner_path']) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        mail_tech = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_testing = ne.custom(lambda x: 1 if x else 0, 'mail_testing'),\n",
    "        mail_info = ne.custom(lambda x: 1 if x else 0, 'mail_info'),\n",
    "        mail_feature = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_event = ne.custom(lambda x: 1 if x else 0, 'mail_event'),\n",
    "        mail_promo = ne.custom(lambda x: 1 if x else 0, 'mail_promo'),\n",
    "        mail_billing = ne.custom(lambda x: 1 if x else 0, 'mail_billing'),\n",
    "        cloud_id = 'id',\n",
    "        event = ne.const('cloud_created'),\n",
    "        event_time = ne.custom(lambda x: ' '.join(str(x).split('+')[0].split('T')), 'cloud_created_at'),\n",
    "        puid = 'passport_uid'\n",
    "    \n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        email = na.first('email', by='event_time'),\n",
    "        first_name = na.first('first_name', by='event_time'),\n",
    "        last_name = na.first('last_name', by='event_time'),\n",
    "        login = na.first('login', by='event_time'),\n",
    "        phone = na.first('phone', by='event_time'),\n",
    "        user_settings_email = na.first('user_settings_email', by='event_time'),\n",
    "        cloud_status = na.first('cloud_status', by='event_time'),\n",
    "        cloud_name = na.first('cloud_name', by='event_time'),\n",
    "        event = na.first('event', by='cloud_created_at'),\n",
    "        event_time = na.first('event_time', by='cloud_created_at'),\n",
    "        cloud_id = na.first('cloud_id', by='cloud_created_at'),\n",
    "        mail_tech = na.first('mail_tech', by='cloud_created_at'),\n",
    "        mail_testing = na.first('mail_testing', by='cloud_created_at'),\n",
    "        mail_info = na.first('mail_info', by='cloud_created_at'),\n",
    "        mail_feature = na.first('mail_feature', by='cloud_created_at'),\n",
    "        mail_event = na.first('mail_event', by='cloud_created_at'),\n",
    "        mail_promo = na.first('mail_promo', by='cloud_created_at'),\n",
    "        mail_billing = na.first('mail_billing', by='cloud_created_at')\n",
    "    )\n",
    "\n",
    "clouds_ = clouds \\\n",
    "    .unique(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        'cloud_id',\n",
    "        'puid',\n",
    "        'mail_tech',\n",
    "        'mail_testing',\n",
    "        'mail_info',\n",
    "        'mail_feature',\n",
    "        'mail_event',\n",
    "        'mail_promo',\n",
    "        'mail_billing'\n",
    "    )\n",
    "\n",
    "offers = job.table(paths_dict['offers_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in [None, ''], 'passport_uid')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'passport_uid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        promocode_client_name = 'client_name',\n",
    "        promocode_type = 'type',\n",
    "        puid = 'passport_uid',\n",
    "        promocode_source = 'client_source',\n",
    "        promocode_client_type = ne.custom(lambda x: 'Enterprise/ISV' if x == 'direct_offer' else 'Direct')\n",
    "    )\n",
    "\n",
    "segments = job.table(paths_dict['client_segments']) \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    )\n",
    "\n",
    "passports = job.table(paths_dict['balance']) \\\n",
    "    .unique(\n",
    "        'PASSPORT_ID'\n",
    "    ) \\\n",
    "    .project(\n",
    "        puid = 'PASSPORT_ID',\n",
    "        balance_name = 'NAME'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = job.table(paths_dict['billing_accounts_path']) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ba_created_at = 'created_at',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = ne.custom(lambda x,y:get_reason(y) if x == 'suspended' else 'Unlocked', 'state', 'metadata')\n",
    "    ) \\\n",
    "    .join(\n",
    "        offers,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        segments,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        passports,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = ba_puid_dict_ \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        segment = ne.custom(lambda x: x.lower() if x not in ['', None] else 'mass', 'segment')\n",
    "    )\n",
    "\n",
    "\n",
    "ba_puid_dict_hist = job.table(paths_dict['ba_hist']) \\\n",
    "    .unique(\n",
    "        'billing_account_id',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .project(\n",
    "        date = 'date',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'billing_account_id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = 'block_reason'\n",
    "    ) \\\n",
    "    .join(\n",
    "        offers,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        segments,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        passports,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_hist = ba_puid_dict_hist \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        segment = ne.custom(lambda x: x.lower() if x not in ['', None] else 'mass', 'segment')\n",
    "    ) \\\n",
    "    .unique('billing_account_id', 'date')\n",
    "\n",
    "\n",
    "\n",
    "sku_dict = job.table(paths_dict['sku_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'name',\n",
    "        'service_id',\n",
    "        sku_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "service_dict = job.table(paths_dict['service_dict_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        service_name = 'name',\n",
    "        service_description = 'description',\n",
    "        service_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "sku_dict = sku_dict \\\n",
    "    .join(\n",
    "        service_dict,\n",
    "        by = 'service_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict = ba_puid_dict_ \\\n",
    "    .join(\n",
    "        clouds_,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "bas = ba_puid_dict \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        event = ne.const('ba_created'),\n",
    "        event_time = ne.custom(get_datetime_from_epoch, 'ba_created_at')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_puid_dict__ = ba_puid_dict_.unique('puid')\n",
    "visits = job.table(paths_dict['visits_path'])\n",
    "calls = job.table(paths_dict['calls'])\n",
    "click_mail = job.table(paths_dict['click_email']) \n",
    "#open_mail = job.table(paths_dict['open_mail']) \n",
    "\n",
    "puid_sets = job.concat(\n",
    "    clouds,\n",
    "    visits,\n",
    "    calls,\n",
    "    click_mail\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict__,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        ba_name = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_name'),\n",
    "        ba_payment_cycle_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_payment_cycle_type'),\n",
    "        ba_person_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_person_type'),\n",
    "        ba_state = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_state'),\n",
    "        ba_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_type'),\n",
    "        ba_usage_status = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_usage_status'),\n",
    "        block_reason = ne.custom(lambda x: x if x else 'ba_not_created', 'block_reason'),\n",
    "        segment = ne.custom(lambda x: x if x else 'unknown', 'segment'),\n",
    "        promocode_client_name = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_name'),\n",
    "        promocode_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_type'),\n",
    "        promocode_source = ne.custom(lambda x: x if x else 'unknown', 'promocode_source'),\n",
    "        promocode_client_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_type'),\n",
    "        balance_name = ne.custom(lambda x: x if x else 'unknown', 'balance_name'),\n",
    "        sales = ne.custom(lambda x: x if x else 'unknown', 'sales'),\n",
    "        crm_client_name = ne.custom(lambda x: x if x else 'unknown', 'crm_client_name')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_became_paid = job.table(paths_dict['billing_accounts_history_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: str(x).lower() == 'paid', 'usage_status')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.min('updated_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('ba_became_paid')\n",
    "    )\n",
    "\n",
    "first_trial_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: float(x) < 0, 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:57','event_time'),\n",
    "        event = ne.const('first_trial_consumption')\n",
    "    )\n",
    "\n",
    "\n",
    "first_paid_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x, y: float(x) + float(y) > 0, 'cost', 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:58','event_time'),\n",
    "        event = ne.const('first_paid_consumption')\n",
    "    )\n",
    "\n",
    "first_payment = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        payment_type = ne.custom(get_payment_type, 'context')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('modified_at', by='modified_at'),\n",
    "        amount = na.first('amount', by='modified_at'),\n",
    "        currency = na.first('currency', by='modified_at'),\n",
    "        payment_type = na.first('payment_type', by='modified_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'amount',\n",
    "        'currency',\n",
    "        'payment_type',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('first_payment')\n",
    "    )\n",
    "\n",
    "day_use_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        trial_consumption = ne.custom(lambda x: convert_metric_to_float(x)*-1, 'credit'),\n",
    "        trial_consumption_vat = ne.custom(lambda x,y: convert_metric_to_float(x)*-1/1.18 if y < '2019-01-01' else convert_metric_to_float(x)*-1/1.2, 'credit', 'date'),\n",
    "        real_consumption = ne.custom(lambda x, y: convert_metric_to_float(x) + convert_metric_to_float(y) if x not in [None, ''] and y not in [None, ''] else 0.0,'cost', 'credit'),\n",
    "        real_consumption_vat = ne.custom(lambda x, y, z: (convert_metric_to_float(x) + convert_metric_to_float(y))/1.18 if z < '2019-01-01' else (convert_metric_to_float(x) + convert_metric_to_float(y))/1.2,'cost', 'credit', 'date'),    \n",
    "        event_time = ne.custom(lambda x: str(x) + ' 23:59:59', 'date'),\n",
    "        date = 'date',\n",
    "        event = ne.const('day_use'),\n",
    "        real_payment = ne.const(0),\n",
    "        real_payment_vat = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'event',\n",
    "        'event_time',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        trial_consumption_vat = na.sum('trial_consumption_vat'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_consumption_vat = na.sum('real_consumption_vat'),\n",
    "        real_payment = na.sum('real_payment'),\n",
    "        real_payment_vat = na.sum('real_payment_vat')\n",
    "    )\n",
    "\n",
    "day_use_payments = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'currency',\n",
    "        sku_id = ne.const(''),\n",
    "        event_time = ne.custom(convert_epoch_to_end_day, 'modified_at'),\n",
    "        real_payment = ne.custom(lambda x: convert_metric_to_float(x), 'amount'),\n",
    "        real_payment_vat = ne.custom(lambda x, y: convert_metric_to_float(x)/1.18 if convert_epoch_to_end_day(y).split(' ')[0] < '2019-01-01' else convert_metric_to_float(x)/1.2, 'amount', 'modified_at'),\n",
    "        event = ne.const('day_use'),\n",
    "        date = ne.custom(lambda x: convert_epoch_to_end_day(x).split(' ')[0], 'modified_at'),\n",
    "        trial_consumption = ne.const(0),\n",
    "        trial_consumption_vat = ne.const(0),\n",
    "        real_consumption = ne.const(0),\n",
    "        real_consumption_vat = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'event_time',\n",
    "        'event',\n",
    "        'sku_id',\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        trial_consumption_vat = na.sum('trial_consumption_vat'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_consumption_vat = na.sum('real_consumption_vat'),\n",
    "        real_payment = na.sum('real_payment'),\n",
    "        real_payment_vat = na.sum('real_payment_vat')\n",
    "    )\n",
    "\n",
    "ba_sets_hist = job.concat(\n",
    "    day_use_consumption,\n",
    "    day_use_payments,\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict_hist,\n",
    "        by = ['billing_account_id', 'date'],\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        sku_dict,\n",
    "        by = 'sku_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_sets = job.concat(\n",
    "    bas,\n",
    "    first_payment,\n",
    "    first_paid_consumption,\n",
    "    first_trial_consumption,\n",
    "    ba_became_paid\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict_,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        sku_dict,\n",
    "        by = 'sku_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "result = job.concat(\n",
    "        puid_sets,\n",
    "        ba_sets,\n",
    "        ba_sets_hist\n",
    "    )\n",
    "\n",
    "result.put('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_delta(new_date, old_date):\n",
    "    try:\n",
    "        return (datetime.datetime.strptime(new_date, '%Y-%m-%d %H:%M:%S') - datetime.datetime.strptime(old_date, '%Y-%m-%d %H:%M:%S')).seconds\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def apply_attr(result_dict_, last_visit_dict_):\n",
    "    for col in last_visit_dict_:\n",
    "        try:\n",
    "            result_dict_[col] = last_visit_dict_[col]\n",
    "            \n",
    "        except:\n",
    "            result_dict_[col ] = None\n",
    "    \n",
    "    result_dict_['session_start_time'] = last_visit_dict_['session_start_time']\n",
    "    return result_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attribution_reduce(groups):\n",
    "    for key, records in groups:\n",
    "        is_first_event = 1\n",
    "        attr_window = 7776000\n",
    "        utms = [\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"channel\"\n",
    "        ]\n",
    "        metrics = {\n",
    "            'real_consumption': 0.0,\n",
    "            'real_consumption_vat': 0.0,\n",
    "            'real_payment': 0.0,\n",
    "            'real_payment_vat': 0.0,\n",
    "            'trial_consumption': 0.0,\n",
    "            'trial_consumption_vat': 0.0\n",
    "        }\n",
    "        metric_sku = {}\n",
    "        \n",
    "        visits_settings = [\n",
    "            \"ad_block\",\n",
    "            \"age\",\n",
    "            \"area\",\n",
    "            \"channel\",\n",
    "            \"channel_detailed\",\n",
    "            \"city\",\n",
    "            \"client_ip\",\n",
    "            \"counter_id\",\n",
    "            \"country\",\n",
    "            \"device_model\",\n",
    "            \"device_type\",\n",
    "            \"duration\",\n",
    "            \"first_visit_dt\",\n",
    "            \"general_interests\",\n",
    "            \"hits\",\n",
    "            \"income\",\n",
    "            \"interests\",\n",
    "            \"is_bounce\",\n",
    "            \"mobile_phone_vendor\",\n",
    "            \"os\",\n",
    "            \"page_views\",\n",
    "            \"referer\",\n",
    "            \"remote_ip\",\n",
    "            \"resolution_depth\",\n",
    "            \"resolution_height\",\n",
    "            \"resolution_width\",\n",
    "            \"search_phrase\",\n",
    "            \"sex\",\n",
    "            \"start_time\",\n",
    "            \"total_visits\",\n",
    "            \"user_id\",\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"visit_id\",\n",
    "            \"visit_version\",\n",
    "            \"window_client_height\",\n",
    "            \"window_client_width\",\n",
    "            \"is_robot\",\n",
    "            \"start_url\"\n",
    "        ]\n",
    "        \n",
    "        '''\n",
    "        meta_data_dict = {\n",
    "            \"segment\": None,\n",
    "            \"ba_currency\": None,\n",
    "            \"ba_name\": None,\n",
    "            \"ba_payment_cycle_type\": None,\n",
    "            \"ba_person_type\": None,\n",
    "            \"ba_state\": None,\n",
    "            \"ba_type\": None,\n",
    "            \"ba_usage_status\": None,\n",
    "            \"balance_name\": None,\n",
    "            \"billing_account_id\": None,\n",
    "            \"login\": None,\n",
    "            \"cloud_id\": None,\n",
    "            \"cloud_name\": None,\n",
    "            \"cloud_status\": None,\n",
    "            \"mail_tech\": None,\n",
    "            \"mail_testing\": None,\n",
    "            \"mail_info\": None,\n",
    "            \"mail_feature\": None,\n",
    "            \"mail_event\": None,\n",
    "            \"mail_promo\": None,\n",
    "            \"mail_billing\": None,\n",
    "            \"crm_client_name\": None,\n",
    "            \"sales\": None\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        last_visit_dict = {}\n",
    "        last_direct_visit_dict = {}\n",
    "        funnel_steps = {}\n",
    "        record_list = []\n",
    "        for rec in records:\n",
    "            \n",
    "            if not rec['event_time']:\n",
    "                continue\n",
    "            \n",
    "            result_dict = rec.to_dict().copy()\n",
    "            \n",
    "            '''\n",
    "            for meta in meta_data_dict:\n",
    "                if meta in rec:\n",
    "                    if rec[meta]:\n",
    "                        meta_data_dict[meta] = rec[meta]\n",
    "            '''\n",
    "            \n",
    "            if not rec['event'] in funnel_steps:\n",
    "                funnel_steps[rec['event']] = rec['event_time']\n",
    "            \n",
    "            for metric in metrics:\n",
    "                if metric in result_dict:\n",
    "                    result_dict[metric] = convert_metric_to_float(result_dict[metric])\n",
    "                else:\n",
    "                    result_dict[metric] = 0.0\n",
    "                    \n",
    "                if 'name' in result_dict and metric in result_dict:\n",
    "                    if result_dict['name'] + '_' + metric in metric_sku:\n",
    "                        metric_sku[result_dict['name'] + '_' + metric] += result_dict[metric]\n",
    "                    else:\n",
    "                         metric_sku[result_dict['name'] + '_' + metric] = 0.0\n",
    "                #metrics[metric] += result_dict[metric]\n",
    "                try:\n",
    "                    result_dict[metric + '_cum'] = metric_sku[result_dict['name'] + '_' + metric]\n",
    "                except:\n",
    "                    result_dict[metric + '_cum'] = 0.0\n",
    "                \n",
    "            \n",
    "            if is_first_event == 1:\n",
    "                \n",
    "                is_first_event = 0\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    for utm in utms:\n",
    "                        result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "                else:\n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        \n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and 'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                            \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    if last_direct_visit_dict or last_visit_dict:\n",
    "                        \n",
    "                        if last_direct_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_direct_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_direct_visit_dict)\n",
    "\n",
    "                        elif last_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_visit_dict)\n",
    "                            else:\n",
    "                                for utm in utms:\n",
    "                                    result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    else:\n",
    "                        for utm in utms:\n",
    "                            result_dict[utm] = 'Unknown'\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                                \n",
    "                else:\n",
    "                    \n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and  'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "        \n",
    "        for rec_dict in record_list:\n",
    "            for event in funnel_steps:\n",
    "                rec_dict['first_' + event + '_datetime'] = funnel_steps[event]\n",
    "            #for meta in meta_data_dict:\n",
    "                #rec_dict[meta] = meta_data_dict[meta]\n",
    "                \n",
    "            yield Record(key, **rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"ad_block\": int,\n",
    "    \"age\": str,\n",
    "    \"amount\": str,\n",
    "    \"area\": str,\n",
    "    \"ba_currency\": str,\n",
    "    \"ba_name\": str,\n",
    "    \"ba_payment_cycle_type\": str,\n",
    "    \"ba_person_type\": str,\n",
    "    \"ba_state\": str,\n",
    "    \"ba_type\": str,\n",
    "    \"ba_usage_status\": str,\n",
    "    \"balance_name\": str,\n",
    "    \"billing_account_id\": str,\n",
    "    \"channel\": str,\n",
    "    \"channel_detailed\": str,\n",
    "    \"city\": str,\n",
    "    \"client_ip\": str,\n",
    "    \"cloud_id\": str,\n",
    "    \"cloud_name\": str,\n",
    "    \"cloud_status\": str,\n",
    "    \"cost\": float,\n",
    "    \"counter_id\": str,\n",
    "    \"country\": str,\n",
    "    \"credit\": float,\n",
    "    \"currency\": str,\n",
    "    \"device_model\": str,\n",
    "    \"device_type\": str,\n",
    "    \"duration\": int,\n",
    "    \"email\": str,\n",
    "    \"event\": str,\n",
    "    \"event_time\": str,\n",
    "    \"first_ba_became_paid_datetime\": str,\n",
    "    \"first_ba_created_datetime\": str,\n",
    "    \"first_cloud_created_datetime\": str,\n",
    "    \"first_day_use_datetime\": str,\n",
    "    \"first_first_paid_consumption_datetime\": str,\n",
    "    \"first_first_payment_datetime\": str,\n",
    "    \"first_first_trial_consumption_datetime\": str,\n",
    "    \"first_name\": str,\n",
    "    \"first_visit_datetime\": str,\n",
    "    \"first_visit_dt\": str,\n",
    "    \"general_interests\": str,\n",
    "    \"hits\": int,\n",
    "    \"income\": int,\n",
    "    \"interests\": str,\n",
    "    \"is_bounce\": int,\n",
    "    \"is_robot\": str,\n",
    "    \"last_name\": str,\n",
    "    \"login\": str,\n",
    "    \"mobile_phone_vendor\": int,\n",
    "    \"name\": str,\n",
    "    \"os\": str,\n",
    "    \"page_views\": int,\n",
    "    \"payment_type\": str,\n",
    "    \"phone\": str,\n",
    "    \"promocode_client_name\": str,\n",
    "    \"promocode_client_type\": str,\n",
    "    \"promocode_source\": str,\n",
    "    \"promocode_type\": str,\n",
    "    \"puid\": str,\n",
    "    \"real_consumption\": float,\n",
    "    \"real_consumption_cum\": float,\n",
    "    \"real_payment\": float,\n",
    "    \"real_payment_cum\": float,\n",
    "    \"referer\": str,\n",
    "    \"remote_ip\": str,\n",
    "    \"resolution_depth\": int,\n",
    "    \"resolution_height\": int,\n",
    "    \"resolution_width\": int,\n",
    "    \"search_phrase\": str,\n",
    "    \"segment\": str,\n",
    "    \"service_description\": str,\n",
    "    \"service_id\": str,\n",
    "    \"service_name\": str,\n",
    "    \"session_start_time\": str,\n",
    "    \"sex\": str,\n",
    "    \"sku_id\": str,\n",
    "    \"start_time\": str,\n",
    "    \"start_url\": str,\n",
    "    \"total_visits\": int,\n",
    "    \"trial_consumption\": float,\n",
    "    \"trial_consumption_cum\": float,\n",
    "    \"user_id\": str,\n",
    "    \"user_settings_email\": str,\n",
    "    \"utm_campaign\": str,\n",
    "    \"utm_content\": str,\n",
    "    \"utm_medium\": str,\n",
    "    \"utm_source\": str,\n",
    "    \"utm_term\": str,\n",
    "    \"visit_id\": str,\n",
    "    \"visit_version\": str,\n",
    "    \"window_client_height\": int,\n",
    "    \"window_client_width\": int,\n",
    "    \"mail_tech\": int,\n",
    "    \"mail_testing\": int,\n",
    "    \"mail_info\": int,\n",
    "    \"mail_feature\": int,\n",
    "    \"mail_event\": int,\n",
    "    \"mail_promo\": int,\n",
    "    \"mail_billing\": int,\n",
    "    \"crm_client_name\": str,\n",
    "    \"sales\": str,\n",
    "    \"block_reason\": str,\n",
    "    \"trial_consumption_vat\": float,\n",
    "    \"trial_consumption_vat_cum\": float,\n",
    "    \"real_consumption_vat\": float,\n",
    "    \"real_consumption_vat_cum\": float,\n",
    "    \"real_payment_vat\": float,\n",
    "    \"real_payment_vat_cum\": float,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fa9f69b8e9407ebe639a6e16ab7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 16:54:11,092\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d02a8cda-a03fe6f7-3fe03e8-329680fa&tab=details\n",
      "2019-04-11 16:59:25,219\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=7599766e-e87c6c47-3fe03e8-8d7f422e&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "cube = job.table('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date()))) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .sort(\n",
    "        'event_time'\n",
    "    ) \\\n",
    "    .reduce(\n",
    "        apply_attribution_reduce,\n",
    "        memory_limit = 2048\n",
    "    ) \\\n",
    "    .project(\n",
    "        **apply_types_in_project(schema)\n",
    "    )\n",
    "cube \\\n",
    ".put('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())), schema = schema)\n",
    "#cube \\\n",
    "#.put('%s/%s' % (paths_dict['funnel_cube'],'cube'), schema = schema)\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4014fe8363d481293eede9590dc2e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 17:03:57,796\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=8e8c42e4-87a5d148-3fe03e8-9f4444cb&tab=details\n",
      "2019-04-11 17:07:36,776\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=71230717-ae02c47b-3fe03e8-86fbd391&tab=details\n",
      "2019-04-11 17:08:37,327\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c7add1a8-b63160dc-3fe03e8-1bfd931a&tab=details\n",
      "2019-04-11 17:12:30,443\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=274428c4-f18384c1-3fe03e8-463badb4&tab=details\n",
      "2019-04-11 17:13:58,353\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=3749dffd-60b25770-3fe03e8-297e6703&tab=details\n",
      "2019-04-11 17:14:49,952\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a894e142-ae2e3140-3fe03e8-40196748&tab=details\n",
      "2019-04-11 17:15:26,499\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1d7e6de1-d011cbee-3fe03e8-4a5ebc18&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date()))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 2)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption_to_validate = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption_to_validate = na.sum('trial_consumption', missing=0),\n",
    "        call_to_validate = na.sum('call', missing=0),\n",
    "        visit_to_validate = na.sum('visit', missing=0),\n",
    "        ba_created_to_validate = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption_to_validate = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created_to_validate = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption_to_validate = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid_to_validate = na.sum('ba_became_paid', missing=0),\n",
    "        day_use_to_validate = na.sum('day_use', missing=0),\n",
    "        first_payment_to_validate = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "\n",
    "control = job.table('%s/%s' % (paths_dict['funnel_cube'],str(datetime.date.today() - datetime.timedelta(days = 1)))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 2)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption = na.sum('trial_consumption', missing=0),\n",
    "        call = na.sum('call', missing=0),\n",
    "        visit = na.sum('visit', missing=0),\n",
    "        ba_created = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid = na.sum('ba_became_paid', missing=0),\n",
    "        day_use = na.sum('day_use', missing=0),\n",
    "        first_payment = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "to_val.join(\n",
    "        control,\n",
    "        by = 'date',\n",
    "        type = 'full'\n",
    "    ) \\\n",
    "    .sort('date') \\\n",
    "    .put('%s/validation' % (paths_dict['cube_tmp']))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('day_use', -4)\n",
      "('real_consumption', -21.794647404857365)\n",
      "('trial_consumption', -10.520409147626196)\n"
     ]
    }
   ],
   "source": [
    "val_df = cluster.read('%s/validation' % (paths_dict['cube_tmp'])).as_dataframe().sort_values(by = 'date')\n",
    "\n",
    "col_list = ['ba_became_paid',\n",
    " 'ba_created',\n",
    " 'call',\n",
    " 'cloud_created',\n",
    " 'day_use',\n",
    " 'first_paid_consumption',\n",
    " 'first_payment',\n",
    " 'first_trial_consumption',\n",
    " 'real_consumption',\n",
    " 'trial_consumption',\n",
    " 'visit']\n",
    "\n",
    "diff_col = {}\n",
    "for col in col_list:\n",
    "    val_df[col + '_diff'] = val_df[col] - val_df[col + '_to_validate']\n",
    "    if val_df[col + '_diff'].sum() >= 1 or val_df[col + '_diff'].sum() <= -1:\n",
    "        print(col, val_df[col + '_diff'].sum())\n",
    "        diff_col[col] = val_df[col + '_diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d345eb8dced34227a35903768d8bea34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 17:59:13,268\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1572a3bd-5154f457-3fe03e8-ede917f4&tab=details\n",
      "2019-04-11 18:01:36,703\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e94c80f-dbd215d9-3fe03e8-cc227043&tab=details\n"
     ]
    }
   ],
   "source": [
    "ok = 0\n",
    "if ('visit' in diff_col or 'call' in diff_col or 'day_use' in diff_col):\n",
    "    ok = 1\n",
    "if 'real_consumption' in diff_col:\n",
    "    if abs(diff_col['real_consumption']) < 500:\n",
    "        ok = 1\n",
    "if 'trial_consumption' in diff_col:\n",
    "    if abs(diff_col['trial_consumption']) < 500:\n",
    "        ok = 1\n",
    "if ok == 1:\n",
    "    cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    job = cluster.job()\n",
    "    to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    job.run()\n",
    "\n",
    "    #cluster.driver.remove('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "    #cluster.driver.remove('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "\n",
    "    tables_to_save = date_range_by_days(str(datetime.date.today() - datetime.timedelta(days = 14)), str(datetime.date.today())) + ['cube', 'validation']\n",
    "    tables_to_save = [paths_dict['cube_tmp'] + '/' + table for table in tables_to_save]\n",
    "    for table in get_table_list(paths_dict['cube_tmp'], job).replace('{', '').replace('}', '').split(','):\n",
    "        if table not in tables_to_save:\n",
    "            cluster.driver.remove(table)\n",
    "\n",
    "    text = ['''\n",
    "    Acquisition Cube: Success at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    text = ['''\n",
    "    Acquisition Cube: Fail at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
