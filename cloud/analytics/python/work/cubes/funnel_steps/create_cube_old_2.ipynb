{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, datetime, ast, numpy as np, telebot, json, requests, os, sys\n",
    "module_path = os.path.abspath(os.path.join('/home/ktereshin/yandex/arcadia/cloud/analytics/python/work'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from nile.api.v1 import (\n",
    "    clusters,\n",
    "    aggregators as na,\n",
    "    extractors as ne,\n",
    "    filters as nf,\n",
    "    Record\n",
    ")\n",
    "from vault_client import instances\n",
    "\n",
    "from init_funnel_steps import (\n",
    "    paths_dict_prod,\n",
    "    paths_dict_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service(name_):\n",
    "    return str(name_).split('.')[0]\n",
    "\n",
    "\n",
    "def convert_metric_to_float(num):\n",
    "    try:\n",
    "        return float(num)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def get_payment_type(context):\n",
    "    try:\n",
    "        return ast.literal_eval(context)['payment_type']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_reason(metadata_):\n",
    "    if metadata_ not in ['', None]:\n",
    "        metadata =  json.loads(metadata_)\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    if metadata:\n",
    "        if 'block_reason' in metadata:\n",
    "            return metadata['block_reason']\n",
    "        if 'suspend_reason' in metadata:\n",
    "            return metadata['suspend_reason']\n",
    "        #if 'fraud_detected_by' in metadata:\n",
    "            #if isinstance(metadata['fraud_detected_by'], list):\n",
    "                #return metadata['fraud_detected_by'][0]\n",
    "            #else:\n",
    "                #return metadata['fraud_detected_by'].replace('[', '').replace(']', '').replace(\"u'\", '').replace(\"'\", '')\n",
    "    return 'unknown'\n",
    "\n",
    "def get_datetime_from_epoch(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "    return date_list\n",
    "\n",
    "def get_last_not_empty_table(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    last_table_rows = 0\n",
    "    last_table = ''\n",
    "    for table in tables_list:\n",
    "        try:\n",
    "            table_rows = int(job.driver.get_attribute(table, 'chunk_row_count'))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if table_rows > last_table_rows:\n",
    "            last_table_rows =  table_rows\n",
    "            last_table = table\n",
    "    if last_table:\n",
    "        return last_table\n",
    "    else:\n",
    "        return tables_list[0]\n",
    "\n",
    "\n",
    "def get_table_list(folder_path, job):\n",
    "    tables_list = sorted([folder_path + '/' + x for x in job.driver.list(folder_path)], reverse=True)\n",
    "    return '{%s}' % (','.join(tables_list))\n",
    "\n",
    "def apply_types_in_project(schema_):\n",
    "    apply_types_dict = {}\n",
    "    for col in schema_:\n",
    "        \n",
    "        if schema_[col] == str:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: str(x).replace('\"', '').replace(\"'\", '').replace('\\\\','') if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == int:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: int(x) if x not in ['', None] else None, col)\n",
    "            \n",
    "        elif schema_[col] == float:\n",
    "            apply_types_dict[col] = ne.custom(lambda x: float(x) if x not in ['', None] else None, col)\n",
    "    return apply_types_dict\n",
    "\n",
    "def convert_epoch_to_end_day(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).replace(hour=23).replace(minute=59).replace(second=59))\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def convert_epoch_to_date(epoch):\n",
    "    try:\n",
    "        return str(datetime.datetime.fromtimestamp(int(epoch)).date())\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def date_range_by_days(start_str, end_str):\n",
    "    start = datetime.datetime.strptime(start_str, '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(end_str, '%Y-%m-%d')\n",
    "    delta = int((end - start).days) + 1\n",
    "    date_list = []\n",
    "    \n",
    "    for i in range(delta):\n",
    "        date_list.append( str((start + datetime.timedelta(days = i)).date()) )\n",
    "        \n",
    "    return date_list\n",
    "\n",
    "def get_ba_history(groups):\n",
    "    for key, records in groups:\n",
    "        \n",
    "        rec_list = list(records)\n",
    "        result_dict = {}\n",
    "        start_date = ''\n",
    "        for rec in rec_list:\n",
    "            rec_ = rec.to_dict()\n",
    "            rec_['date'] = convert_epoch_to_date(rec_['updated_at'])\n",
    "            if not start_date:\n",
    "                start_date = rec_['date']\n",
    "                \n",
    "            result_dict[rec_['date']] = rec_\n",
    "        \n",
    "        date_range = date_range_by_days(start_date, str(datetime.date.today()))\n",
    "        res = {}\n",
    "        for date in date_range:\n",
    "            \n",
    "            for date_ in sorted(result_dict):\n",
    "                \n",
    "                if date_ <= date:\n",
    "                    result_dict[date_]['date'] = date\n",
    "                    res = result_dict[date_]\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            yield Record(key, **res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "client = instances.Production()\n",
    "yt_creds = client.get_version('ver-01d33pgv8pzc7t99s3egm24x47')\n",
    "telebot_creds = client.get_version('ver-01d4wza60ns43j5mqktvvvwdnx')\n",
    "bot = telebot.TeleBot(telebot_creds['value']['token'])\n",
    "cluster = clusters.yt.Hahn(\n",
    "    token = yt_creds['value']['token'],\n",
    "    pool = yt_creds['value']['pool']\n",
    ")\n",
    "if mode == 'test':\n",
    "    paths_dict_temp = paths_dict_test\n",
    "elif mode == 'prod':\n",
    "    paths_dict_temp = paths_dict_prod\n",
    "paths_dict = paths_dict_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//home/cloud_analytics/import/iam/cloud_owners/1h/2019-04-11T02:01:08\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-sku/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-services/1d/2019-03-20\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-usage-reports/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-transactions/1h/2019-04-11T05:00:00\n",
      "//home/logfeller/logs/yc-billing-export-billing-accounts-history/1h/2019-04-11T07:00:00\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "for path in['cloud_owner_path', 'billing_accounts_path', 'sku_path', 'service_dict_path', 'billing_accounts_path', 'billing_records_path','transactions_path', 'billing_accounts_history_path']:\n",
    "    valid_path = get_last_not_empty_table(paths_dict_temp[path], job)\n",
    "    print(valid_path)\n",
    "    paths_dict[path] = valid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ed78446029436e8a9be131a4d28970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 10:34:02,004\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6030657f-c0bd69d8-3fe03e8-45629007&tab=details\n",
      "2019-04-11 10:34:30,893\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=9f7ede50-ca511eeb-3fe03e8-baa8e1d1&tab=details\n",
      "2019-04-11 10:34:46,296\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4f739723-e5f3d289-3fe03e8-b0de2f79&tab=details\n",
      "2019-04-11 10:35:10,787\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c6941c66-a9b44d9f-3fe03e8-8ea849a0&tab=details\n",
      "2019-04-11 10:35:51,677\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=f719764e-f49c6291-3fe03e8-b2fa6777&tab=details\n",
      "2019-04-11 10:36:23,041\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6c965191-78b701c1-3fe03e8-a285cd5f&tab=details\n",
      "2019-04-11 10:37:19,015\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2e20c8e0-51297f4c-3fe03e8-2e350e1e&tab=details\n",
      "2019-04-11 10:37:49,080\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=82b0477-cfe13e9-3fe03e8-45e7ac52&tab=details\n",
      "2019-04-11 10:38:27,258\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c95cd926-6439f8e7-3fe03e8-3b99333c&tab=details\n",
      "2019-04-11 10:38:44,512\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=9aa9d9d9-689d484b-3fe03e8-c8ab5888&tab=details\n",
      "2019-04-11 10:39:22,908\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2473e85-d4ceb6bc-3fe03e8-23fb9401&tab=details\n",
      "2019-04-11 10:40:05,905\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1ee99878-34eafdf7-3fe03e8-9bc6cef9&tab=details\n",
      "2019-04-11 10:40:33,271\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d8f7342d-292eed9f-3fe03e8-c7c3f816&tab=details\n",
      "2019-04-11 10:41:01,268\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6042fed2-2f887940-3fe03e8-755db339&tab=details\n",
      "2019-04-11 10:41:58,228\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6a007d9c-2cc14a82-3fe03e8-e9da20b6&tab=details\n",
      "2019-04-11 10:42:55,248\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=674c587f-18873603-3fe03e8-156a46d0&tab=details\n",
      "2019-04-11 10:44:44,421\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a7a879c-e7e99046-3fe03e8-4085d9fe&tab=details\n",
      "2019-04-11 10:49:14,451\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e217b08c-fbc669de-3fe03e8-ed8be441&tab=details\n",
      "2019-04-11 10:50:25,320\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=a597733-89d842ca-3fe03e8-4f3c47a1&tab=details\n",
      "2019-04-11 10:51:25,673\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e8c6b773-e23a9bce-3fe03e8-503ccaaf&tab=details\n",
      "2019-04-11 10:51:45,046\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=cd2d0508-7878d678-3fe03e8-48a0ff9f&tab=details\n",
      "2019-04-11 10:52:04,844\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=837bd82b-620bc2f7-3fe03e8-29ff3722&tab=details\n",
      "2019-04-11 10:53:01,715\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=bb23f508-f7605f9a-3fe03e8-fc66af40&tab=details\n",
      "2019-04-11 10:54:08,183\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=aa83d183-c02cb5c9-3fe03e8-cfcc741b&tab=details\n",
      "2019-04-11 10:54:55,295\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b97389ae-5824e046-3fe03e8-f700a2bd&tab=details\n",
      "2019-04-11 10:55:26,627\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b0f9440d-ae403d6-3fe03e8-6287c42a&tab=details\n",
      "2019-04-11 10:56:10,614\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=7c3be8b5-fcc29dc8-3fe03e8-3e113dba&tab=details\n",
      "2019-04-11 10:56:28,769\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=d0c2da88-59f3565a-3fe03e8-d247a69b&tab=details\n",
      "2019-04-11 10:57:06,772\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=40838438-62b69f25-3fe03e8-96ca921c&tab=details\n",
      "2019-04-11 10:57:35,683\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=562077fb-b3d2f87e-3fe03e8-f9e24899&tab=details\n",
      "2019-04-11 10:58:21,016\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=434c076a-46a3f3d1-3fe03e8-8f5f265&tab=details\n",
      "2019-04-11 10:58:47,147\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ed80c5cf-b62898c6-3fe03e8-108e106a&tab=details\n",
      "2019-04-11 11:00:04,128\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=102e807e-ff9e1e02-3fe03e8-aa4d779c&tab=details\n",
      "2019-04-11 11:04:35,751\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e4505e83-1c550e2e-3fe03e8-3e4043e1&tab=details\n",
      "2019-04-11 11:04:47,972\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c6fa98c-9e59ebf4-3fe03e8-f6507a9a&tab=details\n",
      "2019-04-11 11:05:52,585\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4547d3cd-c90da1c9-3fe03e8-626622ab&tab=details\n",
      "2019-04-11 11:07:18,974\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2e76470b-6c8228eb-3fe03e8-379bf2d&tab=details\n",
      "2019-04-11 11:09:21,117\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=6ec4681b-43ab6455-3fe03e8-7ad71812&tab=details\n",
      "2019-04-11 11:09:44,937\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=25555051-819b2388-3fe03e8-d6cdacae&tab=details\n",
      "2019-04-11 11:10:04,704\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=9df0e8ab-20991b73-3fe03e8-5875b231&tab=details\n",
      "2019-04-11 11:10:37,745\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=14eed002-50639eee-3fe03e8-db7f1403&tab=details\n",
      "2019-04-11 11:11:21,354\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4a93322f-f77d1004-3fe03e8-55429a00&tab=details\n",
      "2019-04-11 11:11:48,846\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ee00d801-b5774b2-3fe03e8-229c6490&tab=details\n",
      "2019-04-11 11:12:35,911\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=4cfcfa6e-585f025f-3fe03e8-57e912d2&tab=details\n",
      "2019-04-11 11:15:27,124\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ceaa9c45-8155739c-3fe03e8-5223f7c&tab=details\n",
      "2019-04-11 11:17:27,100\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=e47857d-e1d5af4d-3fe03e8-7237badc&tab=details\n",
      "2019-04-11 11:19:22,959\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=46da5600-f5494f9-3fe03e8-e1bc788b&tab=details\n",
      "2019-04-11 11:19:58,560\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5cb0b076-b33411bd-3fe03e8-4a44db85&tab=details\n",
      "2019-04-11 11:20:20,783\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=631343b5-b2f10dcd-3fe03e8-536a5928&tab=details\n",
      "2019-04-11 11:20:56,210\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b2c1984e-a557c6aa-3fe03e8-1f855fc9&tab=details\n",
      "2019-04-11 11:22:03,121\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b63b0cea-f8ed89e2-3fe03e8-8a4887f8&tab=details\n",
      "2019-04-11 11:24:04,540\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=77e74495-f0954fea-3fe03e8-8a0d37d7&tab=details\n",
      "2019-04-11 11:25:45,689\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=624ab128-73ee8ffd-3fe03e8-e061a2a8&tab=details\n",
      "2019-04-11 11:27:51,719\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=43771394-120b9c50-3fe03e8-eee8ad1f&tab=details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 11:30:17,769\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1f155d26-1758cae1-3fe03e8-176f722f&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "\n",
    "\n",
    "#cloud created event\n",
    "clouds = job.table(paths_dict['cloud_owner_path']) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        mail_tech = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_testing = ne.custom(lambda x: 1 if x else 0, 'mail_testing'),\n",
    "        mail_info = ne.custom(lambda x: 1 if x else 0, 'mail_info'),\n",
    "        mail_feature = ne.custom(lambda x: 1 if x else 0, 'mail_tech'),\n",
    "        mail_event = ne.custom(lambda x: 1 if x else 0, 'mail_event'),\n",
    "        mail_promo = ne.custom(lambda x: 1 if x else 0, 'mail_promo'),\n",
    "        mail_billing = ne.custom(lambda x: 1 if x else 0, 'mail_billing'),\n",
    "        cloud_id = 'id',\n",
    "        event = ne.const('cloud_created'),\n",
    "        event_time = ne.custom(lambda x: ' '.join(str(x).split('+')[0].split('T')), 'cloud_created_at'),\n",
    "        puid = 'passport_uid'\n",
    "    \n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        email = na.first('email', by='event_time'),\n",
    "        first_name = na.first('first_name', by='event_time'),\n",
    "        last_name = na.first('last_name', by='event_time'),\n",
    "        login = na.first('login', by='event_time'),\n",
    "        phone = na.first('phone', by='event_time'),\n",
    "        user_settings_email = na.first('user_settings_email', by='event_time'),\n",
    "        cloud_status = na.first('cloud_status', by='event_time'),\n",
    "        cloud_name = na.first('cloud_name', by='event_time'),\n",
    "        event = na.first('event', by='cloud_created_at'),\n",
    "        event_time = na.first('event_time', by='cloud_created_at'),\n",
    "        cloud_id = na.first('cloud_id', by='cloud_created_at'),\n",
    "        mail_tech = na.first('mail_tech', by='cloud_created_at'),\n",
    "        mail_testing = na.first('mail_testing', by='cloud_created_at'),\n",
    "        mail_info = na.first('mail_info', by='cloud_created_at'),\n",
    "        mail_feature = na.first('mail_feature', by='cloud_created_at'),\n",
    "        mail_event = na.first('mail_event', by='cloud_created_at'),\n",
    "        mail_promo = na.first('mail_promo', by='cloud_created_at'),\n",
    "        mail_billing = na.first('mail_billing', by='cloud_created_at')\n",
    "    )\n",
    "\n",
    "clouds_ = clouds \\\n",
    "    .unique(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'email',\n",
    "        'first_name',\n",
    "        'last_name',\n",
    "        'login',\n",
    "        'phone',\n",
    "        'user_settings_email',\n",
    "        'cloud_status',\n",
    "        'cloud_name',\n",
    "        'cloud_id',\n",
    "        'puid',\n",
    "        'mail_tech',\n",
    "        'mail_testing',\n",
    "        'mail_info',\n",
    "        'mail_feature',\n",
    "        'mail_event',\n",
    "        'mail_promo',\n",
    "        'mail_billing'\n",
    "    )\n",
    "\n",
    "offers = job.table(paths_dict['offers_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in [None, ''], 'passport_uid')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'passport_uid'\n",
    "    ) \\\n",
    "    .project(\n",
    "        promocode_client_name = 'client_name',\n",
    "        promocode_type = 'type',\n",
    "        puid = 'passport_uid',\n",
    "        promocode_source = 'client_source',\n",
    "        promocode_client_type = ne.custom(lambda x: 'Enterprise/ISV' if x == 'direct_offer' else 'Direct')\n",
    "    )\n",
    "\n",
    "segments = job.table(paths_dict['client_segments']) \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    )\n",
    "\n",
    "passports = job.table(paths_dict['balance']) \\\n",
    "    .unique(\n",
    "        'PASSPORT_ID'\n",
    "    ) \\\n",
    "    .project(\n",
    "        puid = 'PASSPORT_ID',\n",
    "        balance_name = 'NAME'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = job.table(paths_dict['billing_accounts_path']) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ba_created_at = 'created_at',\n",
    "        ba_name = 'name',\n",
    "        ba_state = 'state',\n",
    "        ba_person_type = 'person_type',\n",
    "        ba_payment_cycle_type = 'payment_cycle_type',\n",
    "        ba_usage_status =  'usage_status',\n",
    "        ba_currency = 'currency',\n",
    "        ba_type = 'type',\n",
    "        billing_account_id = 'id',\n",
    "        puid = 'owner_id',\n",
    "        block_reason = ne.custom(lambda x,y:get_reason(y) if x == 'suspended' else 'Unlocked', 'state', 'metadata')\n",
    "    ) \\\n",
    "    .join(\n",
    "        offers,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        segments,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        passports,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict_ = ba_puid_dict_ \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        segment = ne.custom(lambda x: x.lower() if x not in ['', None] else 'mass', 'segment')\n",
    "    )\n",
    "\n",
    "\n",
    "sku_dict = job.table(paths_dict['sku_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        'name',\n",
    "        'service_id',\n",
    "        sku_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "service_dict = job.table(paths_dict['service_dict_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x not in ['', None], 'id')\n",
    "    ) \\\n",
    "    .unique(\n",
    "        'id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        service_name = 'name',\n",
    "        service_description = 'description',\n",
    "        service_id = 'id'\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "sku_dict = sku_dict \\\n",
    "    .join(\n",
    "        service_dict,\n",
    "        by = 'service_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "ba_puid_dict = ba_puid_dict_ \\\n",
    "    .join(\n",
    "        clouds_,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "bas = ba_puid_dict \\\n",
    "    .unique(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        event = ne.const('ba_created'),\n",
    "        event_time = ne.custom(get_datetime_from_epoch, 'ba_created_at')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_puid_dict__ = ba_puid_dict_.unique('puid')\n",
    "visits = job.table(paths_dict['visits_path'])\n",
    "calls = job.table(paths_dict['calls'])\n",
    "click_mail = job.table(paths_dict['click_email']) \n",
    "#open_mail = job.table(paths_dict['open_mail']) \n",
    "\n",
    "puid_sets = job.concat(\n",
    "    clouds,\n",
    "    visits,\n",
    "    calls,\n",
    "    click_mail\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict__,\n",
    "        by = 'puid',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        ba_name = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_name'),\n",
    "        ba_payment_cycle_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_payment_cycle_type'),\n",
    "        ba_person_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_person_type'),\n",
    "        ba_state = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_state'),\n",
    "        ba_type = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_type'),\n",
    "        ba_usage_status = ne.custom(lambda x: x if x else 'ba_not_created', 'ba_usage_status'),\n",
    "        block_reason = ne.custom(lambda x: x if x else 'ba_not_created', 'block_reason'),\n",
    "        segment = ne.custom(lambda x: x if x else 'unknown', 'segment'),\n",
    "        promocode_client_name = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_name'),\n",
    "        promocode_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_type'),\n",
    "        promocode_source = ne.custom(lambda x: x if x else 'unknown', 'promocode_source'),\n",
    "        promocode_client_type = ne.custom(lambda x: x if x else 'unknown', 'promocode_client_type'),\n",
    "        balance_name = ne.custom(lambda x: x if x else 'unknown', 'balance_name'),\n",
    "        sales = ne.custom(lambda x: x if x else 'unknown', 'sales'),\n",
    "        crm_client_name = ne.custom(lambda x: x if x else 'unknown', 'crm_client_name')\n",
    "    )\n",
    "\n",
    "#========================================\n",
    "ba_became_paid = job.table(paths_dict['billing_accounts_history_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: str(x).lower() == 'paid', 'usage_status')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.min('updated_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('ba_became_paid')\n",
    "    )\n",
    "\n",
    "first_trial_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: float(x) < 0, 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:57','event_time'),\n",
    "        event = ne.const('first_trial_consumption')\n",
    "    )\n",
    "\n",
    "\n",
    "first_paid_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x, y: float(x) + float(y) > 0, 'cost', 'credit')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('date', by='date'),\n",
    "        sku_id = na.first('sku_id', by='date'),\n",
    "        cloud_id = na.first('cloud_id', by='date'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'cloud_id',\n",
    "        event_time = ne.custom( lambda x:  str(x) + ' 23:59:58','event_time'),\n",
    "        event = ne.const('first_paid_consumption')\n",
    "    )\n",
    "\n",
    "first_payment = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        ne.all(),\n",
    "        payment_type = ne.custom(get_payment_type, 'context')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        event_time = na.first('modified_at', by='modified_at'),\n",
    "        amount = na.first('amount', by='modified_at'),\n",
    "        currency = na.first('currency', by='modified_at'),\n",
    "        payment_type = na.first('payment_type', by='modified_at')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'amount',\n",
    "        'currency',\n",
    "        'payment_type',\n",
    "        event_time = ne.custom( get_datetime_from_epoch,'event_time'),\n",
    "        event = ne.const('first_payment')\n",
    "    )\n",
    "\n",
    "day_use_consumption = job.table(paths_dict['billing_records_path']) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        trial_consumption = ne.custom(lambda x: convert_metric_to_float(x)*-1, 'credit'),\n",
    "        real_consumption = ne.custom(lambda x, y: convert_metric_to_float(x) + convert_metric_to_float(y) if x not in [None, ''] and y not in [None, ''] else 0.0,'cost', 'credit'),\n",
    "        event_time = ne.custom(lambda x: str(x) + ' 23:59:59', 'date'),\n",
    "        event = ne.const('day_use'),\n",
    "        real_payment = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'sku_id',\n",
    "        'event',\n",
    "        'event_time'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_payment = na.sum('real_payment')\n",
    "    )\n",
    "\n",
    "day_use_payments = job.table(paths_dict['transactions_path']) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x == 'payments', 'type'),\n",
    "        nf.custom(lambda x: x == 'ok', 'status'),\n",
    "    ) \\\n",
    "    .project(\n",
    "        'billing_account_id',\n",
    "        'currency',\n",
    "        sku_id = ne.const(''),\n",
    "        event_time = ne.custom(convert_epoch_to_end_day, 'modified_at'),\n",
    "        real_payment = ne.custom(lambda x: convert_metric_to_float(x), 'amount'),\n",
    "        event = ne.const('day_use'),\n",
    "        trial_consumption = ne.const(0),\n",
    "        real_consumption = ne.const(0)\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'billing_account_id',\n",
    "        'event_time',\n",
    "        'event',\n",
    "        'sku_id'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        trial_consumption = na.sum('trial_consumption'),\n",
    "        real_consumption = na.sum('real_consumption'),\n",
    "        real_payment = na.sum('real_payment')\n",
    "    )\n",
    "\n",
    "ba_sets = job.concat(\n",
    "    bas,\n",
    "    day_use_consumption,\n",
    "    day_use_payments,\n",
    "    first_payment,\n",
    "    first_paid_consumption,\n",
    "    first_trial_consumption,\n",
    "    ba_became_paid\n",
    "    ) \\\n",
    "    .join(\n",
    "        ba_puid_dict,\n",
    "        by = 'billing_account_id',\n",
    "        type = 'left'\n",
    "    ) \\\n",
    "    .join(\n",
    "        sku_dict,\n",
    "        by = 'sku_id',\n",
    "        type = 'left'\n",
    "    )\n",
    "\n",
    "result = job.concat(\n",
    "        puid_sets,\n",
    "        ba_sets\n",
    "    )\n",
    "\n",
    "result.put('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_delta(new_date, old_date):\n",
    "    try:\n",
    "        return (datetime.datetime.strptime(new_date, '%Y-%m-%d %H:%M:%S') - datetime.datetime.strptime(old_date, '%Y-%m-%d %H:%M:%S')).seconds\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def apply_attr(result_dict_, last_visit_dict_):\n",
    "    for col in last_visit_dict_:\n",
    "        try:\n",
    "            result_dict_[col] = last_visit_dict_[col]\n",
    "            \n",
    "        except:\n",
    "            result_dict_[col ] = None\n",
    "    \n",
    "    result_dict_['session_start_time'] = last_visit_dict_['session_start_time']\n",
    "    return result_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attribution_reduce(groups):\n",
    "    for key, records in groups:\n",
    "        is_first_event = 1\n",
    "        attr_window = 7776000\n",
    "        utms = [\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"channel\"\n",
    "        ]\n",
    "        metrics = {\n",
    "            'real_consumption': 0.0,\n",
    "            'real_payment': 0.0,\n",
    "            'trial_consumption': 0.0\n",
    "        }\n",
    "        \n",
    "        visits_settings = [\n",
    "            \"ad_block\",\n",
    "            \"age\",\n",
    "            \"area\",\n",
    "            \"channel\",\n",
    "            \"channel_detailed\",\n",
    "            \"city\",\n",
    "            \"client_ip\",\n",
    "            \"counter_id\",\n",
    "            \"country\",\n",
    "            \"device_model\",\n",
    "            \"device_type\",\n",
    "            \"duration\",\n",
    "            \"first_visit_dt\",\n",
    "            \"general_interests\",\n",
    "            \"hits\",\n",
    "            \"income\",\n",
    "            \"interests\",\n",
    "            \"is_bounce\",\n",
    "            \"mobile_phone_vendor\",\n",
    "            \"os\",\n",
    "            \"page_views\",\n",
    "            \"referer\",\n",
    "            \"remote_ip\",\n",
    "            \"resolution_depth\",\n",
    "            \"resolution_height\",\n",
    "            \"resolution_width\",\n",
    "            \"search_phrase\",\n",
    "            \"sex\",\n",
    "            \"start_time\",\n",
    "            \"total_visits\",\n",
    "            \"user_id\",\n",
    "            \"utm_campaign\",\n",
    "            \"utm_content\",\n",
    "            \"utm_medium\",\n",
    "            \"utm_source\",\n",
    "            \"utm_term\",\n",
    "            \"visit_id\",\n",
    "            \"visit_version\",\n",
    "            \"window_client_height\",\n",
    "            \"window_client_width\",\n",
    "            \"is_robot\",\n",
    "            \"start_url\"\n",
    "        ]\n",
    "        \n",
    "        '''\n",
    "        meta_data_dict = {\n",
    "            \"segment\": None,\n",
    "            \"ba_currency\": None,\n",
    "            \"ba_name\": None,\n",
    "            \"ba_payment_cycle_type\": None,\n",
    "            \"ba_person_type\": None,\n",
    "            \"ba_state\": None,\n",
    "            \"ba_type\": None,\n",
    "            \"ba_usage_status\": None,\n",
    "            \"balance_name\": None,\n",
    "            \"billing_account_id\": None,\n",
    "            \"login\": None,\n",
    "            \"cloud_id\": None,\n",
    "            \"cloud_name\": None,\n",
    "            \"cloud_status\": None,\n",
    "            \"mail_tech\": None,\n",
    "            \"mail_testing\": None,\n",
    "            \"mail_info\": None,\n",
    "            \"mail_feature\": None,\n",
    "            \"mail_event\": None,\n",
    "            \"mail_promo\": None,\n",
    "            \"mail_billing\": None,\n",
    "            \"crm_client_name\": None,\n",
    "            \"sales\": None\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        last_visit_dict = {}\n",
    "        last_direct_visit_dict = {}\n",
    "        funnel_steps = {}\n",
    "        record_list = []\n",
    "        for rec in records:\n",
    "            \n",
    "            if not rec['event_time']:\n",
    "                continue\n",
    "            \n",
    "            result_dict = rec.to_dict().copy()\n",
    "            \n",
    "            '''\n",
    "            for meta in meta_data_dict:\n",
    "                if meta in rec:\n",
    "                    if rec[meta]:\n",
    "                        meta_data_dict[meta] = rec[meta]\n",
    "            '''\n",
    "            \n",
    "            if not rec['event'] in funnel_steps:\n",
    "                funnel_steps[rec['event']] = rec['event_time']\n",
    "            \n",
    "            for metric in metrics:\n",
    "                if metric in result_dict:\n",
    "                    result_dict[metric] = convert_metric_to_float(result_dict[metric])\n",
    "                else:\n",
    "                    result_dict[metric] = 0.0\n",
    "                metrics[metric] += result_dict[metric]\n",
    "                result_dict[metric + '_cum'] = metrics[metric]\n",
    "                \n",
    "            \n",
    "            if is_first_event == 1:\n",
    "                \n",
    "                is_first_event = 0\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    for utm in utms:\n",
    "                        result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "                else:\n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        \n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and 'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                            \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                if rec['event'] not in ['visit', 'day_use', 'call', 'click_mail']:\n",
    "                    \n",
    "                    if last_direct_visit_dict or last_visit_dict:\n",
    "                        \n",
    "                        if last_direct_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_direct_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_direct_visit_dict)\n",
    "\n",
    "                        elif last_visit_dict:\n",
    "                            if get_time_delta(result_dict['event_time'], last_visit_dict['session_start_time']) <= attr_window:\n",
    "                                result_dict = apply_attr(result_dict, last_visit_dict)\n",
    "                            else:\n",
    "                                for utm in utms:\n",
    "                                    result_dict[utm] = 'Unknown'\n",
    "                        \n",
    "                    else:\n",
    "                        for utm in utms:\n",
    "                            result_dict[utm] = 'Unknown'\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "                                \n",
    "                else:\n",
    "                    \n",
    "                    if rec['event'] in ('visit', 'call', 'click_mail'):\n",
    "                        if 'cloud.yandex' in str(rec['referer']):\n",
    "                            continue\n",
    "                        \n",
    "                        for visit_col in visits_settings:\n",
    "                            last_visit_dict[visit_col] = rec[visit_col]\n",
    "                            \n",
    "                        last_visit_dict['session_start_time'] = rec['event_time']\n",
    "                        \n",
    "                        if (last_visit_dict['referer'] not in ['', None] and 'cloud.' not in last_visit_dict['referer'] and  'Organic' not in last_visit_dict['channel']) or rec['event'] in ['call', 'click_mail']:\n",
    "                            \n",
    "                            for visit_col in visits_settings:\n",
    "                                last_direct_visit_dict[visit_col] = rec[visit_col]\n",
    "                                \n",
    "                            last_direct_visit_dict['session_start_time'] = rec['event_time']\n",
    "                    \n",
    "                    #yield Record(key, **result_dict)\n",
    "                    record_list.append(result_dict)\n",
    "        \n",
    "        for rec_dict in record_list:\n",
    "            for event in funnel_steps:\n",
    "                rec_dict['first_' + event + '_datetime'] = funnel_steps[event]\n",
    "            #for meta in meta_data_dict:\n",
    "                #rec_dict[meta] = meta_data_dict[meta]\n",
    "                \n",
    "            yield Record(key, **rec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"ad_block\": int,\n",
    "    \"age\": str,\n",
    "    \"amount\": str,\n",
    "    \"area\": str,\n",
    "    \"ba_currency\": str,\n",
    "    \"ba_name\": str,\n",
    "    \"ba_payment_cycle_type\": str,\n",
    "    \"ba_person_type\": str,\n",
    "    \"ba_state\": str,\n",
    "    \"ba_type\": str,\n",
    "    \"ba_usage_status\": str,\n",
    "    \"balance_name\": str,\n",
    "    \"billing_account_id\": str,\n",
    "    \"channel\": str,\n",
    "    \"channel_detailed\": str,\n",
    "    \"city\": str,\n",
    "    \"client_ip\": str,\n",
    "    \"cloud_id\": str,\n",
    "    \"cloud_name\": str,\n",
    "    \"cloud_status\": str,\n",
    "    \"cost\": float,\n",
    "    \"counter_id\": str,\n",
    "    \"country\": str,\n",
    "    \"credit\": float,\n",
    "    \"currency\": str,\n",
    "    \"device_model\": str,\n",
    "    \"device_type\": str,\n",
    "    \"duration\": int,\n",
    "    \"email\": str,\n",
    "    \"event\": str,\n",
    "    \"event_time\": str,\n",
    "    \"first_ba_became_paid_datetime\": str,\n",
    "    \"first_ba_created_datetime\": str,\n",
    "    \"first_cloud_created_datetime\": str,\n",
    "    \"first_day_use_datetime\": str,\n",
    "    \"first_first_paid_consumption_datetime\": str,\n",
    "    \"first_first_payment_datetime\": str,\n",
    "    \"first_first_trial_consumption_datetime\": str,\n",
    "    \"first_name\": str,\n",
    "    \"first_visit_datetime\": str,\n",
    "    \"first_visit_dt\": str,\n",
    "    \"general_interests\": str,\n",
    "    \"hits\": int,\n",
    "    \"income\": int,\n",
    "    \"interests\": str,\n",
    "    \"is_bounce\": int,\n",
    "    \"is_robot\": str,\n",
    "    \"last_name\": str,\n",
    "    \"login\": str,\n",
    "    \"mobile_phone_vendor\": int,\n",
    "    \"name\": str,\n",
    "    \"os\": str,\n",
    "    \"page_views\": int,\n",
    "    \"payment_type\": str,\n",
    "    \"phone\": str,\n",
    "    \"promocode_client_name\": str,\n",
    "    \"promocode_client_type\": str,\n",
    "    \"promocode_source\": str,\n",
    "    \"promocode_type\": str,\n",
    "    \"puid\": str,\n",
    "    \"real_consumption\": float,\n",
    "    \"real_consumption_cum\": float,\n",
    "    \"real_payment\": float,\n",
    "    \"real_payment_cum\": float,\n",
    "    \"referer\": str,\n",
    "    \"remote_ip\": str,\n",
    "    \"resolution_depth\": int,\n",
    "    \"resolution_height\": int,\n",
    "    \"resolution_width\": int,\n",
    "    \"search_phrase\": str,\n",
    "    \"segment\": str,\n",
    "    \"service_description\": str,\n",
    "    \"service_id\": str,\n",
    "    \"service_name\": str,\n",
    "    \"session_start_time\": str,\n",
    "    \"sex\": str,\n",
    "    \"sku_id\": str,\n",
    "    \"start_time\": str,\n",
    "    \"start_url\": str,\n",
    "    \"total_visits\": int,\n",
    "    \"trial_consumption\": float,\n",
    "    \"trial_consumption_cum\": float,\n",
    "    \"user_id\": str,\n",
    "    \"user_settings_email\": str,\n",
    "    \"utm_campaign\": str,\n",
    "    \"utm_content\": str,\n",
    "    \"utm_medium\": str,\n",
    "    \"utm_source\": str,\n",
    "    \"utm_term\": str,\n",
    "    \"visit_id\": str,\n",
    "    \"visit_version\": str,\n",
    "    \"window_client_height\": int,\n",
    "    \"window_client_width\": int,\n",
    "    \"mail_tech\": int,\n",
    "    \"mail_testing\": int,\n",
    "    \"mail_info\": int,\n",
    "    \"mail_feature\": int,\n",
    "    \"mail_event\": int,\n",
    "    \"mail_promo\": int,\n",
    "    \"mail_billing\": int,\n",
    "    \"crm_client_name\": str,\n",
    "    \"sales\": str,\n",
    "    \"block_reason\": str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37edc7b1d13d4092add697652e462953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 12:34:09,754\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2798c92b-873e0c28-3fe03e8-37077a&tab=details\n",
      "2019-04-11 12:40:33,641\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1d8138f5-295d44d3-3fe03e8-a7f96dc0&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "cube = job.table('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date()))) \\\n",
    "    .groupby(\n",
    "        'puid'\n",
    "    ) \\\n",
    "    .sort(\n",
    "        'event_time'\n",
    "    ) \\\n",
    "    .reduce(\n",
    "        apply_attribution_reduce,\n",
    "        memory_limit = 2048\n",
    "    ) \\\n",
    "    .project(\n",
    "        **apply_types_in_project(schema)\n",
    "    )\n",
    "cube \\\n",
    ".put('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())), schema = schema)\n",
    "#cube \\\n",
    "#.put('%s/%s' % (paths_dict['funnel_cube'],'cube'), schema = schema)\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c15b8b70a4539b5fdc2da770fc507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 12:46:01,300\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=c4f1fabf-37e7ad2e-3fe03e8-f8ad5e58&tab=details\n",
      "2019-04-11 12:49:46,855\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=354b8b79-a36d53c-3fe03e8-71144698&tab=details\n",
      "2019-04-11 12:50:54,735\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=1fb2beb1-b498ae6b-3fe03e8-a979d89e&tab=details\n",
      "2019-04-11 12:54:46,629\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=b3c0477-8ef0c69f-3fe03e8-8081089d&tab=details\n",
      "2019-04-11 12:55:44,119\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=f482b16b-d6045b59-3fe03e8-646f9a00&tab=details\n",
      "2019-04-11 12:56:38,979\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=7377da26-fd2d663b-3fe03e8-78dcda00&tab=details\n",
      "2019-04-11 12:57:09,133\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=5e137e55-ee90b34-3fe03e8-a5c8ac0f&tab=details\n"
     ]
    }
   ],
   "source": [
    "job = cluster.job()\n",
    "to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date()))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 2)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption_to_validate = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption_to_validate = na.sum('trial_consumption', missing=0),\n",
    "        call_to_validate = na.sum('call', missing=0),\n",
    "        visit_to_validate = na.sum('visit', missing=0),\n",
    "        ba_created_to_validate = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption_to_validate = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created_to_validate = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption_to_validate = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid_to_validate = na.sum('ba_became_paid', missing=0),\n",
    "        day_use_to_validate = na.sum('day_use', missing=0),\n",
    "        first_payment_to_validate = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "\n",
    "control = job.table('%s/%s' % (paths_dict['funnel_cube'],str(datetime.date.today() - datetime.timedelta(days = 1)))) \\\n",
    "    .filter(\n",
    "        nf.custom(lambda x: x < str(datetime.date.today() - datetime.timedelta(days = 1)), 'event_time')\n",
    "    ) \\\n",
    "    .project(\n",
    "        'real_consumption',\n",
    "        'trial_consumption',\n",
    "        date = ne.custom(lambda x: str(x).split(' ')[0], 'event_time'),\n",
    "        call = ne.custom(lambda x: 1 if str(x) == 'call' else 0, 'event'),\n",
    "        visit = ne.custom(lambda x: 1 if str(x) == 'visit' else 0, 'event'),\n",
    "        ba_created = ne.custom(lambda x: 1 if str(x) == 'ba_created' else 0, 'event'),\n",
    "        first_paid_consumption = ne.custom(lambda x: 1 if str(x) == 'first_paid_consumption' else 0, 'event'),\n",
    "        cloud_created = ne.custom(lambda x: 1 if str(x) == 'cloud_created' else 0, 'event'),\n",
    "        first_trial_consumption = ne.custom(lambda x: 1 if str(x) == 'first_trial_consumption' else 0, 'event'),\n",
    "        ba_became_paid = ne.custom(lambda x: 1 if str(x) == 'ba_became_paid' else 0, 'event'),\n",
    "        day_use = ne.custom(lambda x: 1 if str(x) == 'day_use' else 0, 'event'),\n",
    "        first_payment = ne.custom(lambda x: 1 if str(x) == 'first_payment' else 0, 'event')\n",
    "    ) \\\n",
    "    .groupby(\n",
    "        'date'\n",
    "    ) \\\n",
    "    .aggregate(\n",
    "        real_consumption = na.sum('real_consumption', missing=0),\n",
    "        trial_consumption = na.sum('trial_consumption', missing=0),\n",
    "        call = na.sum('call', missing=0),\n",
    "        visit = na.sum('visit', missing=0),\n",
    "        ba_created = na.sum('ba_created', missing=0),\n",
    "        first_paid_consumption = na.sum('first_paid_consumption', missing=0),\n",
    "        cloud_created = na.sum('cloud_created', missing=0),\n",
    "        first_trial_consumption = na.sum('first_trial_consumption', missing=0),\n",
    "        ba_became_paid = na.sum('ba_became_paid', missing=0),\n",
    "        day_use = na.sum('day_use', missing=0),\n",
    "        first_payment = na.sum('first_payment', missing=0)\n",
    "    )\n",
    "to_val.join(\n",
    "        control,\n",
    "        by = 'date',\n",
    "        type = 'full'\n",
    "    ) \\\n",
    "    .sort('date') \\\n",
    "    .put('%s/validation' % (paths_dict['cube_tmp']))\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('day_use', -15.0)\n",
      "('real_consumption', -6.634939362292295)\n",
      "('trial_consumption', -1.5201951488488703)\n"
     ]
    }
   ],
   "source": [
    "val_df = cluster.read('%s/validation' % (paths_dict['cube_tmp'])).as_dataframe().sort_values(by = 'date')\n",
    "\n",
    "col_list = ['ba_became_paid',\n",
    " 'ba_created',\n",
    " 'call',\n",
    " 'cloud_created',\n",
    " 'day_use',\n",
    " 'first_paid_consumption',\n",
    " 'first_payment',\n",
    " 'first_trial_consumption',\n",
    " 'real_consumption',\n",
    " 'trial_consumption',\n",
    " 'visit']\n",
    "\n",
    "diff_col = {}\n",
    "for col in col_list:\n",
    "    val_df[col + '_diff'] = val_df[col] - val_df[col + '_to_validate']\n",
    "    if val_df[col + '_diff'].sum() >= 1 or val_df[col + '_diff'].sum() <= -1:\n",
    "        print(col, val_df[col + '_diff'].sum())\n",
    "        diff_col[col] = val_df[col + '_diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e3ee4abbf44e3d8eeb22da71304d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-11 13:01:13,543\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=2c4dadfe-14862d7b-3fe03e8-8b7cb12f&tab=details\n",
      "2019-04-11 13:05:12,945\tINFO\tOperation started: http://hahn.yt.yandex.net/?page=operation&mode=detail&id=ab6071f3-e5771b92-3fe03e8-d0b79bbb&tab=details\n"
     ]
    }
   ],
   "source": [
    "ok = 0\n",
    "if ('visit' in diff_col or 'call' in diff_col or 'day_use' in diff_col):\n",
    "    ok = 1\n",
    "if 'real_consumption' in diff_col:\n",
    "    if abs(diff_col['real_consumption']) < 500:\n",
    "        ok = 1\n",
    "if 'trial_consumption' in diff_col:\n",
    "    if abs(diff_col['trial_consumption']) < 500:\n",
    "        ok = 1\n",
    "if ok == 1:\n",
    "    cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    #cluster.driver.remove('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    job = cluster.job()\n",
    "    to_val = job.table('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "    to_val.put('%s/%s' % (paths_dict['funnel_cube'],'cube'))\n",
    "    job.run()\n",
    "\n",
    "    #cluster.driver.remove('%s/%s_temp' % (paths_dict['cube_tmp'],str(datetime.datetime.today().date())))\n",
    "    #cluster.driver.remove('%s/%s_to_validate' % (paths_dict['funnel_cube'],str(datetime.datetime.today().date())))\n",
    "\n",
    "    tables_to_save = date_range_by_days(str(datetime.date.today() - datetime.timedelta(days = 14)), str(datetime.date.today())) + ['cube', 'validation']\n",
    "    tables_to_save = [paths_dict['cube_tmp'] + '/' + table for table in tables_to_save]\n",
    "    for table in get_table_list(paths_dict['cube_tmp'], job).replace('{', '').replace('}', '').split(','):\n",
    "        if table not in tables_to_save:\n",
    "            cluster.driver.remove(table)\n",
    "\n",
    "    text = ['''\n",
    "    Acquisition Cube: Success at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    text = ['''\n",
    "    Acquisition Cube: Fail at {0}\n",
    "    '''.format(datetime.datetime.now())]\n",
    "    for col in diff_col:\n",
    "        text.append('''\n",
    "        Have diff in {0} = {1}\n",
    "        '''.format(col, diff_col[col]))\n",
    "    text.append('=============================================')\n",
    "    #bot.send_message(telebot_creds['value']['chat_id'], '\\n'.join(text))\n",
    "    requests.post('https://api.telegram.org/bot{0}/sendMessage?chat_id={1}&text={2}'.format(\n",
    "        telebot_creds['value']['token'],\n",
    "        telebot_creds['value']['chat_id'],\n",
    "        '\\n'.join(text)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2-venv",
   "language": "python",
   "name": "python2-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
