# Pgsync

## Назначение
Pgsync -- это диспетчер, управляющий базами Postgresql. В его задачи входит возрат кластера в работоспособное состояние в случае внештатной ситуации.

## Возможности
 * Регулировка синхронности репликации в зависимости от качества связности узлов;
 * Переключение роли мастера между участниками кластера в случае необходимости;
 * Изоляция узла от нагрузки в случае возникновения внештатной ситуации;

## Описание механизма работы

### Общее описание

Сразу после запуска, gpsync входит в петлю обработки, где каждую секунду выполняет следующее:

1. Проверяется блокировка в Zookeeper,
2. Собирается информация о состоянии реплик и мастера,
3. Собранная информация записывается в ZK,
4. Принимается решение о необходимости вмешательства в работу кластера.

П. 4 на текущий момент зависит от следующих факторов:
 * Взаимодействие с ZK не нарушено
 * Является ли текущий инстанс держателем блокировки типа "мастер" или "синхронная реплика"
 * Присутствует ли в ZK блокировка от мастера
 * Имеются ли в кластере рабочие реплики
 * Тип репликации соответствует требованиям из конфига

### Последовательность действий
1. Инициализация. Загружаются plugin-ы, например, на pgmeta, где баунсеры смотрят в мастер.
 * 1.1. Проверяется отстутствие стоп-флага. Если есть, gpsync завершается с ошибкой.
 * 1.2. Проверяется связность с ПГ и ЗК. Если с ЗК не удается связаться и текущая роль -- мастер, останавливается pgbouncer. Если не работает ПГ, а ЗК в порядке, то отпускается мастер-блокировка.
 * 1.3. Проверяется возможность сделать pg_rewind. Если нет, то gpsync завершается.
 * 1.4. Производится проверка того, что рабочий кластер не запущен на "пустом" ЗК, т.к. это, с большой долей вероятности, следствие ошибки в конфигурации. Если оба нижеприведенных условия выполняются, то gpsync завершается аварийно.
 * 1.4.1. Проверяется наличие в ЗК узлов-потомков по адресу ```<prefix>/all_hosts```.
 * 1.4.2. Проверяется timeline текущего инстанса: он должен быть больше единицы.
 * 1.5. В блокирующем режиме создается узел-потомок с hostname текущего инстанса по адресу ```<prefix>/all_hosts/<hostname>```.
2. Main loop.
 * 2.1. Ждем ```global:iteration_timeout```
 * 2.2. Определяется текущая локальная роль ПГ и его состояние.
 * 2.3. Определяется состояние ЗК (наличие соединения).
 * 2.4. Пишется статус-файл, содержащий инф-ю из пп 2.2. и 2.3.
 * 2.5. В зависимости от роли (мастер, реплика, неисправен) выполняются различные проверки и действия. См ниже подробнее п 3, 4 и 5.
 * 2.6. Переинициализируется соединение с ПГ и ЗК, если оно потеряно.

3. Действия и проверки если локальная роль это "мастер"
 * 3.1. Попытаться получить блокировку типа "мастер". Если это не получилось:
 * 3.1.1. Локальный pgbouncer останавливается.
 * 3.1.2. Если держатель блокировки не определен, то переинициализировать соединение. Переход к (п.2)
 * 3.1.3. Если держатель определен, и это не текущий инстанс, то, фактически, хост превращается в реплику. Процедура передачи роли описана в п.4.3.
 * 3.2. Записать в ЗК информацию о репликах, если инф-я из ЗК от timeline совпадает с полученной из ПГ.
 * 3.3. Если timeline из ЗК совпадает с локальным, однако пп. 3.2. не удался, останавливается pgbouncer и возвр. на п 2.
 * 3.4. Если в ЗК нет инф-ии о timeline, то записывается локальная.
 * 3.5. Если локальный timeline и на ЗК не совпадают:
 * 3.5.1. Производится checkpoint.
 * 3.5.2. Если timeline в ЗК больше локального, то останавливаем pgbouncer и переходим на п. 2
 * 3.5.3. Если локальный timeline больше, чем в ЗК, то перезаписываем инф-ю в ЗК.
 * 3.6. Запускаем pgbouncer.
 * 3.7. Если выставлен ```master:change_replication_type```:
 * 3.7.1. Сравнить текущий и желамый тип репликации -- "sync" или "async"
 * 3.7.2. Выставить нужный тип репликации. В случае с sync также указываем имя хоста, удерживающего блокировку sync_replica.

4. Действия и проверки если локальная роль это "реплика"
 * 4.1. Проверить есть связность с ЗК. Если нет, то возврат в п.2.
 * 4.2. Проверить наличие блокировки типа "мастер". В случае, если ее нет, произвести failover: (любое исключение перехватывается и вызывает аварийное завершение gpsync)
 * 4.2.1. Провести ряд проверок. При провале любой из них возврат к п. 2: 
 * 4.2.1.1. Является ли текущий инстанс sync-репликой;
 * 4.2.1.2. Прошло ли достаточно времени с момента последней попытки failover (регулируется опцией ```replica:min_failover_timeout```);
 * 4.2.1.3. Если удалось определить timeline в ЗК, сравнить его с текущим. Если определить не удалось, пропустить проверку;
 * 4.2.1.4. Убедиться, что прошло достаточно (см. ```replica:failover_checks```) циклов;
 * 4.2.1.5. Убедиться, что мастер действительно мертв, сделав SELECT 42 из хоста, указанного в recovery.conf (каждый раз делать одну попытку; в случае неответа инкрементить счетчик до тех пор, пока он не станет больше ```replica:dead_master_checks```)
 * 4.2.2. Взять лок ЗК типа "мастер". В случае неудачи, п.2
 * 4.2.3. Попытаться удалить инф-ю о состоянии предыдущего failover. В случае неудачи, отпустить блокировку типа "мастер", возврат в п .2
 * 4.2.4. В случае, если используется replication_slots: 
 * 4.2.1.5. Отметить в ЗК, что failover находится в состоянии "creating_slots".
 * 4.2.1.6. Прочитать список участников кластера в шарде, исключить из этого списка текущий инстанс. В случае неудачи отпустить блокировку и вернутьсяк п.2
 * 4.2.1.7. Создать replication_slots.
 * 4.2.5. Отметить в ЗК, что failover находится в состоянии "promoting". Попытаться произвести pg_ctl promote. В случае его провала, отпустить блокировку и вернуться к п.2
 * 4.2.7. Дождаться, когда ПГ поднимется (ждать ```global:iteration_timeout```)
 * 4.2.7. Отметить в ЗК, что failover находится в состоянии "checkpointing", сделать checkpoint.
 * 4.2.8. Записать в ЗК текущий timeline, обновить failover в состояние "finished", а также поставить текущее время в last_failover_time.
 * 4.3. Проверить совпадает ли локальная информация о местонахождении роли мастера с адресом хоста, держащего блокировку типа "мастер". В противном случае:
 * 4.3.1. Останавливаем pgbouncer.
 * 4.3.2. Если количество попыток "поворота" на другой мастер не превышает ```<master|replica>:remaster_checks```, или инстанс находится в переходном состоянии, то переход на п. 2. (```self._return_to_cluster()```)
 * 4.3.3. Если ПГ уже находится в состоянии failover, то переход на п.2.
 * 4.3.4. Если ПГ находится в состоянии восстановления из архива, то выполняется переключение:
 * 4.3.4.1. Создать и заполнить recovery.conf, указывающий на нового мастера.
 * 4.3.4.2. Дождаться, когда ПГ достигнет консистентного состояния.
 * 4.3.4.3. Дождаться, когда с мастера начнуть приходить WAL:
 * 4.3.4.5. Возврат к п.2
 * 4.3.5. Если счетчик попыток rewind больше ```global:max_rewind_retries```, то ставим особый флаг (см. пп. 1.1.) и завершаем работу gpsync с ошибкой.
 * 4.3.6. Делаем попытку rewind, т.к. п. 3.1.3.4. не сработал. Если попытка провалится, переход на п.2
 * 4.3.6.1. Останавливаем ПГ, если он не перешел в нормальное состояние (с т.з. pg_control)
 * 4.3.6.2. Удаляем recovery.conf, временно отключаем архивацию.
 * 4.3.6.3. Запускаем ПГ, сбрасывает postgresql.auto.conf
 * 4.3.6.4. Ставим rewind-блокировку в ЗК, производим rewind, снимаем.
 * 4.3.6.5. Выполнить последовательность действий, аналогичную 3.1.3.4
 * 4.3.7. Если включены replication slots, то добавить их.
 * 4.4. Проверить, что в ЗК есть информация о текущей реплике и она имеет отметку "streaming". В противном случае:
 * 4.4.1. Если текущая реплика имеет тип "sync", то отпустить блокировку типа "синхронная реплика".
 * 4.4.2. Произвести checkpoint.
 * 4.4.3. Если текущий timeline меньше timeline в ЗК на единицу:
 * 4.4.3.1. В течение ```replica:recovery_timeout``` ожидать логов с мастера. В противном случае предпринять новую попытку failover -- п. 4.3
 * 4.5. Если ```replica:start_pgbouncer``` выставлен в "yes", то запустить pgbouncer.
 * 4.6. Если текущая реплика имеет отметку "streaming", то попытаться схватить блокировку типа "синхронная реплика".

5. Действия и проверки если локальную роль не удается определить
 * 5.1. Остановить pgbouncer.
 * 5.2. Отпустить блокировки в ЗК типа "мастер" или "синхронная реплика", если текущий инстнс является их держателем.
 * 5.3. Из ранее сохраненного состояния (см. п.2.2 и п.2.3) попытаться определить роль, мастера, timeline, версию ПГ и местонахождение директории pgdata. В случае провала или недоступности этой информации, присвоить роль "реплика", а последний мастер равным None.
 * 5.4. При наличии активной блокировки типа "мастер":
 * 5.4.1. Сравнить хостнейм его держателя с инф-ей из п. 5.3. Если предыдущая локальная роль была "реплика", а мастер не изменился, то попытаться запустить ПГ, и вернуться в п.2.
 * 5.4.2. Если мастер изменился или предыдущая локальная роль не была "реплика", то локальный инстанс переводится в режим "реплика" и далее согласно п. 4.3.
 * 5.5. В случае, если активных блокировок нет (кластер находится в нерабочем состоянии):
 * 5.5.1. Если предыдущая роль была "мастер" и инф-я о timeline из ЗК не совпадает с последним локальным timeline, то возврат к п.2

### Утилита gpsync-util

В поставку входит утилита gpsync-util, которая позволяет осуществлять переключение мастера или инициализировать кластер в случае запуска из резервной копии или смены адреса ЗК.
Подробное описание ключей см через опции ```gpsync-util --help```, а также ```gpsync-util <command> --help```.

#### Плановое переключение мастера
Pgsync имеет возможность осуществлять плановое переключение мастера. Данный функционал предусматривает переход роли мастера к текущей синхронной реплике.
Для того, чтобы инициировать переключение, используется режим ```switchover```. Например:
```
gpsync-util -c gpsync.conf switchover
2017-01-19 15:50:32,583 DEBUG:	lock holders: {u'sync_replica': u'pgtest01i.mail.yandex.net', u'master': u'pgtest01h.mail.yandex.net', u'timeline': 38}
2017-01-19 15:50:32,583 INFO:	switchover pgtest01h.mail.yandex.net (timeline: 38) to pgtest01i.mail.yandex.net
type "yes" to continue: yes
2017-01-19 15:50:35,157 INFO:	initiating switchover with {u'timeline': 38, u'hostname': u'pgtest01h.mail.yandex.net'}
2017-01-19 15:50:35,173 DEBUG:	No lock instance for switchover/master. Creating one.
2017-01-19 15:50:35,531 DEBUG:	state: {u'info': {u'timeline': 38, u'hostname': u'pgtest01h.mail.yandex.net'}, u'progress': u'scheduled', u'failover': u'finished', u'replicas': [{u'replay_location_diff': 128, u'write_location_diff': 0, u'sync_state': u'sync', u'sent_location_diff': 0, u'master_location': u'5/760B6700', u'client_hostname': u'pgtest01i.mail.yandex.net', u'state': u'streaming'}, {u'replay_location_diff': 128, u'write_location_diff': 0, u'sync_state': u'async', u'sent_location_diff': 0, u'master_location': u'5/760B6700', u'client_hostname': u'pgtest01f.mail.yandex.net', u'state': u'streaming'}]}
2017-01-19 15:50:35,673 DEBUG:	current switchover status: scheduled, failover: finished
2017-01-19 15:50:36,832 DEBUG:	current switchover status: initiated, failover: switchover_initiated
2017-01-19 15:50:38,258 DEBUG:	current switchover status: initiated, failover: switchover_master_shut
2017-01-19 15:50:39,401 DEBUG:	current switchover status: promoting_replica, failover: promoting
2017-01-19 15:50:40,559 DEBUG:	current switchover status: promoting_replica, failover: promoting
2017-01-19 15:50:41,689 DEBUG:	current switchover status: promoting_replica, failover: promoting
2017-01-19 15:50:42,897 DEBUG:	current switchover status: promoting_replica, failover: promoting
2017-01-19 15:50:45,079 INFO:	master is now pgtest01i.mail.yandex.net
2017-01-19 15:50:45,142 DEBUG:	full state: {u'info': {u'timeline': 38, u'hostname': u'pgtest01h.mail.yandex.net'}, u'progress': u'finished', u'failover': u'finished', u'replicas': [{u'replay_location_diff': 128, u'write_location_diff': 0, u'sync_state': u'sync', u'sent_location_diff': 0, u'master_location': u'5/760B6780', u'client_hostname': u'pgtest01i.mail.yandex.net', u'state': u'streaming'}, {u'replay_location_diff': 128, u'write_location_diff': 0, u'sync_state': u'async', u'sent_location_diff': 0, u'master_location': u'5/760B6780', u'client_hostname': u'pgtest01f.mail.yandex.net', u'state': u'streaming'}]}
2017-01-19 15:50:45,142 DEBUG:	waiting for replicas to appear...
2017-01-19 15:50:46,206 DEBUG:	replicas up: pgtest01h.mail.yandex.net@5/77002098
2017-01-19 15:50:47,270 DEBUG:	replicas up: pgtest01h.mail.yandex.net@5/77002198
2017-01-19 15:50:48,335 DEBUG:	replicas up: pgtest01h.mail.yandex.net@5/77002198
2017-01-19 15:50:49,416 DEBUG:	replicas up: pgtest01h.mail.yandex.net@5/770024F8
2017-01-19 15:50:50,497 DEBUG:	replicas up: pgtest01h.mail.yandex.net@5/770024F8
2017-01-19 15:50:51,561 DEBUG:	replicas up: pgtest01f.mail.yandex.net@5/77002580, pgtest01h.mail.yandex.net@5/77002580
2017-01-19 15:50:51,561 INFO:	switchover finished, status "finished"
```
На переключение, запуск мастера и появление реплик в состоянии ```streaming``` выставляется таймаут в 60 сек по-умолчанию (для каждого этапа). Параметр можно переопределить опцией ```--timeout```. Ожидаемое количество реплик определяется через опцию ```--replicas``` и по-умолчанию составляет 2.
Если по какой-то причине переключение не случилось и/или требуется сбросить состояние переключения (н., при опечатке при явном указании мастера или timeline), следует воспользоваться опцией ```--reset```. Вместе с тем, поскольку данный функционал предполагает вмешательство в распределнный алгоритм, это следует делать только в том члучае, когда есть гарантия, что переключения не произойдет. В противном случае есть риск привести кластер к аварийному переключению (failover).
Кроме того, допускается явное указание как мастера, так и timeline, которые следует переключить. Следует, однако, помнить, что в случае, если они не совпадают с реальными, логика gpsync их проигнорирует.

#### Миграция на другой префикс или адрес в ЗК
В gpsync настроена защита от запуска рабочего кластера в "пустом" ЗК. Это сделано для предотвращения последствий ошибки в конфигурировании (см. п. 1.4.)
Если при старте текущий инстанс имеет timeline более единицы (т.е. как минимум однажды производился promote мастера), а в ```<prefix>/all_hosts@ZK``` нет ни одного узла-потомка, gpsync завершается аварийно.

Вместе с тем, может возникнуть необходимость такого запуска, например при управляемом изменении адреса или префикса ЗК.

Для этого можно воспользоваться режимом ```initzk``` утилиты. Например:
```
gpsync-init --config gpsync.conf --zk new.zk.addr:port --prefix /new_prefix pg01a.fq.dn pg01b.fq.dn pg01c.fq.dn
```

Если не указано иное, префиксы и адреса ЗК используются из конфигурации (по-умолчанию ```/etc/gpsync.conf```).
Единственным обязательным параметром является список hostname-ов, разделенный пробелами.

### Конфигурация
Несколько моментов, на которые следует обратить внимание:

1. Параметры ```change_replication_type``` и ```change_replication_metric``` можно настроить так, чтобы gpsync вообще не менял тип репликации. Или деградировал до асинхронной репликации в случае проблем только днём, а ночью и в выходные, когда нагрузки меньше, репликация всегда была синхронной.

2. Параметр ```allow_potential_data_loss``` допускает переключение мастера даже тогда, когда ни одна из реплик не является синхронной (т.е. с потерей данных). В этом случае новым мастером станет та, у которой старше позиция xlog'а.

#### Пример конфигурации с описанием

```ini
[global]
# Имя пользователя, под которым будет работать демон.
daemon_user = postgres

# Путь до файла журнала. В случае, если путь относительный, родительским каталогом будет working_dir (ниже)
log_file = /var/log/gpsync/gpsync.log

# Запуск без ухода в фоновый режим
foreground = no

# Детализация журнала. Допустимые значения: debug, info, warning, error, critical.
log_level = debug

# Путь до pid-файла..
pid_file = /var/run/gpsync/gpsync.pid

# Рабочая директория демона (cwd)
working_dir = /tmp

# Строка подключения к локальному инстансу ПГ.
local_conn_string = dbname=postgres user=postgres connect_timeout=1

# Дополнительные параметры в случае подключения к мастеру.
# Используются для вызова pg_rewind.
append_rewind_conn_string = port=5432 dbname=postgres user=xxx password=xxx connect_timeout=10 sslmode=verify-full

# Строка подключения, используемая при проверке доступности ПГ.
append_master_conn_string = port=6432 dbname=postgres user=xxx password=xxx connect_timeout=1 sslmode=verify-full

# Время ожиданяи в секундах между итерациями main loop (см. выше).
iteration_timeout = 1

# Строка подключения к Zookeeper
zk_hosts = zk02d.mail.yandex.net:2181,zk02e.mail.yandex.net:2181,zk02g.mail.yandex.net:2181

# Путь к директории, содержащей исполняемые файлы из поставки ПГ (pg_rewind, pg_controldata, pg_ctl)
bin_path = /usr/lib/postgresql/9.6/bin

# Команда запуска ПГ
pg_service_cmd = sudo service postgresql %s

# Использовать ли replication_slots при изменении ролей
use_replication_slots = yes

# Команда генерации файла recovery.conf. Команде передаются следующие аргументы:
# # %m - hostname мастера
# # %p - полный путь до recovery.conf
generate_recovery_conf = /usr/local/yandex/populate_recovery_conf.py -s -r -p %p %m

# Максимальное количество попыток выполнить pg_rewind. После исчерпания этой цифры pgysnc ставит флаг и завершается с ошибкой (см.)
max_rewind_retries = 3

# Используется ли pgbouncer в единственном экземпляре или нет
standalone_pgbouncer = yes

# Адрес по которому работает проверка pgbouncer в случае standalone_pgbouncer = yes
pgbouncer_addr = localhost

# Порт по которому работает проверка pgbouncer в случае standalone_pgbouncer = yes
pgbouncer_port = 6432

# Таймаут проверки pgbouncer на адрес:порт в секундах
pgbouncer_conn_timeout = 1

[master]
# Изменять ли тип репликации на синхронный (или асинхронный)
# Выполняется только в случае, если есть блокировка в ЗК.
change_replication_type = yes

# Критерий, согласно которому изменять тип репликации:
# 'count' - реппликация становится асинхронной в случае неисправности всех реплик, 
#           и синхронной в случае, если, как минимум, одна реплика доступна.
# 'load'  - реппликация становится асинхронной в случае, если кол-во сессий превышает overload_sessions_ratio. 
#           В случае возврата этого показателя к норме, синхронность восстанавливается.
# 'time'  - Изменение типа репликации произойдет только в указанное время. Требует наличия count или load (см. выше)
change_replication_metric = count,load,time

# Порог количества сессий (включая неактивные), после пересечения которого изменять тип репликации (если указан соотвтветствующий аргумент выше)
overload_sessions_ratio = 75

# Расписание выключения синхронной репликации: если текущее время попадает в обозначенный интервал, gpsync может выключать синхронную репликацию.
# В примере ниже указано рабочее время по будням и "никогда" по выходным.
weekday_change_hours = 10-22
weekend_change_hours = 0-0

# Количество проверок, после которых старый мастер становится репликой нового.
remaster_checks = 3

[replica]
# Количество проверок, после которорых синхронная реплика становится мастером.
failover_checks = 3

# Запускать ли pgbouncer на реплике в случае, если аномалий не обнаружено.
start_pgbouncer = yes

# Количество проверок, после которорых реплика производит переключение мастера (источника репликации).
remaster_checks = 5

# Промежуток времени (в сек), в течение которого запрещены новые попытки failover. Счетчик запускается после последнего failover.
min_failover_timeout = 3600

# Резрешить проведение failover в случае, если в кластере нет синхронных реплик.
allow_potential_data_loss = no

# Время, в течение которого ожидать завершения восстановления инстанса в кластер. По истечению указанного порога запускается pg_rewind.
recovery_timeout = 60

# Количество проверок доступности мастера через протокол ПГ, прежде, чем выполнять failover.
# Актуально в случае, если между ЗК и текущим мастером отстутствует связность.
dead_master_checks = 86400
```
## Используемые компоненты

### Внутренние компоненты

Внутрияндексовые компоненты не используются.

### Внешние компоненты

* [Kazoo](https://github.com/python-zk/kazoo) для взаимодействия с Zookeeper
* [Psycopg2](https://github.com/psycopg/psycopg2) для взимодействия с Postgresql
