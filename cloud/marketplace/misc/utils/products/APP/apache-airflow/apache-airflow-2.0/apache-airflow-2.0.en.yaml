consoleDescription: "A platform created to author, schedule and monitor workflows programmatically."
siteDescription: "Apache® Airflow enables you to author workflows as Directed Acyclic Graphs (DAGs) of tasks. The Airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. You can easily visualize pipelines running in production, monitor progress, and troubleshoot issues in user-friendly interface. Apache® is either registered trademark or trademark of the Apache Software Foundation in the United States and/or other countries."
useCases: |
  * Creating Directed Acyclic Graphs (DAGs) of tasks.
  * Monitoring.

name: 2.0
documentation: |
  * [Website](https://airflow.apache.org/)
  * [Documentation](https://airflow.apache.org/docs/stable/)
additionalInfo: "The image is created based on Ubuntu 20.04 image.
Airflow version 2.0.0 is installed.
Main configuration file is located in /etc/airflow/airflow.cfg
Airflow logs are stored in directory /var/log/airflow/
DAGs should be placed to directory /home/airflow/dags/
Airflow scheduler and webserver are run as systemd units: airflow-scheduler.service and airflow-webserver.service
Airflow metadata db is run as local PostgreSQL daemon 127.0.0.1:5432 (connect using ssh to see username, password and db name)
Airflow webserver is listening on http://0.0.0.0:80/
DB encryption key and Flask key are generated during instance creation and written to file /etc/airflow/secrets.txt
Airflow webserver requires authentication by default.
Username: test_admin
Password: <Compute instance id>"
