[Алерт в Juggler](https://juggler.yandex-team.ru/aggregate_checks/?project=ycloud&query=service%3Dinstance-*%26host%3Dyc_common_compute_*), [Алерт в Solomon](https://solomon.yandex-team.ru/admin/projects/yandexcloud/alerts?text=alert+on+crashed+instances).

## instance-crashed, instance-error
Загорается при переходе инстансов в статусы `crashed/error`.

## Подробности
Метка `reason` определяет причину падения. Причины можно разбить на две категории по зоне ответственности: Compute и Core. В данный момент все алерты получает команда Compute. Как обкатаем эту схему, и Юра переведет нас на алертинг через Juggler - завернем часть алертов в команду Core. Пока же имеет смысл при разборе алертов проверять - действительно ли сгенеренный код соответствует реальной причине и команде, к которой она отнесена.

На данный момент алерт никак не учитывает, что инстансы могут быть Serverless'ными, но на самом деле ошибки от Serverless никогда не должны роутиться в Core.

Ниже - список всех возможных причин с разбивкой по командам.

## Диагностика

### Compute
#### 1. catch-of-running-instance
На ноде инстанса не было, она увидела, что в Compute он на нее заассайнен и при этом находится в running статусе. Нода его себе взяла в управление, но через `running` -> `crashed` . По идее, такого быть не должно. Если произошло - значит ноду затерли без расселения (ошибка инфры).

**Как реагировать?**

Пока не перейдем на Juggler-алерты, будут приходить - никак не реагируем. Когда перейдем - должны срабатывать даунтаймы инфры, а если не сработали - уже тогда выяснять, что это было.

#### 2. compute-node-reboot

Нода запускается - у нее в `state.json` инстанс в `running`, но процесса гипервизора уже нет, и по косвенным признакам мы выясняем, что был ребут железки.

**Как реагировать?**

На единичные события нет особого смысла как-то реагировать, т. к. за ребутом железок следит Инфра, но если прилетела пачка от разных нод, то лучше удостовриться, что это были именно ребуты (посмотреть uptime), и Инфра в курсе.

#### 3. hypervisor-configuration
Пока что довольно общий код. Любая ошибка в процессе конфигурации запущенного гипервизора (втыкание дисков, сетевых интерфейсов, GPU).

**Как реагировать?**

Продиагностировать, завести тикет.

#### 4. instance-configuration

Тоже пока что очень общий код. Любая ошибка в процессе подготовки всех необходимых ресурсов инстанса.

**Как реагировать?**

Продиагностировать, завести тикет.

#### 5. local-disk-error

Не смогли затереть локальный NVMe-диск.

**Как реагировать?**

Вместе с этим событием должен загореться Juggler-алерт
[compute-node-disks](https://docs.yandex-team.ru/yc-monitoring/compute-node/compute-node-disks), в котором будет список
проблемных дисков, о которых необходимо сообщить `/duty infra`.

#### 6. lost-hypervisor-during-restart

Нода запускается - у нее в `state.json` инстанс в `running`, но процесса гипервизора уже нет, либо не удается к нему подключиться.

Возможные причины:

* Между остановкой и запуском сервиса прошло значительное время, и инстанс за это время успел остановиться сам (`poweroff` из гостя). Этот кейс будет постепенно исключаться по мере перехода инстансов на [CLOUD-86256](https://st.yandex-team.ru/CLOUD-86256).
* Ребут ноды. В случае ребута ноды мы в большинстве случаев должны прислать `compute-node-reboot`, но не всегда: если инстанс участвовал в каком-то переходном процессе, то для этого случая у нас пока недостаточно эвристик.
* Нода не смогла переподключиться к гипервизору.

**Как реагировать?**

Понять причину и уже действовать исходя из этого понимания.

#### 7. migration-abort

Генерируется только Python-нодой с ее довольно костыльной схемой live-migration. Скорее всего, означает, что у нас по какой-то причине сфейлилась либо подготовка инстанса на target node, либо incoming миграция.

**Как реагировать?**

Просим konishchev@ посмотреть.

#### 7. missing-encryption-key

Инстанс запущен с `internal_data_disk_id`, но секрета с таким именем нет на данной Compute Node. Скорее всего, впоследствии выключим его из алерта, т. к. это ошибка пользователя, а не команды Compute.

**Как реагировать?**

Ничего не делаем. Пользователь сам увидит сфейлившуюся операцию.

#### 8. nbs-endpoints-error

Проблемы с конфигурацией NBS endpoint'ов.

**Как реагировать?**

Просим zasimov-a@ посмотреть.

#### 9. unknown-error

Все остальное. По идее, не должно возникать.

**Как реагировать?**

**Важно!** Разобраться с причиной и завести тикет на то, чтобы завести новый код креша или уточнить правила для существующего.

### Core

#### 1. broken-qmp-connection

Проблемы с QMP-соединением. Вероятнее всего - таймаут при ожидании ответа от QMP.

**Как реагировать?**

Читать логи/dmesg - искать причину залипания QEMU.

#### 2. failed-incoming-migration

Incoming-миграция завершилась с ошибкой.

**Как реагировать?**

Читать логи QEMU (прикапываются в логи инстанса) - там вероятнее всего будет причина фейла миграции.

#### 3. guest-panic

Гостевая паника (triple fault). Вероятнее всего, проблема в самом госте, и команде Core это будет не интересно.

**Как реагировать?**

По идее, этот код имеет смысл игнорировать для единичных инстансов и обращать внимание только на массовые срабатывания.

#### 4. hypervisor-startup-error

Гипервизор не смог запуститься за отведенный таймаут, либо вовсе упал при старте. К примеру, как следствие фрагментации THP.

**Как реагировать?**

Сначала смотрим в логи QEMU. Дальше уже разбираем индивидуально.

#### 5. hypervisor-termination-error

Не смогли убить гипервизор за отведенный таймаут. К примеру, висел в D-state.

**Как реагировать?**

Разбирается индивидуально (логи, atop, и пр.).

#### 6. qmp-error

Получили отказ в выполнении QMP-команды там, где Compute предполагает всегда успешное ее выполнение.

**Как реагировать?**

Смотрим логи инстанса - какая команда посылалась, какой ответ получили.

#### 7. unexpected-hypervisor-shutdown

Гипервизор завершился не по нашей инициативе - к примеру, OOM.

**Как реагировать?**

Сначала смотрим в dmesg, предполагая OOM, если нет - уже в логи и пр. В случае OOM увозим инстанс с ноды ([старый способ](https://wiki.yandex-team.ru/cloud/compute/duty/#uveztimashinysrabotajushhegouzlacherezlivemigration), [новый способ](https://wiki.yandex-team.ru/cloud/compute/admin-api/#rasselenienody)). Нередкая ситуация - когда инстанс не получается увезти, т. к. он OOM'ится в процессе live migration. В этом случае можно либо попробовать увезти соседей, либо сделать [ycp compute admin node disable](https://wiki.yandex-team.ru/cloud/compute/admin-api/#editor) + `yc --profile sa-prod compute instance stop $id` + `yc --profile sa-prod compute instance start $id` (из под сервисного аккаута) + [ycp compute admin node enable](https://wiki.yandex-team.ru/cloud/compute/admin-api/#editor), убедившись перед start'ом, что инстанс успел деаллоацироваться с ноды (`ycp compute instance get $id | grep compute_node`).

## Ссылки
- [Исходный код алерта](https://bb.yandex-team.ru/projects/CLOUD/repos/yc-monitoring/browse/compute/alerts/compute_bad_instances.j2)
- [CLOUD-71477](https://st.yandex-team.ru/CLOUD-71477)
